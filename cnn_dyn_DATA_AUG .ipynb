{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782da64b",
   "metadata": {},
   "source": [
    "IMPORT AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3282f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765551689.450296 3442771 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1765551689.480458 3442771 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765551690.056336 3442771 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.0-dev20251210\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✅ Op Determinism Abilitato!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765551690.752522 3442771 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"✅ Op Determinism Abilitato!\")\n",
    "except AttributeError:\n",
    "    print(\"⚠️ Attenzione: La tua versione di TF è troppo vecchia per enable_op_determinism.\")\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "SEEDS = [555, 123,42,7,999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65e287",
   "metadata": {},
   "source": [
    "DATASET LOADING AND MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    folder='dataset/images'\n",
    "    data=[]\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path=os.path.join(folder,filename)\n",
    "        img=cv2.imread(img_path) #opencv save in bgr\n",
    "        data.append({\n",
    "            'image':img,\n",
    "            'filename':filename\n",
    "        })\n",
    "\n",
    "    print(len(data),'images loaded')\n",
    "    print('file name is: ',data[0]['filename'], 'shape of the image is:  ', data[0]['image'].shape )\n",
    "\n",
    "    label=pd.read_csv('dataset/raw/bbx_annotations.csv')\n",
    "    print(label.shape, label.iloc[0]['filename'])\n",
    "    #images order is random, and for 1 image you can have more class\n",
    "\n",
    "    print('we have', len(label['class'].unique()), 'different classes')\n",
    "\n",
    "    #replace biggger img with half sized ones\n",
    "    #cv2.imwrite('resize_image/last_img_pre_downsampling.jpg',data[-100]['image'])\n",
    "    for i,item in enumerate(data):\n",
    "        if \"upper\" in item[\"filename\"].lower():\n",
    "            data[i]['image']=cv2.resize(\n",
    "                data[i]['image'],\n",
    "                (data[i]['image'].shape[1]//2,data[i]['image'].shape[0]//2)\n",
    "                ,interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    #cv2.imwrite('resize_image/last_img_post_downsampling.jpg',data[-100]['image'])\n",
    "       \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea259a97",
   "metadata": {},
   "source": [
    "FROM THE PURE DATASET TO THE TRAIN AND TEST DATA AND LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e35d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_modelling(dataset,annotation):   \n",
    "    dataset_df = pd.DataFrame(dataset) \n",
    "    label_map={'goalpost':0,\n",
    "               'ball':1,\n",
    "               'robot':2,\n",
    "               'goalspot':3,\n",
    "               'centerspot':4}\n",
    "    def get_vector(classes_found):\n",
    "        vec=np.zeros(5,dtype=int)\n",
    "\n",
    "        for c in classes_found:\n",
    "            if c in label_map:\n",
    "                vec[label_map[c]]=1\n",
    "        return list(vec)\n",
    "    \n",
    "    grouped = annotation.groupby('filename')['class'].apply(list).reset_index()\n",
    "    grouped['label']=grouped['class'].apply(get_vector)\n",
    "    final_annotation=grouped[['filename','label']]\n",
    "\n",
    "    final_dataset= pd.merge(dataset_df, final_annotation[['filename', 'label']], on='filename', how='inner')\n",
    "    final_dataset.to_csv('csv/temp/final_dataset.csv')\n",
    "    final_dataset=final_dataset.drop(columns=['filename'])\n",
    "    df_train, df_test = train_test_split(final_dataset, test_size=0.2, random_state=42)\n",
    "    x_train = np.array(df_train['image'].tolist()).astype('float32') /255.0\n",
    "    y_train = np.array(df_train['label'].tolist()).astype('float32')\n",
    "    \n",
    "    x_test = np.array(df_test['image'].tolist()).astype('float32') / 255.0\n",
    "    y_test = np.array(df_test['label'].tolist()).astype('float32')\n",
    "    return x_train, y_train,x_test,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f862c6d",
   "metadata": {},
   "source": [
    "DOUBLING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_set(x_train,y_train,aug_type):\n",
    "    rng = np.random.RandomState(42)    \n",
    "    if aug_type=='flip':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        x_train_aug = np.concatenate([x_train, x_flipped], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train, y_flipped], axis=0)\n",
    "    elif aug_type=='noise':\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        x_train_aug = np.concatenate([x_train, x_noisy], axis=0)\n",
    "        y_noise = y_train\n",
    "        y_train_aug = np.concatenate([y_train, y_noise], axis=0)\n",
    "    elif aug_type=='both':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        y_noise = y_train\n",
    "        x_train_aug = np.concatenate([x_train,x_flipped, x_noisy], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train,y_flipped, y_noise], axis=0)\n",
    "\n",
    "    #avoid to have all noisy data in validation--> shuffle\n",
    "    indices = np.arange(x_train_aug.shape[0])\n",
    "    rng.shuffle(indices)\n",
    "    x_train_aug = x_train_aug[indices]\n",
    "    y_train_aug = y_train_aug[indices]\n",
    "\n",
    "    return x_train_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b40f52",
   "metadata": {},
   "source": [
    "MODEL BUILIDNG, \n",
    "kernel dimesnsion, pooling dimension, fc layers dimension, number of conv layer and learning rate have different combination.\n",
    "instead, i fixed:\n",
    "pooling stride=2 \n",
    "pooling type: avg pooling\n",
    "number of kernel per layer: 16, 32, 64...\n",
    "last pooling: glob avg pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(240,320,3)))\n",
    "    model.add(layers.RandomFlip(\"horizontal\"))\n",
    "    model.add(layers.GaussianNoise(0.05))\n",
    "\n",
    "    for i in range(4):\n",
    "        kernel_number=16*(2**i)\n",
    "        model.add(layers.Conv2D(kernel_number,(7,7),activation='relu',padding='same'))\n",
    "        model.add(layers.AveragePooling2D((3,3),strides=2,padding='same'))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a2e85",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee23710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452 images loaded\n",
      "file name is:  lower_100056_jpg.rf.ec9852c66b4eee4a185317210a378f16.jpg shape of the image is:   (240, 320, 3)\n",
      "(8125, 8) upper_604302_jpg.rf.6215ee30a829ec658154eb4d067dfdf5.jpg\n",
      "we have 5 different classes\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 555 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765551692.709396 3442771 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1765551692.779440 3442771 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9241 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765551695.073061 3443095 cuda_dnn.cc:461] Loaded cuDNN version 91600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 0.5252 - precision: 0.7844 - recall: 0.4786 - val_loss: 0.5287 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 2/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.5130 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5151 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 3/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4977 - precision: 0.8107 - recall: 0.4777 - val_loss: 0.4909 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 4/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4851 - precision: 0.8201 - recall: 0.4819 - val_loss: 0.4957 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 5/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4711 - precision: 0.8298 - recall: 0.4911 - val_loss: 0.4844 - val_precision: 0.7544 - val_recall: 0.5147\n",
      "Epoch 6/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4654 - precision: 0.8329 - recall: 0.4977 - val_loss: 0.4909 - val_precision: 0.7592 - val_recall: 0.5009\n",
      "Epoch 7/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4592 - precision: 0.8411 - recall: 0.5002 - val_loss: 0.4876 - val_precision: 0.7875 - val_recall: 0.4991\n",
      "Epoch 8/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4598 - precision: 0.8439 - recall: 0.5019 - val_loss: 0.4872 - val_precision: 0.8022 - val_recall: 0.4974\n",
      "Epoch 9/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4546 - precision: 0.8499 - recall: 0.5019 - val_loss: 0.4924 - val_precision: 0.7939 - val_recall: 0.4922\n",
      "Epoch 10/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4540 - precision: 0.8500 - recall: 0.5048 - val_loss: 0.4881 - val_precision: 0.7978 - val_recall: 0.4974\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765551733.210672 3442771 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 123 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.5270 - precision: 0.7951 - recall: 0.4765 - val_loss: 0.5348 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 2/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4982 - precision: 0.8192 - recall: 0.4940 - val_loss: 0.5028 - val_precision: 0.7812 - val_recall: 0.4750\n",
      "Epoch 3/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4703 - precision: 0.8386 - recall: 0.4931 - val_loss: 0.4789 - val_precision: 0.7873 - val_recall: 0.4922\n",
      "Epoch 4/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4674 - precision: 0.8427 - recall: 0.4948 - val_loss: 0.4757 - val_precision: 0.7983 - val_recall: 0.4991\n",
      "Epoch 5/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4653 - precision: 0.8491 - recall: 0.4965 - val_loss: 0.4781 - val_precision: 0.7790 - val_recall: 0.4870\n",
      "Epoch 6/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4685 - precision: 0.8417 - recall: 0.4935 - val_loss: 0.4816 - val_precision: 0.7818 - val_recall: 0.4888\n",
      "Epoch 7/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4625 - precision: 0.8409 - recall: 0.5015 - val_loss: 0.4815 - val_precision: 0.7839 - val_recall: 0.4888\n",
      "Epoch 8/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4577 - precision: 0.8471 - recall: 0.5027 - val_loss: 0.4774 - val_precision: 0.7978 - val_recall: 0.5043\n",
      "Epoch 9/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4557 - precision: 0.8502 - recall: 0.5056 - val_loss: 0.4743 - val_precision: 0.7961 - val_recall: 0.4991\n",
      "Epoch 10/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4546 - precision: 0.8541 - recall: 0.5069 - val_loss: 0.4729 - val_precision: 0.8039 - val_recall: 0.5026\n",
      "Epoch 11/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4528 - precision: 0.8566 - recall: 0.5073 - val_loss: 0.4704 - val_precision: 0.8128 - val_recall: 0.5026\n",
      "Epoch 12/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4522 - precision: 0.8596 - recall: 0.5094 - val_loss: 0.4682 - val_precision: 0.8151 - val_recall: 0.5026\n",
      "Epoch 13/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4495 - precision: 0.8613 - recall: 0.5119 - val_loss: 0.4635 - val_precision: 0.8197 - val_recall: 0.5026\n",
      "Epoch 14/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4490 - precision: 0.8625 - recall: 0.5114 - val_loss: 0.4653 - val_precision: 0.8244 - val_recall: 0.5026\n",
      "Epoch 15/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4452 - precision: 0.8662 - recall: 0.5144 - val_loss: 0.4565 - val_precision: 0.8254 - val_recall: 0.5060\n",
      "Epoch 16/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4439 - precision: 0.8669 - recall: 0.5152 - val_loss: 0.4543 - val_precision: 0.8244 - val_recall: 0.5026\n",
      "Epoch 17/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4398 - precision: 0.8634 - recall: 0.5131 - val_loss: 0.4459 - val_precision: 0.8207 - val_recall: 0.5060\n",
      "Epoch 18/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4321 - precision: 0.8533 - recall: 0.5277 - val_loss: 0.4452 - val_precision: 0.8116 - val_recall: 0.5060\n",
      "Epoch 19/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4308 - precision: 0.8330 - recall: 0.5418 - val_loss: 0.4368 - val_precision: 0.7834 - val_recall: 0.5371\n",
      "Epoch 20/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4249 - precision: 0.8370 - recall: 0.5535 - val_loss: 0.4318 - val_precision: 0.7739 - val_recall: 0.5734\n",
      "Epoch 21/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4216 - precision: 0.8240 - recall: 0.5689 - val_loss: 0.4322 - val_precision: 0.7634 - val_recall: 0.5907\n",
      "Epoch 22/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4128 - precision: 0.8196 - recall: 0.5822 - val_loss: 0.4277 - val_precision: 0.7293 - val_recall: 0.6235\n",
      "Epoch 23/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4010 - precision: 0.8121 - recall: 0.6097 - val_loss: 0.4164 - val_precision: 0.7596 - val_recall: 0.6166\n",
      "Epoch 24/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.3917 - precision: 0.8081 - recall: 0.6275 - val_loss: 0.4093 - val_precision: 0.7520 - val_recall: 0.6390\n",
      "Epoch 25/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3833 - precision: 0.8097 - recall: 0.6409 - val_loss: 0.4056 - val_precision: 0.7982 - val_recall: 0.6079\n",
      "Epoch 26/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3793 - precision: 0.8093 - recall: 0.6500 - val_loss: 0.4065 - val_precision: 0.7899 - val_recall: 0.6235\n",
      "Epoch 27/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3715 - precision: 0.8083 - recall: 0.6667 - val_loss: 0.4106 - val_precision: 0.7768 - val_recall: 0.6252\n",
      "Epoch 28/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3643 - precision: 0.7995 - recall: 0.6787 - val_loss: 0.4033 - val_precision: 0.7949 - val_recall: 0.6425\n",
      "Epoch 29/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.3590 - precision: 0.8101 - recall: 0.6854 - val_loss: 0.4016 - val_precision: 0.7960 - val_recall: 0.6200\n",
      "Epoch 30/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.3542 - precision: 0.8173 - recall: 0.6871 - val_loss: 0.3941 - val_precision: 0.7894 - val_recall: 0.6408\n",
      "Epoch 31/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3466 - precision: 0.8184 - recall: 0.6958 - val_loss: 0.3976 - val_precision: 0.7674 - val_recall: 0.6269\n",
      "Epoch 32/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3409 - precision: 0.8214 - recall: 0.7004 - val_loss: 0.3965 - val_precision: 0.7924 - val_recall: 0.6459\n",
      "Epoch 33/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3373 - precision: 0.8172 - recall: 0.7070 - val_loss: 0.3877 - val_precision: 0.7931 - val_recall: 0.6356\n",
      "Epoch 34/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3317 - precision: 0.8231 - recall: 0.7145 - val_loss: 0.3824 - val_precision: 0.7983 - val_recall: 0.6425\n",
      "Epoch 35/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3264 - precision: 0.8289 - recall: 0.7137 - val_loss: 0.3761 - val_precision: 0.7860 - val_recall: 0.6598\n",
      "Epoch 36/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.3190 - precision: 0.8306 - recall: 0.7262 - val_loss: 0.3758 - val_precision: 0.7856 - val_recall: 0.6580\n",
      "Epoch 37/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.3171 - precision: 0.8344 - recall: 0.7233 - val_loss: 0.3680 - val_precision: 0.7863 - val_recall: 0.6926\n",
      "Epoch 38/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3112 - precision: 0.8388 - recall: 0.7320 - val_loss: 0.3675 - val_precision: 0.7860 - val_recall: 0.7168\n",
      "Epoch 39/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.3066 - precision: 0.8430 - recall: 0.7420 - val_loss: 0.3613 - val_precision: 0.7817 - val_recall: 0.7237\n",
      "Epoch 40/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3008 - precision: 0.8451 - recall: 0.7491 - val_loss: 0.3544 - val_precision: 0.7996 - val_recall: 0.7237\n",
      "Epoch 41/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2965 - precision: 0.8399 - recall: 0.7553 - val_loss: 0.3592 - val_precision: 0.7903 - val_recall: 0.7288\n",
      "Epoch 42/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.2900 - precision: 0.8415 - recall: 0.7532 - val_loss: 0.3543 - val_precision: 0.7973 - val_recall: 0.7202\n",
      "Epoch 43/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2845 - precision: 0.8447 - recall: 0.7607 - val_loss: 0.3586 - val_precision: 0.7860 - val_recall: 0.7358\n",
      "Epoch 44/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2781 - precision: 0.8479 - recall: 0.7653 - val_loss: 0.3624 - val_precision: 0.7849 - val_recall: 0.7375\n",
      "Epoch 45/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2795 - precision: 0.8487 - recall: 0.7728 - val_loss: 0.3567 - val_precision: 0.8088 - val_recall: 0.7012\n",
      "Epoch 46/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2741 - precision: 0.8483 - recall: 0.7794 - val_loss: 0.3578 - val_precision: 0.8085 - val_recall: 0.6926\n",
      "Epoch 47/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2688 - precision: 0.8453 - recall: 0.7819 - val_loss: 0.3466 - val_precision: 0.8015 - val_recall: 0.7185\n",
      "Epoch 48/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2592 - precision: 0.8583 - recall: 0.7865 - val_loss: 0.3456 - val_precision: 0.7860 - val_recall: 0.7168\n",
      "Epoch 49/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2531 - precision: 0.8536 - recall: 0.7932 - val_loss: 0.3522 - val_precision: 0.7796 - val_recall: 0.7271\n",
      "Epoch 50/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2493 - precision: 0.8527 - recall: 0.7953 - val_loss: 0.3433 - val_precision: 0.7928 - val_recall: 0.7271\n",
      "Epoch 51/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2437 - precision: 0.8606 - recall: 0.8040 - val_loss: 0.3417 - val_precision: 0.7872 - val_recall: 0.7409\n",
      "Epoch 52/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2405 - precision: 0.8549 - recall: 0.8044 - val_loss: 0.3520 - val_precision: 0.7632 - val_recall: 0.7513\n",
      "Epoch 53/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2420 - precision: 0.8554 - recall: 0.8077 - val_loss: 0.3550 - val_precision: 0.7599 - val_recall: 0.7651\n",
      "Epoch 54/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.2433 - precision: 0.8554 - recall: 0.8102 - val_loss: 0.3660 - val_precision: 0.7276 - val_recall: 0.7565\n",
      "Epoch 55/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2428 - precision: 0.8513 - recall: 0.8102 - val_loss: 0.3545 - val_precision: 0.7504 - val_recall: 0.7737\n",
      "Epoch 56/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2352 - precision: 0.8627 - recall: 0.8132 - val_loss: 0.3473 - val_precision: 0.7513 - val_recall: 0.7772\n",
      "\u001b[1m10/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765551937.348740 3442771 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 42 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.5356 - precision: 0.7833 - recall: 0.4798 - val_loss: 0.5143 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 2/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.5154 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5140 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 3/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.5091 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5114 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 4/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.5066 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5076 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 5/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4911 - precision: 0.8266 - recall: 0.4761 - val_loss: 0.4863 - val_precision: 0.7847 - val_recall: 0.4784\n",
      "Epoch 6/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.4736 - precision: 0.8304 - recall: 0.4911 - val_loss: 0.4843 - val_precision: 0.7942 - val_recall: 0.4732\n",
      "Epoch 7/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4668 - precision: 0.8433 - recall: 0.4815 - val_loss: 0.4835 - val_precision: 0.7971 - val_recall: 0.4819\n",
      "Epoch 8/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4627 - precision: 0.8413 - recall: 0.4965 - val_loss: 0.4796 - val_precision: 0.7989 - val_recall: 0.4801\n",
      "Epoch 9/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4570 - precision: 0.8496 - recall: 0.5006 - val_loss: 0.4894 - val_precision: 0.8121 - val_recall: 0.4853\n",
      "Epoch 10/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.5622 - precision: 0.8006 - recall: 0.4711 - val_loss: 0.5113 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 11/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.5047 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5090 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 12/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.5004 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5044 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 13/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4949 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.4974 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765551984.125623 3442771 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 7 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.5295 - precision: 0.7745 - recall: 0.4732 - val_loss: 0.5248 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 2/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.5127 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5159 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 3/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.5079 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5198 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 4/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4994 - precision: 0.8101 - recall: 0.4723 - val_loss: 0.6728 - val_precision: 0.6337 - val_recall: 0.2988\n",
      "Epoch 5/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4789 - precision: 0.8283 - recall: 0.4977 - val_loss: 0.4846 - val_precision: 0.7886 - val_recall: 0.4767\n",
      "Epoch 6/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4728 - precision: 0.8383 - recall: 0.4940 - val_loss: 0.4891 - val_precision: 0.7977 - val_recall: 0.4767\n",
      "Epoch 7/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4605 - precision: 0.8458 - recall: 0.4977 - val_loss: 0.4841 - val_precision: 0.8035 - val_recall: 0.4801\n",
      "Epoch 8/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4585 - precision: 0.8475 - recall: 0.5019 - val_loss: 0.4790 - val_precision: 0.8114 - val_recall: 0.4905\n",
      "Epoch 9/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4599 - precision: 0.8529 - recall: 0.4969 - val_loss: 0.4832 - val_precision: 0.7899 - val_recall: 0.4870\n",
      "Epoch 10/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4524 - precision: 0.8531 - recall: 0.5077 - val_loss: 0.4731 - val_precision: 0.8169 - val_recall: 0.5009\n",
      "Epoch 11/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4478 - precision: 0.8589 - recall: 0.5094 - val_loss: 0.4743 - val_precision: 0.8208 - val_recall: 0.4905\n",
      "Epoch 12/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.4453 - precision: 0.8458 - recall: 0.5135 - val_loss: 0.4716 - val_precision: 0.8295 - val_recall: 0.4957\n",
      "Epoch 13/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.4443 - precision: 0.8396 - recall: 0.5206 - val_loss: 0.4585 - val_precision: 0.8413 - val_recall: 0.4853\n",
      "Epoch 14/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4375 - precision: 0.8229 - recall: 0.5452 - val_loss: 0.4497 - val_precision: 0.8319 - val_recall: 0.5130\n",
      "Epoch 15/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4310 - precision: 0.8181 - recall: 0.5522 - val_loss: 0.4506 - val_precision: 0.8005 - val_recall: 0.5406\n",
      "Epoch 16/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4292 - precision: 0.8247 - recall: 0.5522 - val_loss: 0.4547 - val_precision: 0.8391 - val_recall: 0.5043\n",
      "Epoch 17/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4219 - precision: 0.8091 - recall: 0.5680 - val_loss: 0.4454 - val_precision: 0.7862 - val_recall: 0.5717\n",
      "Epoch 18/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4101 - precision: 0.8134 - recall: 0.5859 - val_loss: 0.4339 - val_precision: 0.7880 - val_recall: 0.5907\n",
      "Epoch 19/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3994 - precision: 0.8035 - recall: 0.6092 - val_loss: 0.4247 - val_precision: 0.7433 - val_recall: 0.6252\n",
      "Epoch 20/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3993 - precision: 0.7959 - recall: 0.6263 - val_loss: 0.4163 - val_precision: 0.7546 - val_recall: 0.6425\n",
      "Epoch 21/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3854 - precision: 0.7969 - recall: 0.6434 - val_loss: 0.4201 - val_precision: 0.7148 - val_recall: 0.6753\n",
      "Epoch 22/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3808 - precision: 0.7992 - recall: 0.6575 - val_loss: 0.4109 - val_precision: 0.7560 - val_recall: 0.6580\n",
      "Epoch 23/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3737 - precision: 0.7994 - recall: 0.6733 - val_loss: 0.4110 - val_precision: 0.7470 - val_recall: 0.6477\n",
      "Epoch 24/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3694 - precision: 0.7973 - recall: 0.6729 - val_loss: 0.4118 - val_precision: 0.7374 - val_recall: 0.6304\n",
      "Epoch 25/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3654 - precision: 0.8044 - recall: 0.6829 - val_loss: 0.4057 - val_precision: 0.7475 - val_recall: 0.6442\n",
      "Epoch 26/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3591 - precision: 0.8127 - recall: 0.6862 - val_loss: 0.4011 - val_precision: 0.7631 - val_recall: 0.6563\n",
      "Epoch 27/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3521 - precision: 0.8123 - recall: 0.7079 - val_loss: 0.3965 - val_precision: 0.7660 - val_recall: 0.6615\n",
      "Epoch 28/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3486 - precision: 0.8104 - recall: 0.6954 - val_loss: 0.3913 - val_precision: 0.7703 - val_recall: 0.6718\n",
      "Epoch 29/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3514 - precision: 0.8074 - recall: 0.7029 - val_loss: 0.3877 - val_precision: 0.7509 - val_recall: 0.6978\n",
      "Epoch 30/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3399 - precision: 0.8201 - recall: 0.7170 - val_loss: 0.3885 - val_precision: 0.7457 - val_recall: 0.6788\n",
      "Epoch 31/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3289 - precision: 0.8233 - recall: 0.7291 - val_loss: 0.3737 - val_precision: 0.7675 - val_recall: 0.7012\n",
      "Epoch 32/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3194 - precision: 0.8226 - recall: 0.7333 - val_loss: 0.3754 - val_precision: 0.7702 - val_recall: 0.7237\n",
      "Epoch 33/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3133 - precision: 0.8296 - recall: 0.7457 - val_loss: 0.3862 - val_precision: 0.7615 - val_recall: 0.7168\n",
      "Epoch 34/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3139 - precision: 0.8229 - recall: 0.7445 - val_loss: 0.3725 - val_precision: 0.7623 - val_recall: 0.7202\n",
      "Epoch 35/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.3030 - precision: 0.8307 - recall: 0.7578 - val_loss: 0.3798 - val_precision: 0.7576 - val_recall: 0.7288\n",
      "Epoch 36/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2989 - precision: 0.8402 - recall: 0.7615 - val_loss: 0.3512 - val_precision: 0.7815 - val_recall: 0.7168\n",
      "Epoch 37/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2952 - precision: 0.8420 - recall: 0.7649 - val_loss: 0.3516 - val_precision: 0.7786 - val_recall: 0.7168\n",
      "Epoch 38/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2981 - precision: 0.8345 - recall: 0.7620 - val_loss: 0.3768 - val_precision: 0.7628 - val_recall: 0.6943\n",
      "Epoch 39/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2952 - precision: 0.8464 - recall: 0.7661 - val_loss: 0.3466 - val_precision: 0.8074 - val_recall: 0.6805\n",
      "Epoch 40/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2818 - precision: 0.8522 - recall: 0.7824 - val_loss: 0.3501 - val_precision: 0.7869 - val_recall: 0.7081\n",
      "Epoch 41/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2802 - precision: 0.8522 - recall: 0.7849 - val_loss: 0.3410 - val_precision: 0.7828 - val_recall: 0.7409\n",
      "Epoch 42/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2715 - precision: 0.8517 - recall: 0.7911 - val_loss: 0.3590 - val_precision: 0.7748 - val_recall: 0.7427\n",
      "Epoch 43/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2720 - precision: 0.8518 - recall: 0.7894 - val_loss: 0.3532 - val_precision: 0.7589 - val_recall: 0.7720\n",
      "Epoch 44/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2646 - precision: 0.8540 - recall: 0.7986 - val_loss: 0.3389 - val_precision: 0.7535 - val_recall: 0.7444\n",
      "Epoch 45/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2561 - precision: 0.8652 - recall: 0.8065 - val_loss: 0.3572 - val_precision: 0.7671 - val_recall: 0.7565\n",
      "Epoch 46/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2512 - precision: 0.8630 - recall: 0.8177 - val_loss: 0.3569 - val_precision: 0.7649 - val_recall: 0.7530\n",
      "Epoch 47/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2513 - precision: 0.8642 - recall: 0.8156 - val_loss: 0.3797 - val_precision: 0.7826 - val_recall: 0.7150\n",
      "Epoch 48/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.2501 - precision: 0.8601 - recall: 0.8161 - val_loss: 0.3663 - val_precision: 0.7713 - val_recall: 0.7340\n",
      "Epoch 49/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.2439 - precision: 0.8669 - recall: 0.8211 - val_loss: 0.3655 - val_precision: 0.7670 - val_recall: 0.7219\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765552163.072640 3442771 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 999 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.5268 - precision: 0.8018 - recall: 0.4698 - val_loss: 0.5156 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 2/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.5115 - precision: 0.8075 - recall: 0.4732 - val_loss: 0.5110 - val_precision: 0.7756 - val_recall: 0.4715\n",
      "Epoch 3/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4830 - precision: 0.8345 - recall: 0.4806 - val_loss: 0.4837 - val_precision: 0.7915 - val_recall: 0.4853\n",
      "Epoch 4/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4718 - precision: 0.8351 - recall: 0.4952 - val_loss: 0.5065 - val_precision: 0.7837 - val_recall: 0.4819\n",
      "Epoch 5/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4644 - precision: 0.8436 - recall: 0.4960 - val_loss: 0.4759 - val_precision: 0.8033 - val_recall: 0.5009\n",
      "Epoch 6/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.4592 - precision: 0.8495 - recall: 0.4981 - val_loss: 0.4729 - val_precision: 0.8083 - val_recall: 0.5026\n",
      "Epoch 7/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4568 - precision: 0.8507 - recall: 0.4981 - val_loss: 0.4708 - val_precision: 0.8006 - val_recall: 0.4991\n",
      "Epoch 8/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4563 - precision: 0.8537 - recall: 0.5002 - val_loss: 0.4689 - val_precision: 0.7973 - val_recall: 0.5026\n",
      "Epoch 9/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4561 - precision: 0.8539 - recall: 0.4985 - val_loss: 0.4636 - val_precision: 0.8089 - val_recall: 0.5043\n",
      "Epoch 10/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4474 - precision: 0.8607 - recall: 0.5065 - val_loss: 0.4576 - val_precision: 0.8151 - val_recall: 0.5026\n",
      "Epoch 11/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4420 - precision: 0.8653 - recall: 0.5081 - val_loss: 0.4509 - val_precision: 0.8154 - val_recall: 0.5112\n",
      "Epoch 12/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4322 - precision: 0.8449 - recall: 0.5372 - val_loss: 0.4463 - val_precision: 0.7795 - val_recall: 0.5924\n",
      "Epoch 13/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.4228 - precision: 0.8169 - recall: 0.5809 - val_loss: 0.4448 - val_precision: 0.7314 - val_recall: 0.6114\n",
      "Epoch 14/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4187 - precision: 0.8110 - recall: 0.5822 - val_loss: 0.4343 - val_precision: 0.7548 - val_recall: 0.6166\n",
      "Epoch 15/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4161 - precision: 0.8053 - recall: 0.5868 - val_loss: 0.4410 - val_precision: 0.7206 - val_recall: 0.6235\n",
      "Epoch 16/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.4103 - precision: 0.8059 - recall: 0.5959 - val_loss: 0.4356 - val_precision: 0.7365 - val_recall: 0.6131\n",
      "Epoch 17/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4093 - precision: 0.8125 - recall: 0.6005 - val_loss: 0.4332 - val_precision: 0.7671 - val_recall: 0.6200\n",
      "Epoch 18/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.4046 - precision: 0.8154 - recall: 0.6009 - val_loss: 0.4274 - val_precision: 0.7292 - val_recall: 0.6373\n",
      "Epoch 19/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3986 - precision: 0.8076 - recall: 0.6113 - val_loss: 0.4248 - val_precision: 0.7450 - val_recall: 0.6408\n",
      "Epoch 20/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3961 - precision: 0.8144 - recall: 0.6155 - val_loss: 0.4178 - val_precision: 0.7586 - val_recall: 0.6459\n",
      "Epoch 21/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3903 - precision: 0.8112 - recall: 0.6259 - val_loss: 0.4147 - val_precision: 0.7376 - val_recall: 0.6701\n",
      "Epoch 22/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.3795 - precision: 0.8195 - recall: 0.6442 - val_loss: 0.4023 - val_precision: 0.7970 - val_recall: 0.6511\n",
      "Epoch 23/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.3732 - precision: 0.8154 - recall: 0.6600 - val_loss: 0.4017 - val_precision: 0.7849 - val_recall: 0.6304\n",
      "Epoch 24/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3685 - precision: 0.8191 - recall: 0.6783 - val_loss: 0.3936 - val_precision: 0.7571 - val_recall: 0.6943\n",
      "Epoch 25/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3598 - precision: 0.8127 - recall: 0.6900 - val_loss: 0.3823 - val_precision: 0.8038 - val_recall: 0.6511\n",
      "Epoch 26/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3482 - precision: 0.8217 - recall: 0.6979 - val_loss: 0.3787 - val_precision: 0.8075 - val_recall: 0.6667\n",
      "Epoch 27/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3450 - precision: 0.8236 - recall: 0.7033 - val_loss: 0.3746 - val_precision: 0.8038 - val_recall: 0.6649\n",
      "Epoch 28/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.3475 - precision: 0.8210 - recall: 0.7041 - val_loss: 0.3725 - val_precision: 0.8170 - val_recall: 0.6477\n",
      "Epoch 29/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3420 - precision: 0.8281 - recall: 0.7074 - val_loss: 0.3730 - val_precision: 0.7824 - val_recall: 0.6891\n",
      "Epoch 30/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.3377 - precision: 0.8231 - recall: 0.7066 - val_loss: 0.3755 - val_precision: 0.7658 - val_recall: 0.6891\n",
      "Epoch 31/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3281 - precision: 0.8276 - recall: 0.7233 - val_loss: 0.3666 - val_precision: 0.7616 - val_recall: 0.7116\n",
      "Epoch 32/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.3226 - precision: 0.8267 - recall: 0.7345 - val_loss: 0.3658 - val_precision: 0.7658 - val_recall: 0.7116\n",
      "Epoch 33/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.3141 - precision: 0.8267 - recall: 0.7466 - val_loss: 0.3683 - val_precision: 0.7652 - val_recall: 0.6978\n",
      "Epoch 34/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3117 - precision: 0.8271 - recall: 0.7507 - val_loss: 0.3631 - val_precision: 0.7514 - val_recall: 0.7202\n",
      "Epoch 35/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.3037 - precision: 0.8378 - recall: 0.7628 - val_loss: 0.3586 - val_precision: 0.7805 - val_recall: 0.7185\n",
      "Epoch 36/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2998 - precision: 0.8388 - recall: 0.7624 - val_loss: 0.3536 - val_precision: 0.7856 - val_recall: 0.7150\n",
      "Epoch 37/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.2945 - precision: 0.8389 - recall: 0.7695 - val_loss: 0.3672 - val_precision: 0.7748 - val_recall: 0.7012\n",
      "Epoch 38/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2955 - precision: 0.8329 - recall: 0.7653 - val_loss: 0.3664 - val_precision: 0.7910 - val_recall: 0.6995\n",
      "Epoch 39/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.2891 - precision: 0.8415 - recall: 0.7732 - val_loss: 0.3585 - val_precision: 0.7813 - val_recall: 0.7219\n",
      "Epoch 40/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.2851 - precision: 0.8456 - recall: 0.7749 - val_loss: 0.3662 - val_precision: 0.7663 - val_recall: 0.7306\n",
      "Epoch 41/120\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.2820 - precision: 0.8481 - recall: 0.7786 - val_loss: 0.3690 - val_precision: 0.7738 - val_recall: 0.7150\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765552309.870287 3442771 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "dataset, annotation=load_dataset()\n",
    "x_train,y_train, x_test, y_test=dataset_modelling(dataset, annotation)\n",
    "\n",
    "\n",
    "for seed in SEEDS:\n",
    "    bestf1=0\n",
    "    all_results = []\n",
    "\n",
    "    print(f\"\\n ================== INIZIO CICLO CON SEED: {seed} ================== \")\n",
    "\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    reset_seeds(seed)\n",
    "    model=build_model()\n",
    "\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                        tf.keras.metrics.Recall(name='recall'),\n",
    "                        ])\n",
    "    early_stop=EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "    reset_seeds(seed)\n",
    "    #class_weights_dict=compute_class_weight(y_train)\n",
    "    history=model.fit(\n",
    "        x_train,y_train,\n",
    "        epochs=120,\n",
    "        batch_size=16, \n",
    "        validation_split=0.2, \n",
    "        callbacks=[early_stop]\n",
    "        )\n",
    "\n",
    "    y_pred=model.predict(x_test)\n",
    "    predictions_binary = (y_pred > 0.5).astype(int)\n",
    "    target_names = ['goalpost','ball','robot','goalspot','centerspot']\n",
    "    report_dict = classification_report(y_test, predictions_binary, target_names=target_names, output_dict=True)\n",
    "    f1_macro = report_dict['macro avg']['f1-score']\n",
    "    \n",
    "\n",
    "    df_report = pd.DataFrame(report_dict).transpose()\n",
    "    df_report = df_report.round(2)\n",
    "    df_report['support'] = df_report['support'].astype(int)\n",
    "    csv_path = f'csv/report/report_7dyn_{seed}.csv'\n",
    "    df_report.to_csv(csv_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, input_image):\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n",
    "    layer_names = [layer.name for layer in model.layers if 'conv' in layer.name]\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    img_batch = np.expand_dims(input_image, axis=0)\n",
    "    activations = activation_model.predict(img_batch)\n",
    "    images_per_row = 16\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # layer_activation ha shape (1, H, W, Num_Filtri)\n",
    "        n_features = layer_activation.shape[-1] # Numero di filtri (es. 32, 64...)\n",
    "        size_h = layer_activation.shape[1]      # Altezza feature map\n",
    "        size_w = layer_activation.shape[2]\n",
    "        # Limitiamo a 64 feature per non intasare il grafico se il layer è profondo\n",
    "        n_features = min(n_features, 32) \n",
    "        n_cols = n_features // images_per_row\n",
    "        \n",
    "        if n_cols == 0: n_cols = 1 # Sicurezza\n",
    "        \n",
    "        # Griglia vuota per l'immagine finale\n",
    "        display_grid = np.zeros((size_h * n_cols, images_per_row * size_w))\n",
    "        \n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "                \n",
    "                # Post-process per renderla visibile (normalizzazione)\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= (channel_image.std() + 1e-5) # Evita div by zero\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                \n",
    "                # Inseriamo nella griglia\n",
    "                display_grid[col * size_h : (col + 1) * size_h,\n",
    "                             row * size_w : (row + 1) * size_w] = channel_image\n",
    "\n",
    "        # Plotting\n",
    "        scale = 1. / size_h\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(f\"Layer: {layer_name} ({n_features} feature maps)\")\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.savefig('images/feature_map/data_aug_fnb.jpg', bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "index_ball = np.where(y_test[:, 1] == 1)[0][0] \n",
    "img_to_test = x_test[index_ball]\n",
    "# 2. Visualizza cosa vede la rete\n",
    "visualize_feature_maps(model, img_to_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
