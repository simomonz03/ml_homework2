{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782da64b",
   "metadata": {},
   "source": [
    "IMPORT AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3282f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765551576.621140 3441118 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1765551576.645494 3441118 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765551577.209768 3441118 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.0-dev20251210\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✅ Op Determinism Abilitato!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765551577.864879 3441118 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"✅ Op Determinism Abilitato!\")\n",
    "except AttributeError:\n",
    "    print(\"⚠️ Attenzione: La tua versione di TF è troppo vecchia per enable_op_determinism.\")\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "SEEDS = [555, 123,42,7,999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65e287",
   "metadata": {},
   "source": [
    "DATASET LOADING AND MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    folder='dataset/images'\n",
    "    data=[]\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path=os.path.join(folder,filename)\n",
    "        img=cv2.imread(img_path) #opencv save in bgr\n",
    "        data.append({\n",
    "            'image':img,\n",
    "            'filename':filename\n",
    "        })\n",
    "\n",
    "    print(len(data),'images loaded')\n",
    "    print('file name is: ',data[0]['filename'], 'shape of the image is:  ', data[0]['image'].shape )\n",
    "\n",
    "    label=pd.read_csv('dataset/raw/bbx_annotations.csv')\n",
    "    print(label.shape, label.iloc[0]['filename'])\n",
    "    #images order is random, and for 1 image you can have more class\n",
    "\n",
    "    print('we have', len(label['class'].unique()), 'different classes')\n",
    "\n",
    "    #replace biggger img with half sized ones\n",
    "    #cv2.imwrite('resize_image/last_img_pre_downsampling.jpg',data[-100]['image'])\n",
    "    for i,item in enumerate(data):\n",
    "        if \"upper\" in item[\"filename\"].lower():\n",
    "            data[i]['image']=cv2.resize(\n",
    "                data[i]['image'],\n",
    "                (data[i]['image'].shape[1]//2,data[i]['image'].shape[0]//2)\n",
    "                ,interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    #cv2.imwrite('resize_image/last_img_post_downsampling.jpg',data[-100]['image'])\n",
    "       \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea259a97",
   "metadata": {},
   "source": [
    "FROM THE PURE DATASET TO THE TRAIN AND TEST DATA AND LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e35d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_modelling(dataset,annotation):   \n",
    "    dataset_df = pd.DataFrame(dataset) \n",
    "    label_map={'goalpost':0,\n",
    "               'ball':1,\n",
    "               'robot':2,\n",
    "               'goalspot':3,\n",
    "               'centerspot':4}\n",
    "    def get_vector(classes_found):\n",
    "        vec=np.zeros(5,dtype=int)\n",
    "\n",
    "        for c in classes_found:\n",
    "            if c in label_map:\n",
    "                vec[label_map[c]]=1\n",
    "        return list(vec)\n",
    "    \n",
    "    grouped = annotation.groupby('filename')['class'].apply(list).reset_index()\n",
    "    grouped['label']=grouped['class'].apply(get_vector)\n",
    "    final_annotation=grouped[['filename','label']]\n",
    "\n",
    "    final_dataset= pd.merge(dataset_df, final_annotation[['filename', 'label']], on='filename', how='inner')\n",
    "    final_dataset.to_csv('csv/temp/final_dataset.csv')\n",
    "    final_dataset=final_dataset.drop(columns=['filename'])\n",
    "    df_train, df_test = train_test_split(final_dataset, test_size=0.2, random_state=42)\n",
    "    x_train = np.array(df_train['image'].tolist()).astype('float32') /255.0\n",
    "    y_train = np.array(df_train['label'].tolist()).astype('float32')\n",
    "    \n",
    "    x_test = np.array(df_test['image'].tolist()).astype('float32') / 255.0\n",
    "    y_test = np.array(df_test['label'].tolist()).astype('float32')\n",
    "    return x_train, y_train,x_test,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f862c6d",
   "metadata": {},
   "source": [
    "DOUBLING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_set(x_train,y_train,aug_type):\n",
    "    rng = np.random.RandomState(42)    \n",
    "    if aug_type=='flip':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        x_train_aug = np.concatenate([x_train, x_flipped], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train, y_flipped], axis=0)\n",
    "    elif aug_type=='noise':\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        x_train_aug = np.concatenate([x_train, x_noisy], axis=0)\n",
    "        y_noise = y_train\n",
    "        y_train_aug = np.concatenate([y_train, y_noise], axis=0)\n",
    "    elif aug_type=='both':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        y_noise = y_train\n",
    "        x_train_aug = np.concatenate([x_train,x_flipped, x_noisy], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train,y_flipped, y_noise], axis=0)\n",
    "\n",
    "    #avoid to have all noisy data in validation--> shuffle\n",
    "    indices = np.arange(x_train_aug.shape[0])\n",
    "    rng.shuffle(indices)\n",
    "    x_train_aug = x_train_aug[indices]\n",
    "    y_train_aug = y_train_aug[indices]\n",
    "\n",
    "    return x_train_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b40f52",
   "metadata": {},
   "source": [
    "MODEL BUILIDNG, \n",
    "kernel dimesnsion, pooling dimension, fc layers dimension, number of conv layer and learning rate have different combination.\n",
    "instead, i fixed:\n",
    "pooling stride=2 \n",
    "pooling type: avg pooling\n",
    "number of kernel per layer: 16, 32, 64...\n",
    "last pooling: glob avg pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(240,320,3)))\n",
    "    model.add(layers.RandomFlip(\"horizontal\"))\n",
    "    model.add(layers.GaussianNoise(0.05))\n",
    "\n",
    "    for i in range(4):\n",
    "        kernel_number=16*(2**i)\n",
    "        model.add(layers.Conv2D(kernel_number,(7,7),activation='relu',padding='same'))\n",
    "        model.add(layers.AveragePooling2D((3,3),strides=2,padding='same'))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a2e85",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee23710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452 images loaded\n",
      "file name is:  lower_100056_jpg.rf.ec9852c66b4eee4a185317210a378f16.jpg shape of the image is:   (240, 320, 3)\n",
      "(8125, 8) upper_604302_jpg.rf.6215ee30a829ec658154eb4d067dfdf5.jpg\n",
      "we have 5 different classes\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 555 ================== \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765551579.893928 3441118 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1765551579.990758 3441118 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1348 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765551591.623091 3441272 bfc_allocator.cc:502] Allocator (GPU_0_bfc) ran out of memory trying to allocate 14.06MiB (rounded to 14745600)requested by op SameWorkerRecvDone\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "I0000 00:00:1765551591.623152 3441272 bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc\n",
      "I0000 00:00:1765551591.623153 3441272 bfc_allocator.cc:1056] Bin (256): \tTotal Chunks: 47, Chunks in use: 47. 11.8KiB allocated for chunks. 11.8KiB in use in bin. 1.1KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623157 3441272 bfc_allocator.cc:1056] Bin (512): \tTotal Chunks: 8, Chunks in use: 8. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 3.2KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623159 3441272 bfc_allocator.cc:1056] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623161 3441272 bfc_allocator.cc:1056] Bin (2048): \tTotal Chunks: 2, Chunks in use: 2. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623162 3441272 bfc_allocator.cc:1056] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623164 3441272 bfc_allocator.cc:1056] Bin (8192): \tTotal Chunks: 2, Chunks in use: 2. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 18.4KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623166 3441272 bfc_allocator.cc:1056] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 27.5KiB allocated for chunks. 27.5KiB in use in bin. 27.5KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623167 3441272 bfc_allocator.cc:1056] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623169 3441272 bfc_allocator.cc:1056] Bin (65536): \tTotal Chunks: 5, Chunks in use: 5. 419.2KiB allocated for chunks. 419.2KiB in use in bin. 388.0KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623170 3441272 bfc_allocator.cc:1056] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623171 3441272 bfc_allocator.cc:1056] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 392.0KiB allocated for chunks. 392.0KiB in use in bin. 392.0KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623173 3441272 bfc_allocator.cc:1056] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 622.0KiB allocated for chunks. 622.0KiB in use in bin. 392.0KiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623174 3441272 bfc_allocator.cc:1056] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 2. 4.59MiB allocated for chunks. 3.06MiB in use in bin. 3.06MiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623176 3441272 bfc_allocator.cc:1056] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623177 3441272 bfc_allocator.cc:1056] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623178 3441272 bfc_allocator.cc:1056] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623180 3441272 bfc_allocator.cc:1056] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623181 3441272 bfc_allocator.cc:1056] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623182 3441272 bfc_allocator.cc:1056] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623184 3441272 bfc_allocator.cc:1056] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623185 3441272 bfc_allocator.cc:1056] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 1.31GiB allocated for chunks. 1.31GiB in use in bin. 1.21GiB client-requested in use in bin.\n",
      "I0000 00:00:1765551591.623187 3441272 bfc_allocator.cc:1072] Bin for 14.06MiB was 8.00MiB, Chunk State: \n",
      "I0000 00:00:1765551591.623189 3441272 bfc_allocator.cc:1085] Next region of size 1413677056\n",
      "I0000 00:00:1765551591.623194 3441272 bfc_allocator.cc:1105] InUse at 704a92000000 of size 1280 next 1\n",
      "I0000 00:00:1765551591.623195 3441272 bfc_allocator.cc:1105] InUse at 704a92000500 of size 256 next 2\n",
      "I0000 00:00:1765551591.623196 3441272 bfc_allocator.cc:1105] InUse at 704a92000600 of size 256 next 3\n",
      "I0000 00:00:1765551591.623197 3441272 bfc_allocator.cc:1105] InUse at 704a92000700 of size 256 next 4\n",
      "I0000 00:00:1765551591.623198 3441272 bfc_allocator.cc:1105] InUse at 704a92000800 of size 256 next 5\n",
      "I0000 00:00:1765551591.623199 3441272 bfc_allocator.cc:1105] InUse at 704a92000900 of size 256 next 6\n",
      "I0000 00:00:1765551591.623200 3441272 bfc_allocator.cc:1105] InUse at 704a92000a00 of size 256 next 7\n",
      "I0000 00:00:1765551591.623200 3441272 bfc_allocator.cc:1105] InUse at 704a92000b00 of size 256 next 9\n",
      "I0000 00:00:1765551591.623201 3441272 bfc_allocator.cc:1105] InUse at 704a92000c00 of size 256 next 10\n",
      "I0000 00:00:1765551591.623202 3441272 bfc_allocator.cc:1105] InUse at 704a92000d00 of size 256 next 8\n",
      "I0000 00:00:1765551591.623202 3441272 bfc_allocator.cc:1105] InUse at 704a92000e00 of size 256 next 11\n",
      "I0000 00:00:1765551591.623203 3441272 bfc_allocator.cc:1105] InUse at 704a92000f00 of size 256 next 16\n",
      "I0000 00:00:1765551591.623204 3441272 bfc_allocator.cc:1105] InUse at 704a92001000 of size 256 next 14\n",
      "I0000 00:00:1765551591.623205 3441272 bfc_allocator.cc:1105] InUse at 704a92001100 of size 256 next 15\n",
      "I0000 00:00:1765551591.623205 3441272 bfc_allocator.cc:1105] InUse at 704a92001200 of size 256 next 21\n",
      "I0000 00:00:1765551591.623206 3441272 bfc_allocator.cc:1105] InUse at 704a92001300 of size 256 next 19\n",
      "I0000 00:00:1765551591.623207 3441272 bfc_allocator.cc:1105] InUse at 704a92001400 of size 512 next 20\n",
      "I0000 00:00:1765551591.623208 3441272 bfc_allocator.cc:1105] InUse at 704a92001600 of size 256 next 26\n",
      "I0000 00:00:1765551591.623209 3441272 bfc_allocator.cc:1105] InUse at 704a92001700 of size 256 next 24\n",
      "I0000 00:00:1765551591.623209 3441272 bfc_allocator.cc:1105] InUse at 704a92001800 of size 512 next 25\n",
      "I0000 00:00:1765551591.623210 3441272 bfc_allocator.cc:1105] InUse at 704a92001a00 of size 512 next 29\n",
      "I0000 00:00:1765551591.623211 3441272 bfc_allocator.cc:1105] InUse at 704a92001c00 of size 256 next 30\n",
      "I0000 00:00:1765551591.623212 3441272 bfc_allocator.cc:1105] InUse at 704a92001d00 of size 256 next 32\n",
      "I0000 00:00:1765551591.623212 3441272 bfc_allocator.cc:1105] InUse at 704a92001e00 of size 256 next 31\n",
      "I0000 00:00:1765551591.623213 3441272 bfc_allocator.cc:1105] InUse at 704a92001f00 of size 256 next 36\n",
      "I0000 00:00:1765551591.623214 3441272 bfc_allocator.cc:1105] InUse at 704a92002000 of size 256 next 37\n",
      "I0000 00:00:1765551591.623214 3441272 bfc_allocator.cc:1105] InUse at 704a92002100 of size 256 next 35\n",
      "I0000 00:00:1765551591.623215 3441272 bfc_allocator.cc:1105] InUse at 704a92002200 of size 256 next 38\n",
      "I0000 00:00:1765551591.623216 3441272 bfc_allocator.cc:1105] InUse at 704a92002300 of size 256 next 41\n",
      "I0000 00:00:1765551591.623217 3441272 bfc_allocator.cc:1105] InUse at 704a92002400 of size 256 next 42\n",
      "I0000 00:00:1765551591.623217 3441272 bfc_allocator.cc:1105] InUse at 704a92002500 of size 256 next 43\n",
      "I0000 00:00:1765551591.623218 3441272 bfc_allocator.cc:1105] InUse at 704a92002600 of size 256 next 50\n",
      "I0000 00:00:1765551591.623219 3441272 bfc_allocator.cc:1105] InUse at 704a92002700 of size 256 next 45\n",
      "I0000 00:00:1765551591.623220 3441272 bfc_allocator.cc:1105] InUse at 704a92002800 of size 256 next 46\n",
      "I0000 00:00:1765551591.623221 3441272 bfc_allocator.cc:1105] InUse at 704a92002900 of size 256 next 47\n",
      "I0000 00:00:1765551591.623221 3441272 bfc_allocator.cc:1105] InUse at 704a92002a00 of size 256 next 49\n",
      "I0000 00:00:1765551591.623222 3441272 bfc_allocator.cc:1105] InUse at 704a92002b00 of size 512 next 52\n",
      "I0000 00:00:1765551591.623223 3441272 bfc_allocator.cc:1105] InUse at 704a92002d00 of size 256 next 54\n",
      "I0000 00:00:1765551591.623224 3441272 bfc_allocator.cc:1105] InUse at 704a92002e00 of size 256 next 56\n",
      "I0000 00:00:1765551591.623224 3441272 bfc_allocator.cc:1105] InUse at 704a92002f00 of size 256 next 57\n",
      "I0000 00:00:1765551591.623225 3441272 bfc_allocator.cc:1105] InUse at 704a92003000 of size 512 next 58\n",
      "I0000 00:00:1765551591.623226 3441272 bfc_allocator.cc:1105] InUse at 704a92003200 of size 256 next 59\n",
      "I0000 00:00:1765551591.623226 3441272 bfc_allocator.cc:1105] InUse at 704a92003300 of size 256 next 60\n",
      "I0000 00:00:1765551591.623227 3441272 bfc_allocator.cc:1105] InUse at 704a92003400 of size 256 next 61\n",
      "I0000 00:00:1765551591.623228 3441272 bfc_allocator.cc:1105] InUse at 704a92003500 of size 256 next 39\n",
      "I0000 00:00:1765551591.623229 3441272 bfc_allocator.cc:1105] InUse at 704a92003600 of size 2560 next 40\n",
      "I0000 00:00:1765551591.623230 3441272 bfc_allocator.cc:1105] InUse at 704a92004000 of size 2560 next 53\n",
      "I0000 00:00:1765551591.623230 3441272 bfc_allocator.cc:1105] InUse at 704a92004a00 of size 256 next 62\n",
      "I0000 00:00:1765551591.623231 3441272 bfc_allocator.cc:1105] InUse at 704a92004b00 of size 256 next 63\n",
      "I0000 00:00:1765551591.623232 3441272 bfc_allocator.cc:1105] InUse at 704a92004c00 of size 256 next 64\n",
      "I0000 00:00:1765551591.623233 3441272 bfc_allocator.cc:1105] InUse at 704a92004d00 of size 256 next 65\n",
      "I0000 00:00:1765551591.623233 3441272 bfc_allocator.cc:1105] InUse at 704a92004e00 of size 512 next 66\n",
      "I0000 00:00:1765551591.623234 3441272 bfc_allocator.cc:1105] InUse at 704a92005000 of size 512 next 67\n",
      "I0000 00:00:1765551591.623235 3441272 bfc_allocator.cc:1105] InUse at 704a92005200 of size 512 next 68\n",
      "I0000 00:00:1765551591.623235 3441272 bfc_allocator.cc:1105] InUse at 704a92005400 of size 256 next 69\n",
      "I0000 00:00:1765551591.623236 3441272 bfc_allocator.cc:1105] InUse at 704a92005500 of size 256 next 70\n",
      "I0000 00:00:1765551591.623237 3441272 bfc_allocator.cc:1105] InUse at 704a92005600 of size 256 next 71\n",
      "I0000 00:00:1765551591.623238 3441272 bfc_allocator.cc:1105] InUse at 704a92005700 of size 256 next 12\n",
      "I0000 00:00:1765551591.623239 3441272 bfc_allocator.cc:1105] InUse at 704a92005800 of size 9472 next 13\n",
      "I0000 00:00:1765551591.623240 3441272 bfc_allocator.cc:1105] InUse at 704a92007d00 of size 28160 next 48\n",
      "I0000 00:00:1765551591.623240 3441272 bfc_allocator.cc:1105] InUse at 704a9200eb00 of size 9472 next 44\n",
      "I0000 00:00:1765551591.623241 3441272 bfc_allocator.cc:1105] InUse at 704a92011000 of size 93440 next 33\n",
      "I0000 00:00:1765551591.623242 3441272 bfc_allocator.cc:1105] InUse at 704a92027d00 of size 69632 next 18\n",
      "I0000 00:00:1765551591.623243 3441272 bfc_allocator.cc:1105] InUse at 704a92038d00 of size 100352 next 17\n",
      "I0000 00:00:1765551591.623244 3441272 bfc_allocator.cc:1105] InUse at 704a92051500 of size 65536 next 34\n",
      "I0000 00:00:1765551591.623245 3441272 bfc_allocator.cc:1105] InUse at 704a92061500 of size 100352 next 55\n",
      "I0000 00:00:1765551591.623246 3441272 bfc_allocator.cc:1105] InUse at 704a92079d00 of size 636928 next 23\n",
      "I0000 00:00:1765551591.623247 3441272 bfc_allocator.cc:1105] InUse at 704a92115500 of size 401408 next 22\n",
      "I0000 00:00:1765551591.623248 3441272 bfc_allocator.cc:1105] InUse at 704a92177500 of size 1605632 next 51\n",
      "I0000 00:00:1765551591.623249 3441272 bfc_allocator.cc:1105] Free  at 704a922ff500 of size 1605632 next 28\n",
      "I0000 00:00:1765551591.623250 3441272 bfc_allocator.cc:1105] InUse at 704a92487500 of size 1605632 next 27\n",
      "I0000 00:00:1765551591.623251 3441272 bfc_allocator.cc:1105] InUse at 704a9260f500 of size 1407322880 next 18446744073709551615\n",
      "I0000 00:00:1765551591.623252 3441272 bfc_allocator.cc:1110]      Summary of in-use Chunks by size: \n",
      "I0000 00:00:1765551591.623253 3441272 bfc_allocator.cc:1113] 47 Chunks of size 256 totalling 11.8KiB\n",
      "I0000 00:00:1765551591.623256 3441272 bfc_allocator.cc:1113] 8 Chunks of size 512 totalling 4.0KiB\n",
      "I0000 00:00:1765551591.623257 3441272 bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "I0000 00:00:1765551591.623258 3441272 bfc_allocator.cc:1113] 2 Chunks of size 2560 totalling 5.0KiB\n",
      "I0000 00:00:1765551591.623259 3441272 bfc_allocator.cc:1113] 2 Chunks of size 9472 totalling 18.5KiB\n",
      "I0000 00:00:1765551591.623260 3441272 bfc_allocator.cc:1113] 1 Chunks of size 28160 totalling 27.5KiB\n",
      "I0000 00:00:1765551591.623261 3441272 bfc_allocator.cc:1113] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "I0000 00:00:1765551591.623262 3441272 bfc_allocator.cc:1113] 1 Chunks of size 69632 totalling 68.0KiB\n",
      "I0000 00:00:1765551591.623263 3441272 bfc_allocator.cc:1113] 1 Chunks of size 93440 totalling 91.2KiB\n",
      "I0000 00:00:1765551591.623264 3441272 bfc_allocator.cc:1113] 2 Chunks of size 100352 totalling 196.0KiB\n",
      "I0000 00:00:1765551591.623265 3441272 bfc_allocator.cc:1113] 1 Chunks of size 401408 totalling 392.0KiB\n",
      "I0000 00:00:1765551591.623266 3441272 bfc_allocator.cc:1113] 1 Chunks of size 636928 totalling 622.0KiB\n",
      "I0000 00:00:1765551591.623267 3441272 bfc_allocator.cc:1113] 2 Chunks of size 1605632 totalling 3.06MiB\n",
      "I0000 00:00:1765551591.623268 3441272 bfc_allocator.cc:1113] 1 Chunks of size 1407322880 totalling 1.31GiB\n",
      "I0000 00:00:1765551591.623269 3441272 bfc_allocator.cc:1117] Sum Total of in-use chunks: 1.31GiB\n",
      "I0000 00:00:1765551591.623270 3441272 bfc_allocator.cc:1119] Total bytes in pool: 1413677056 memory_limit_: 1413677056 available bytes: 0 curr_region_allocation_bytes_: 2827354112\n",
      "I0000 00:00:1765551591.623272 3441272 bfc_allocator.cc:1124] Stats: \n",
      "Limit:                      1413677056\n",
      "InUse:                      1412071424\n",
      "MaxInUse:                   1412071424\n",
      "NumAllocs:                         168\n",
      "MaxAllocSize:               1407322880\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "W0000 00:00:1765551591.623276 3441272 bfc_allocator.cc:513] *********************************************************************************************xxxxxxx\n",
      "I0000 00:00:1765551591.623293 3441272 local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;bfe4f8db11f768cb;/job:localhost/replica:0/task:0/device:GPU:0;edge_130_IteratorGetNext;0:0\n",
      "\t [[{{node IteratorGetNext/_2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n",
      "I0000 00:00:1765551591.623298 3441272 local_rendezvous.cc:430] Local rendezvous send item cancelled. Key hash: 830625773493952279\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m reset_seeds(seed)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#class_weights_dict=compute_class_weight(y_train)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m history=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m y_pred=model.predict(x_test)\n\u001b[32m     38\u001b[39m predictions_binary = (y_pred > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    913\u001b[39m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[32m    914\u001b[39m   filtered_flat_args = (\n\u001b[32m    915\u001b[39m       \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.unpack_inputs(\n\u001b[32m    916\u001b[39m           bound_args\n\u001b[32m    917\u001b[39m       )\n\u001b[32m    918\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    920\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[32m    925\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/tensorflow/python/framework/errors_impl.py:377\u001b[39m, in \u001b[36mResourceExhaustedError.__init__\u001b[39m\u001b[34m(self, node_def, op, message, *args)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrors.ResourceExhaustedError\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mResourceExhaustedError\u001b[39;00m(OpError):\n\u001b[32m    369\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Raised when some resource has been exhausted while running operation.\u001b[39;00m\n\u001b[32m    370\u001b[39m \n\u001b[32m    371\u001b[39m \u001b[33;03m  For example, this error might be raised if a per-user quota is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    374\u001b[39m \u001b[33;03m  size or reduce dimension size of model weights.\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_def, op, message, *args):\n\u001b[32m    378\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Creates a `ResourceExhaustedError`.\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m     \u001b[38;5;28msuper\u001b[39m(ResourceExhaustedError, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(node_def, op, message,\n\u001b[32m    380\u001b[39m                                                  RESOURCE_EXHAUSTED, *args)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "Normalization failed: type=ResourceExhaustedError args=(None, None, \"{{function_node __inference_multi_step_on_iterator_3143}} SameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;bfe4f8db11f768cb;/job:localhost/replica:0/task:0/device:GPU:0;edge_130_IteratorGetNext;0:0\\n\\t [[{{node IteratorGetNext/_2}}]]\\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\\n [Op:__inference_multi_step_on_iterator_3143]\", {})"
     ]
    }
   ],
   "source": [
    "dataset, annotation=load_dataset()\n",
    "x_train,y_train, x_test, y_test=dataset_modelling(dataset, annotation)\n",
    "\n",
    "\n",
    "for seed in SEEDS:\n",
    "    bestf1=0\n",
    "    all_results = []\n",
    "\n",
    "    print(f\"\\n ================== INIZIO CICLO CON SEED: {seed} ================== \")\n",
    "\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    reset_seeds(seed)\n",
    "    model=build_model()\n",
    "\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                        tf.keras.metrics.Recall(name='recall'),\n",
    "                        ])\n",
    "    early_stop=EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "    reset_seeds(seed)\n",
    "    #class_weights_dict=compute_class_weight(y_train)\n",
    "    history=model.fit(\n",
    "        x_train,y_train,\n",
    "        epochs=120,\n",
    "        batch_size=16, \n",
    "        validation_split=0.2, \n",
    "        callbacks=[early_stop]\n",
    "        )\n",
    "\n",
    "    y_pred=model.predict(x_test)\n",
    "    predictions_binary = (y_pred > 0.5).astype(int)\n",
    "    target_names = ['goalpost','ball','robot','goalspot','centerspot']\n",
    "    report_dict = classification_report(y_test, predictions_binary, target_names=target_names, output_dict=True)\n",
    "    f1_macro = report_dict['macro avg']['f1-score']\n",
    "    \n",
    "\n",
    "    df_report = pd.DataFrame(report_dict).transpose()\n",
    "    df_report = df_report.round(2)\n",
    "    df_report['support'] = df_report['support'].astype(int)\n",
    "    csv_path = f'csv/report/report_7dyn_{seed}.csv'\n",
    "    df_report.to_csv(csv_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
