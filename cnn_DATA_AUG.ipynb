{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782da64b",
   "metadata": {},
   "source": [
    "IMPORT AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3282f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765541482.225978 3263105 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "I0000 00:00:1765541482.257177 3263105 cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765541482.842511 3263105 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.0-dev20251210\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✅ Op Determinism Abilitato!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765541483.551869 3263105 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"✅ Op Determinism Abilitato!\")\n",
    "except AttributeError:\n",
    "    print(\"⚠️ Attenzione: La tua versione di TF è troppo vecchia per enable_op_determinism.\")\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "SEEDS = [555, 123]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65e287",
   "metadata": {},
   "source": [
    "DATASET LOADING AND MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    folder='dataset/images'\n",
    "    data=[]\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path=os.path.join(folder,filename)\n",
    "        img=cv2.imread(img_path) #opencv save in bgr\n",
    "        data.append({\n",
    "            'image':img,\n",
    "            'filename':filename\n",
    "        })\n",
    "\n",
    "    print(len(data),'images loaded')\n",
    "    print('file name is: ',data[0]['filename'], 'shape of the image is:  ', data[0]['image'].shape )\n",
    "\n",
    "    label=pd.read_csv('dataset/raw/bbx_annotations.csv')\n",
    "    print(label.shape, label.iloc[0]['filename'])\n",
    "    #images order is random, and for 1 image you can have more class\n",
    "\n",
    "    print('we have', len(label['class'].unique()), 'different classes')\n",
    "\n",
    "    #replace biggger img with half sized ones\n",
    "    #cv2.imwrite('resize_image/last_img_pre_downsampling.jpg',data[-100]['image'])\n",
    "    for i,item in enumerate(data):\n",
    "        if \"upper\" in item[\"filename\"].lower():\n",
    "            data[i]['image']=cv2.resize(\n",
    "                data[i]['image'],\n",
    "                (data[i]['image'].shape[1]//2,data[i]['image'].shape[0]//2)\n",
    "                ,interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    #cv2.imwrite('resize_image/last_img_post_downsampling.jpg',data[-100]['image'])\n",
    "       \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea259a97",
   "metadata": {},
   "source": [
    "FROM THE PURE DATASET TO THE TRAIN AND TEST DATA AND LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e35d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_modelling(dataset,annotation):   \n",
    "    dataset_df = pd.DataFrame(dataset) \n",
    "    label_map={'goalpost':0,\n",
    "               'ball':1,\n",
    "               'robot':2,\n",
    "               'goalspot':3,\n",
    "               'centerspot':4}\n",
    "    def get_vector(classes_found):\n",
    "        vec=np.zeros(5,dtype=int)\n",
    "\n",
    "        for c in classes_found:\n",
    "            if c in label_map:\n",
    "                vec[label_map[c]]=1\n",
    "        return list(vec)\n",
    "    \n",
    "    grouped = annotation.groupby('filename')['class'].apply(list).reset_index()\n",
    "    grouped['label']=grouped['class'].apply(get_vector)\n",
    "    final_annotation=grouped[['filename','label']]\n",
    "\n",
    "    final_dataset= pd.merge(dataset_df, final_annotation[['filename', 'label']], on='filename', how='inner')\n",
    "    final_dataset.to_csv('csv/temp/final_dataset.csv')\n",
    "    final_dataset=final_dataset.drop(columns=['filename'])\n",
    "    df_train, df_test = train_test_split(final_dataset, test_size=0.2, random_state=42)\n",
    "    x_train = np.array(df_train['image'].tolist()).astype('float32') /255.0\n",
    "    y_train = np.array(df_train['label'].tolist()).astype('float32')\n",
    "    \n",
    "    x_test = np.array(df_test['image'].tolist()).astype('float32') / 255.0\n",
    "    y_test = np.array(df_test['label'].tolist()).astype('float32')\n",
    "    return x_train, y_train,x_test,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f862c6d",
   "metadata": {},
   "source": [
    "DOUBLING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fa642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_set(x_train,y_train,aug_type):\n",
    "    rng = np.random.RandomState(42)    \n",
    "    if aug_type=='flip':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        x_train_aug = np.concatenate([x_train, x_flipped], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train, y_flipped], axis=0)\n",
    "    elif aug_type=='noise':\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        x_train_aug = np.concatenate([x_train, x_noisy], axis=0)\n",
    "        y_noise = y_train\n",
    "        y_train_aug = np.concatenate([y_train, y_noise], axis=0)\n",
    "    elif aug_type=='both':\n",
    "        x_flipped = np.flip(x_train, axis=2)\n",
    "        y_flipped = y_train\n",
    "        noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "        x_noisy = x_train + noise\n",
    "        x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "        y_noise = y_train\n",
    "        x_train_aug = np.concatenate([x_train,x_flipped, x_noisy], axis=0)\n",
    "        y_train_aug = np.concatenate([y_train,y_flipped, y_noise], axis=0)\n",
    "\n",
    "    #avoid to have all noisy data in validation--> shuffle\n",
    "    indices = np.arange(x_train_aug.shape[0])\n",
    "    rng.shuffle(indices)\n",
    "    x_train_aug = x_train_aug[indices]\n",
    "    y_train_aug = y_train_aug[indices]\n",
    "\n",
    "    return x_train_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecc971",
   "metadata": {},
   "source": [
    "CREATE ALL DIFFERENT COMBINATION OF HYPERPARAMETER, WITHOUT USING GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4e29b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparam_combination():\n",
    "    param_grid = {\n",
    "    'batch_size': [16],\n",
    "    'layer_number':[4,5],\n",
    "    'kernel_dim': [7],\n",
    "    'pool_dim': [3], \n",
    "    'lr': [0.0001,0.001],\n",
    "    'fc1' : [128],\n",
    "    'fc2': [128]     \n",
    "}\n",
    "\n",
    "    #every possible combination\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = list(itertools.product(*values))\n",
    "    combinations_dicts = [dict(zip(keys, v)) for v in combinations]\n",
    "    return combinations_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b40f52",
   "metadata": {},
   "source": [
    "MODEL BUILIDNG, \n",
    "kernel dimesnsion, pooling dimension, fc layers dimension, number of conv layer and learning rate have different combination.\n",
    "instead, i fixed:\n",
    "pooling stride=2 \n",
    "pooling type: avg pooling\n",
    "number of kernel per layer: 16, 32, 64...\n",
    "last pooling: glob avg pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layer_num,kernel_dim,pool_dim,fc1,fc2):\n",
    "    model=models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(240,320,3)))\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        kernel_number=16*(2**i)\n",
    "        model.add(layers.Conv2D(kernel_number,(kernel_dim,kernel_dim),activation='relu',padding='same'))\n",
    "        model.add(layers.AveragePooling2D((pool_dim,pool_dim),strides=2,padding='same'))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(fc1,activation='relu'))\n",
    "    model.add(layers.Dense(fc2,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7206a2",
   "metadata": {},
   "source": [
    "SAVING THE CSV FILE CONTAINING F1S OF EACH SEARCHED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f849a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_csv(report_dict,param,target_names,all_results,seed,aug_type):\n",
    "    current_result = param.copy()    \n",
    "    for class_name in target_names:\n",
    "        current_result[f'f1_{class_name}'] = report_dict[class_name]['f1-score']\n",
    "    current_result['f1_macro_avg'] = report_dict['macro avg']['f1-score']\n",
    "\n",
    "    all_results.append(current_result)\n",
    "    pd.DataFrame(all_results).to_csv(f'csv/f1_search/search6{aug_type}_{seed}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a2e85",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee23710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452 images loaded\n",
      "file name is:  lower_100056_jpg.rf.ec9852c66b4eee4a185317210a378f16.jpg shape of the image is:   (240, 320, 3)\n",
      "(8125, 8) upper_604302_jpg.rf.6215ee30a829ec658154eb4d067dfdf5.jpg\n",
      "we have 5 different classes\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 555 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1765541486.410533 3263105 gpu_device.cc:2456] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0a. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1765541486.488124 3263105 gpu_device.cc:2040] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9228 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5070, pci bus id: 0000:01:00.0, compute capability: 12.0a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765541488.824589 3263359 cuda_dnn.cc:461] Loaded cuDNN version 91600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 0.5225 - precision: 0.7941 - recall: 0.4733 - val_loss: 0.4999 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4643 - precision: 0.8266 - recall: 0.4956 - val_loss: 0.4669 - val_precision: 0.8548 - val_recall: 0.4761\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4481 - precision: 0.8358 - recall: 0.5034 - val_loss: 0.4570 - val_precision: 0.8542 - val_recall: 0.4835\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4379 - precision: 0.8334 - recall: 0.5118 - val_loss: 0.4463 - val_precision: 0.8563 - val_recall: 0.4917\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4299 - precision: 0.8160 - recall: 0.5385 - val_loss: 0.4387 - val_precision: 0.8592 - val_recall: 0.4983\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4234 - precision: 0.8141 - recall: 0.5511 - val_loss: 0.4316 - val_precision: 0.8527 - val_recall: 0.5256\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4173 - precision: 0.8098 - recall: 0.5617 - val_loss: 0.4265 - val_precision: 0.8510 - val_recall: 0.5512\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4123 - precision: 0.8088 - recall: 0.5705 - val_loss: 0.4217 - val_precision: 0.8489 - val_recall: 0.5561\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4075 - precision: 0.8113 - recall: 0.5734 - val_loss: 0.4170 - val_precision: 0.8579 - val_recall: 0.5479\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4021 - precision: 0.8107 - recall: 0.5829 - val_loss: 0.4129 - val_precision: 0.8581 - val_recall: 0.5536\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3976 - precision: 0.8157 - recall: 0.5878 - val_loss: 0.4074 - val_precision: 0.8541 - val_recall: 0.5602\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3936 - precision: 0.8113 - recall: 0.5943 - val_loss: 0.4034 - val_precision: 0.8685 - val_recall: 0.5503\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3887 - precision: 0.8133 - recall: 0.6012 - val_loss: 0.3998 - val_precision: 0.8761 - val_recall: 0.5545\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3839 - precision: 0.8131 - recall: 0.6061 - val_loss: 0.3946 - val_precision: 0.8730 - val_recall: 0.5726\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3802 - precision: 0.8149 - recall: 0.6096 - val_loss: 0.3911 - val_precision: 0.8676 - val_recall: 0.5949\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3780 - precision: 0.8131 - recall: 0.6126 - val_loss: 0.3886 - val_precision: 0.8671 - val_recall: 0.6031\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3728 - precision: 0.8134 - recall: 0.6227 - val_loss: 0.3833 - val_precision: 0.8676 - val_recall: 0.6056\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3687 - precision: 0.8125 - recall: 0.6330 - val_loss: 0.3832 - val_precision: 0.8490 - val_recall: 0.6172\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3668 - precision: 0.8128 - recall: 0.6368 - val_loss: 0.3798 - val_precision: 0.8513 - val_recall: 0.6328\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3634 - precision: 0.8147 - recall: 0.6420 - val_loss: 0.3758 - val_precision: 0.8477 - val_recall: 0.6337\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3605 - precision: 0.8113 - recall: 0.6479 - val_loss: 0.3742 - val_precision: 0.8351 - val_recall: 0.6436\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3577 - precision: 0.8103 - recall: 0.6551 - val_loss: 0.3708 - val_precision: 0.8446 - val_recall: 0.6502\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3537 - precision: 0.8106 - recall: 0.6618 - val_loss: 0.3688 - val_precision: 0.8358 - val_recall: 0.6592\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3504 - precision: 0.8119 - recall: 0.6658 - val_loss: 0.3642 - val_precision: 0.8368 - val_recall: 0.6601\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3471 - precision: 0.8129 - recall: 0.6686 - val_loss: 0.3624 - val_precision: 0.8386 - val_recall: 0.6601\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3442 - precision: 0.8151 - recall: 0.6734 - val_loss: 0.3597 - val_precision: 0.8316 - val_recall: 0.6683\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3405 - precision: 0.8143 - recall: 0.6799 - val_loss: 0.3574 - val_precision: 0.8335 - val_recall: 0.6650\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3375 - precision: 0.8166 - recall: 0.6860 - val_loss: 0.3542 - val_precision: 0.8364 - val_recall: 0.6667\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3347 - precision: 0.8210 - recall: 0.6932 - val_loss: 0.3535 - val_precision: 0.8298 - val_recall: 0.6840\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3318 - precision: 0.8198 - recall: 0.6959 - val_loss: 0.3516 - val_precision: 0.8260 - val_recall: 0.6856\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3289 - precision: 0.8225 - recall: 0.7010 - val_loss: 0.3481 - val_precision: 0.8259 - val_recall: 0.6889\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3264 - precision: 0.8215 - recall: 0.7060 - val_loss: 0.3473 - val_precision: 0.8302 - val_recall: 0.6898\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3221 - precision: 0.8280 - recall: 0.7123 - val_loss: 0.3434 - val_precision: 0.8373 - val_recall: 0.6881\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3186 - precision: 0.8281 - recall: 0.7176 - val_loss: 0.3410 - val_precision: 0.8407 - val_recall: 0.6881\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3159 - precision: 0.8286 - recall: 0.7233 - val_loss: 0.3371 - val_precision: 0.8400 - val_recall: 0.6889\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3135 - precision: 0.8329 - recall: 0.7247 - val_loss: 0.3395 - val_precision: 0.8430 - val_recall: 0.6823\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3102 - precision: 0.8335 - recall: 0.7290 - val_loss: 0.3320 - val_precision: 0.8525 - val_recall: 0.6964\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3064 - precision: 0.8358 - recall: 0.7346 - val_loss: 0.3287 - val_precision: 0.8543 - val_recall: 0.6964\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3040 - precision: 0.8382 - recall: 0.7367 - val_loss: 0.3295 - val_precision: 0.8468 - val_recall: 0.6980\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2996 - precision: 0.8376 - recall: 0.7443 - val_loss: 0.3254 - val_precision: 0.8634 - val_recall: 0.6988\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2958 - precision: 0.8377 - recall: 0.7496 - val_loss: 0.3217 - val_precision: 0.8592 - val_recall: 0.7046\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2921 - precision: 0.8413 - recall: 0.7563 - val_loss: 0.3189 - val_precision: 0.8586 - val_recall: 0.7013\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2887 - precision: 0.8445 - recall: 0.7609 - val_loss: 0.3154 - val_precision: 0.8527 - val_recall: 0.7071\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2852 - precision: 0.8453 - recall: 0.7656 - val_loss: 0.3125 - val_precision: 0.8535 - val_recall: 0.7162\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2823 - precision: 0.8462 - recall: 0.7664 - val_loss: 0.3124 - val_precision: 0.8532 - val_recall: 0.7096\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2792 - precision: 0.8473 - recall: 0.7708 - val_loss: 0.3100 - val_precision: 0.8584 - val_recall: 0.7104\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2777 - precision: 0.8484 - recall: 0.7750 - val_loss: 0.3092 - val_precision: 0.8610 - val_recall: 0.7054\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2746 - precision: 0.8530 - recall: 0.7769 - val_loss: 0.3082 - val_precision: 0.8619 - val_recall: 0.7054\n",
      "Epoch 49/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2724 - precision: 0.8524 - recall: 0.7805 - val_loss: 0.3066 - val_precision: 0.8633 - val_recall: 0.7087\n",
      "Epoch 50/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2690 - precision: 0.8561 - recall: 0.7837 - val_loss: 0.3060 - val_precision: 0.8591 - val_recall: 0.7195\n",
      "Epoch 51/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2673 - precision: 0.8552 - recall: 0.7832 - val_loss: 0.3042 - val_precision: 0.8640 - val_recall: 0.7178\n",
      "Epoch 52/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2640 - precision: 0.8580 - recall: 0.7883 - val_loss: 0.3009 - val_precision: 0.8567 - val_recall: 0.7252\n",
      "Epoch 53/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2617 - precision: 0.8601 - recall: 0.7906 - val_loss: 0.3005 - val_precision: 0.8631 - val_recall: 0.7178\n",
      "Epoch 54/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2595 - precision: 0.8595 - recall: 0.7931 - val_loss: 0.3003 - val_precision: 0.8619 - val_recall: 0.7211\n",
      "Epoch 55/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2560 - precision: 0.8648 - recall: 0.7969 - val_loss: 0.3002 - val_precision: 0.8632 - val_recall: 0.7236\n",
      "Epoch 56/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2539 - precision: 0.8626 - recall: 0.7980 - val_loss: 0.2983 - val_precision: 0.8637 - val_recall: 0.7269\n",
      "Epoch 57/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2518 - precision: 0.8654 - recall: 0.8026 - val_loss: 0.2972 - val_precision: 0.8609 - val_recall: 0.7351\n",
      "Epoch 58/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2503 - precision: 0.8661 - recall: 0.8056 - val_loss: 0.2974 - val_precision: 0.8654 - val_recall: 0.7318\n",
      "Epoch 59/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2468 - precision: 0.8691 - recall: 0.8102 - val_loss: 0.2959 - val_precision: 0.8602 - val_recall: 0.7409\n",
      "Epoch 60/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2447 - precision: 0.8709 - recall: 0.8106 - val_loss: 0.2927 - val_precision: 0.8627 - val_recall: 0.7467\n",
      "Epoch 61/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2420 - precision: 0.8715 - recall: 0.8119 - val_loss: 0.2909 - val_precision: 0.8624 - val_recall: 0.7550\n",
      "Epoch 62/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2403 - precision: 0.8707 - recall: 0.8131 - val_loss: 0.2921 - val_precision: 0.8569 - val_recall: 0.7459\n",
      "Epoch 63/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2380 - precision: 0.8719 - recall: 0.8176 - val_loss: 0.2890 - val_precision: 0.8582 - val_recall: 0.7541\n",
      "Epoch 64/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2353 - precision: 0.8764 - recall: 0.8192 - val_loss: 0.2883 - val_precision: 0.8545 - val_recall: 0.7558\n",
      "Epoch 65/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2335 - precision: 0.8744 - recall: 0.8232 - val_loss: 0.2882 - val_precision: 0.8504 - val_recall: 0.7550\n",
      "Epoch 66/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2313 - precision: 0.8765 - recall: 0.8245 - val_loss: 0.2861 - val_precision: 0.8512 - val_recall: 0.7599\n",
      "Epoch 67/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2277 - precision: 0.8767 - recall: 0.8272 - val_loss: 0.2840 - val_precision: 0.8524 - val_recall: 0.7673\n",
      "Epoch 68/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2256 - precision: 0.8779 - recall: 0.8304 - val_loss: 0.2805 - val_precision: 0.8518 - val_recall: 0.7731\n",
      "Epoch 69/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2233 - precision: 0.8774 - recall: 0.8342 - val_loss: 0.2808 - val_precision: 0.8570 - val_recall: 0.7715\n",
      "Epoch 70/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2211 - precision: 0.8806 - recall: 0.8369 - val_loss: 0.2809 - val_precision: 0.8599 - val_recall: 0.7698\n",
      "Epoch 71/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2195 - precision: 0.8800 - recall: 0.8346 - val_loss: 0.2807 - val_precision: 0.8549 - val_recall: 0.7731\n",
      "Epoch 72/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2176 - precision: 0.8812 - recall: 0.8401 - val_loss: 0.2826 - val_precision: 0.8558 - val_recall: 0.7690\n",
      "Epoch 73/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2153 - precision: 0.8833 - recall: 0.8428 - val_loss: 0.2803 - val_precision: 0.8549 - val_recall: 0.7731\n",
      "Epoch 74/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2162 - precision: 0.8801 - recall: 0.8403 - val_loss: 0.2774 - val_precision: 0.8567 - val_recall: 0.7698\n",
      "Epoch 75/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2145 - precision: 0.8827 - recall: 0.8411 - val_loss: 0.2791 - val_precision: 0.8567 - val_recall: 0.7649\n",
      "Epoch 76/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2127 - precision: 0.8832 - recall: 0.8418 - val_loss: 0.2726 - val_precision: 0.8638 - val_recall: 0.7690\n",
      "Epoch 77/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2123 - precision: 0.8832 - recall: 0.8462 - val_loss: 0.2759 - val_precision: 0.8625 - val_recall: 0.7715\n",
      "Epoch 78/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2104 - precision: 0.8877 - recall: 0.8468 - val_loss: 0.2719 - val_precision: 0.8671 - val_recall: 0.7698\n",
      "Epoch 79/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2084 - precision: 0.8852 - recall: 0.8502 - val_loss: 0.2761 - val_precision: 0.8617 - val_recall: 0.7607\n",
      "Epoch 80/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2060 - precision: 0.8876 - recall: 0.8523 - val_loss: 0.2734 - val_precision: 0.8557 - val_recall: 0.7682\n",
      "Epoch 81/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2032 - precision: 0.8890 - recall: 0.8531 - val_loss: 0.2693 - val_precision: 0.8607 - val_recall: 0.7748\n",
      "Epoch 82/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2004 - precision: 0.8915 - recall: 0.8537 - val_loss: 0.2714 - val_precision: 0.8553 - val_recall: 0.7706\n",
      "Epoch 83/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1987 - precision: 0.8890 - recall: 0.8561 - val_loss: 0.2702 - val_precision: 0.8586 - val_recall: 0.7764\n",
      "Epoch 84/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1972 - precision: 0.8913 - recall: 0.8575 - val_loss: 0.2670 - val_precision: 0.8617 - val_recall: 0.7863\n",
      "Epoch 85/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1937 - precision: 0.8917 - recall: 0.8607 - val_loss: 0.2635 - val_precision: 0.8665 - val_recall: 0.7871\n",
      "Epoch 86/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1925 - precision: 0.8923 - recall: 0.8611 - val_loss: 0.2637 - val_precision: 0.8596 - val_recall: 0.7929\n",
      "Epoch 87/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1903 - precision: 0.8954 - recall: 0.8643 - val_loss: 0.2588 - val_precision: 0.8617 - val_recall: 0.7970\n",
      "Epoch 88/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1892 - precision: 0.8925 - recall: 0.8632 - val_loss: 0.2613 - val_precision: 0.8582 - val_recall: 0.7937\n",
      "Epoch 89/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1870 - precision: 0.8945 - recall: 0.8655 - val_loss: 0.2568 - val_precision: 0.8624 - val_recall: 0.7913\n",
      "Epoch 90/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1865 - precision: 0.8955 - recall: 0.8655 - val_loss: 0.2569 - val_precision: 0.8653 - val_recall: 0.7896\n",
      "Epoch 91/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1865 - precision: 0.8954 - recall: 0.8685 - val_loss: 0.2556 - val_precision: 0.8667 - val_recall: 0.7937\n",
      "Epoch 92/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1866 - precision: 0.8970 - recall: 0.8651 - val_loss: 0.2559 - val_precision: 0.8678 - val_recall: 0.7904\n",
      "Epoch 93/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1872 - precision: 0.8961 - recall: 0.8655 - val_loss: 0.2532 - val_precision: 0.8700 - val_recall: 0.7954\n",
      "Epoch 94/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1871 - precision: 0.8985 - recall: 0.8664 - val_loss: 0.2506 - val_precision: 0.8669 - val_recall: 0.7954\n",
      "Epoch 95/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1882 - precision: 0.8961 - recall: 0.8693 - val_loss: 0.2538 - val_precision: 0.8719 - val_recall: 0.7921\n",
      "Epoch 96/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1857 - precision: 0.8975 - recall: 0.8697 - val_loss: 0.2537 - val_precision: 0.8762 - val_recall: 0.7822\n",
      "Epoch 97/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1814 - precision: 0.9010 - recall: 0.8735 - val_loss: 0.2547 - val_precision: 0.8668 - val_recall: 0.7896\n",
      "Epoch 98/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1795 - precision: 0.8997 - recall: 0.8777 - val_loss: 0.2565 - val_precision: 0.8624 - val_recall: 0.7962\n",
      "Epoch 99/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1770 - precision: 0.9037 - recall: 0.8771 - val_loss: 0.2558 - val_precision: 0.8707 - val_recall: 0.8003\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765542200.854899 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 0.5205 - precision: 0.7983 - recall: 0.4731 - val_loss: 0.5232 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.5076 - precision: 0.8022 - recall: 0.4754 - val_loss: 0.5131 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4864 - precision: 0.8123 - recall: 0.4817 - val_loss: 0.4827 - val_precision: 0.8565 - val_recall: 0.4579\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4659 - precision: 0.8338 - recall: 0.4910 - val_loss: 0.4718 - val_precision: 0.8437 - val_recall: 0.4719\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4597 - precision: 0.8371 - recall: 0.4996 - val_loss: 0.4665 - val_precision: 0.8434 - val_recall: 0.4843\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4554 - precision: 0.8407 - recall: 0.5074 - val_loss: 0.4629 - val_precision: 0.8419 - val_recall: 0.4876\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4937 - precision: 0.8204 - recall: 0.4952 - val_loss: 0.5175 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.5031 - precision: 0.8022 - recall: 0.4754 - val_loss: 0.5088 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4898 - precision: 0.8050 - recall: 0.4813 - val_loss: 0.4787 - val_precision: 0.8248 - val_recall: 0.4662\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4618 - precision: 0.8250 - recall: 0.5040 - val_loss: 0.4664 - val_precision: 0.8487 - val_recall: 0.4860\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4510 - precision: 0.8463 - recall: 0.5133 - val_loss: 0.4595 - val_precision: 0.8551 - val_recall: 0.4917\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4450 - precision: 0.8504 - recall: 0.5168 - val_loss: 0.4527 - val_precision: 0.8669 - val_recall: 0.4942\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4382 - precision: 0.8545 - recall: 0.5164 - val_loss: 0.4460 - val_precision: 0.8621 - val_recall: 0.4901\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4319 - precision: 0.8542 - recall: 0.5253 - val_loss: 0.4379 - val_precision: 0.8253 - val_recall: 0.5495\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4238 - precision: 0.8284 - recall: 0.5495 - val_loss: 0.4259 - val_precision: 0.7967 - val_recall: 0.5916\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4168 - precision: 0.8212 - recall: 0.5684 - val_loss: 0.4209 - val_precision: 0.7908 - val_recall: 0.5957\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4095 - precision: 0.8127 - recall: 0.5827 - val_loss: 0.4122 - val_precision: 0.7972 - val_recall: 0.6031\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4018 - precision: 0.8113 - recall: 0.5964 - val_loss: 0.4043 - val_precision: 0.8051 - val_recall: 0.6271\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3937 - precision: 0.8081 - recall: 0.6071 - val_loss: 0.3923 - val_precision: 0.8196 - val_recall: 0.6337\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3854 - precision: 0.8030 - recall: 0.6269 - val_loss: 0.3843 - val_precision: 0.8337 - val_recall: 0.6163\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3753 - precision: 0.8028 - recall: 0.6452 - val_loss: 0.3715 - val_precision: 0.8357 - val_recall: 0.6295\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3646 - precision: 0.8055 - recall: 0.6658 - val_loss: 0.3629 - val_precision: 0.8545 - val_recall: 0.6444\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3549 - precision: 0.8155 - recall: 0.6827 - val_loss: 0.3547 - val_precision: 0.8551 - val_recall: 0.6766\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3434 - precision: 0.8234 - recall: 0.6968 - val_loss: 0.3486 - val_precision: 0.8480 - val_recall: 0.6906\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3337 - precision: 0.8290 - recall: 0.7109 - val_loss: 0.3458 - val_precision: 0.8515 - val_recall: 0.6906\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3225 - precision: 0.8325 - recall: 0.7269 - val_loss: 0.3420 - val_precision: 0.8435 - val_recall: 0.6939\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3141 - precision: 0.8347 - recall: 0.7353 - val_loss: 0.3461 - val_precision: 0.8483 - val_recall: 0.6873\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3027 - precision: 0.8410 - recall: 0.7489 - val_loss: 0.3479 - val_precision: 0.8576 - val_recall: 0.6856\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2916 - precision: 0.8459 - recall: 0.7622 - val_loss: 0.3364 - val_precision: 0.8460 - val_recall: 0.6980\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2805 - precision: 0.8457 - recall: 0.7740 - val_loss: 0.3332 - val_precision: 0.8474 - val_recall: 0.7104\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2726 - precision: 0.8498 - recall: 0.7837 - val_loss: 0.3476 - val_precision: 0.8414 - val_recall: 0.7046\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2624 - precision: 0.8520 - recall: 0.7934 - val_loss: 0.3337 - val_precision: 0.8397 - val_recall: 0.7261\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2521 - precision: 0.8570 - recall: 0.8049 - val_loss: 0.3416 - val_precision: 0.8387 - val_recall: 0.7252\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2451 - precision: 0.8591 - recall: 0.8119 - val_loss: 0.3123 - val_precision: 0.8439 - val_recall: 0.7492\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2349 - precision: 0.8666 - recall: 0.8228 - val_loss: 0.3130 - val_precision: 0.8252 - val_recall: 0.7558\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2282 - precision: 0.8706 - recall: 0.8281 - val_loss: 0.2957 - val_precision: 0.8373 - val_recall: 0.7558\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2197 - precision: 0.8702 - recall: 0.8378 - val_loss: 0.2966 - val_precision: 0.8344 - val_recall: 0.7690\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2115 - precision: 0.8786 - recall: 0.8451 - val_loss: 0.2931 - val_precision: 0.8284 - val_recall: 0.8003\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2040 - precision: 0.8794 - recall: 0.8533 - val_loss: 0.2739 - val_precision: 0.8442 - val_recall: 0.8135\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1945 - precision: 0.8874 - recall: 0.8628 - val_loss: 0.2841 - val_precision: 0.8443 - val_recall: 0.8012\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1913 - precision: 0.8906 - recall: 0.8647 - val_loss: 0.2857 - val_precision: 0.8466 - val_recall: 0.8012\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1822 - precision: 0.8919 - recall: 0.8697 - val_loss: 0.2994 - val_precision: 0.8368 - val_recall: 0.7913\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1802 - precision: 0.8913 - recall: 0.8733 - val_loss: 0.3049 - val_precision: 0.8512 - val_recall: 0.7789\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1760 - precision: 0.8933 - recall: 0.8794 - val_loss: 0.3430 - val_precision: 0.8586 - val_recall: 0.7566\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765542520.505711 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5156 - precision: 0.8011 - recall: 0.4720 - val_loss: 0.4907 - val_precision: 0.9104 - val_recall: 0.4026\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4588 - precision: 0.8268 - recall: 0.4992 - val_loss: 0.4673 - val_precision: 0.8473 - val_recall: 0.4851\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4441 - precision: 0.8383 - recall: 0.5072 - val_loss: 0.4501 - val_precision: 0.8567 - val_recall: 0.4835\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4359 - precision: 0.8226 - recall: 0.5191 - val_loss: 0.4439 - val_precision: 0.8643 - val_recall: 0.4835\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4261 - precision: 0.8167 - recall: 0.5457 - val_loss: 0.4306 - val_precision: 0.8559 - val_recall: 0.4950\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4174 - precision: 0.8145 - recall: 0.5608 - val_loss: 0.4234 - val_precision: 0.8512 - val_recall: 0.5239\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4087 - precision: 0.8141 - recall: 0.5768 - val_loss: 0.4139 - val_precision: 0.8489 - val_recall: 0.5561\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4004 - precision: 0.8116 - recall: 0.5875 - val_loss: 0.4063 - val_precision: 0.8424 - val_recall: 0.5776\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3926 - precision: 0.8122 - recall: 0.5979 - val_loss: 0.4029 - val_precision: 0.8395 - val_recall: 0.5998\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3855 - precision: 0.8087 - recall: 0.6075 - val_loss: 0.4028 - val_precision: 0.8313 - val_recall: 0.6097\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3777 - precision: 0.8138 - recall: 0.6181 - val_loss: 0.3965 - val_precision: 0.8318 - val_recall: 0.6163\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3707 - precision: 0.8176 - recall: 0.6263 - val_loss: 0.3916 - val_precision: 0.8358 - val_recall: 0.6172\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3646 - precision: 0.8194 - recall: 0.6357 - val_loss: 0.3810 - val_precision: 0.8470 - val_recall: 0.6213\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3584 - precision: 0.8212 - recall: 0.6456 - val_loss: 0.3715 - val_precision: 0.8567 - val_recall: 0.6213\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3501 - precision: 0.8226 - recall: 0.6616 - val_loss: 0.3656 - val_precision: 0.8596 - val_recall: 0.6262\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3404 - precision: 0.8236 - recall: 0.6801 - val_loss: 0.3594 - val_precision: 0.8567 - val_recall: 0.6361\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3306 - precision: 0.8278 - recall: 0.6938 - val_loss: 0.3497 - val_precision: 0.8534 - val_recall: 0.6675\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3228 - precision: 0.8318 - recall: 0.7106 - val_loss: 0.3469 - val_precision: 0.8544 - val_recall: 0.6584\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3161 - precision: 0.8350 - recall: 0.7285 - val_loss: 0.3394 - val_precision: 0.8519 - val_recall: 0.6931\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3115 - precision: 0.8327 - recall: 0.7351 - val_loss: 0.3325 - val_precision: 0.8490 - val_recall: 0.6865\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3062 - precision: 0.8340 - recall: 0.7456 - val_loss: 0.3301 - val_precision: 0.8492 - val_recall: 0.7013\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2968 - precision: 0.8361 - recall: 0.7590 - val_loss: 0.3253 - val_precision: 0.8602 - val_recall: 0.6906\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2898 - precision: 0.8409 - recall: 0.7677 - val_loss: 0.3171 - val_precision: 0.8636 - val_recall: 0.7261\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2820 - precision: 0.8442 - recall: 0.7788 - val_loss: 0.3191 - val_precision: 0.8696 - val_recall: 0.7153\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2724 - precision: 0.8485 - recall: 0.7860 - val_loss: 0.3103 - val_precision: 0.8586 - val_recall: 0.7417\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2649 - precision: 0.8493 - recall: 0.7948 - val_loss: 0.3039 - val_precision: 0.8600 - val_recall: 0.7450\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2579 - precision: 0.8529 - recall: 0.8028 - val_loss: 0.3107 - val_precision: 0.8749 - val_recall: 0.7211\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2500 - precision: 0.8564 - recall: 0.8108 - val_loss: 0.2986 - val_precision: 0.8741 - val_recall: 0.7393\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2427 - precision: 0.8607 - recall: 0.8180 - val_loss: 0.2946 - val_precision: 0.8711 - val_recall: 0.7360\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2344 - precision: 0.8673 - recall: 0.8251 - val_loss: 0.2909 - val_precision: 0.8758 - val_recall: 0.7450\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2303 - precision: 0.8676 - recall: 0.8277 - val_loss: 0.2884 - val_precision: 0.8768 - val_recall: 0.7459\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2239 - precision: 0.8719 - recall: 0.8348 - val_loss: 0.2842 - val_precision: 0.8706 - val_recall: 0.7492\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2176 - precision: 0.8761 - recall: 0.8420 - val_loss: 0.2861 - val_precision: 0.8626 - val_recall: 0.7409\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2104 - precision: 0.8795 - recall: 0.8460 - val_loss: 0.2773 - val_precision: 0.8583 - val_recall: 0.7599\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2038 - precision: 0.8832 - recall: 0.8533 - val_loss: 0.2757 - val_precision: 0.8600 - val_recall: 0.7706\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2004 - precision: 0.8855 - recall: 0.8525 - val_loss: 0.2783 - val_precision: 0.8723 - val_recall: 0.7607\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1930 - precision: 0.8877 - recall: 0.8598 - val_loss: 0.2817 - val_precision: 0.8764 - val_recall: 0.7607\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1876 - precision: 0.8910 - recall: 0.8689 - val_loss: 0.2792 - val_precision: 0.8595 - val_recall: 0.7871\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1827 - precision: 0.8906 - recall: 0.8721 - val_loss: 0.2860 - val_precision: 0.8543 - val_recall: 0.7888\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1805 - precision: 0.8906 - recall: 0.8756 - val_loss: 0.2879 - val_precision: 0.8428 - val_recall: 0.7921\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765542831.213084 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5204 - precision: 0.7711 - recall: 0.4813 - val_loss: 0.5315 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.5076 - precision: 0.8022 - recall: 0.4754 - val_loss: 0.5158 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4886 - precision: 0.8127 - recall: 0.4729 - val_loss: 0.4765 - val_precision: 0.8690 - val_recall: 0.4488\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4659 - precision: 0.8335 - recall: 0.4918 - val_loss: 0.4538 - val_precision: 0.8615 - val_recall: 0.5083\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4326 - precision: 0.8084 - recall: 0.5522 - val_loss: 0.4192 - val_precision: 0.8354 - val_recall: 0.5487\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4131 - precision: 0.7925 - recall: 0.5924 - val_loss: 0.4074 - val_precision: 0.8441 - val_recall: 0.5809\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3977 - precision: 0.7952 - recall: 0.6282 - val_loss: 0.3950 - val_precision: 0.8601 - val_recall: 0.5734\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3866 - precision: 0.8010 - recall: 0.6429 - val_loss: 0.3879 - val_precision: 0.8236 - val_recall: 0.6394\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3777 - precision: 0.8033 - recall: 0.6585 - val_loss: 0.3762 - val_precision: 0.8599 - val_recall: 0.6180\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3605 - precision: 0.8123 - recall: 0.6911 - val_loss: 0.3696 - val_precision: 0.8359 - val_recall: 0.6601\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3445 - precision: 0.8120 - recall: 0.7117 - val_loss: 0.3509 - val_precision: 0.8282 - val_recall: 0.6881\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3234 - precision: 0.8305 - recall: 0.7302 - val_loss: 0.3353 - val_precision: 0.8324 - val_recall: 0.7170\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3048 - precision: 0.8433 - recall: 0.7555 - val_loss: 0.3175 - val_precision: 0.8544 - val_recall: 0.7409\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2878 - precision: 0.8478 - recall: 0.7746 - val_loss: 0.3028 - val_precision: 0.8571 - val_recall: 0.7376\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2654 - precision: 0.8598 - recall: 0.7963 - val_loss: 0.2980 - val_precision: 0.8597 - val_recall: 0.7483\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2523 - precision: 0.8624 - recall: 0.8056 - val_loss: 0.2807 - val_precision: 0.8677 - val_recall: 0.7632\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2357 - precision: 0.8701 - recall: 0.8249 - val_loss: 0.2746 - val_precision: 0.8656 - val_recall: 0.7706\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2255 - precision: 0.8715 - recall: 0.8390 - val_loss: 0.2641 - val_precision: 0.8599 - val_recall: 0.8003\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2180 - precision: 0.8743 - recall: 0.8432 - val_loss: 0.2631 - val_precision: 0.8505 - val_recall: 0.8309\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2020 - precision: 0.8885 - recall: 0.8586 - val_loss: 0.2463 - val_precision: 0.8413 - val_recall: 0.8614\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1882 - precision: 0.8928 - recall: 0.8729 - val_loss: 0.2407 - val_precision: 0.8669 - val_recall: 0.8383\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1718 - precision: 0.9014 - recall: 0.8826 - val_loss: 0.2441 - val_precision: 0.8635 - val_recall: 0.8350\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1618 - precision: 0.9044 - recall: 0.8916 - val_loss: 0.2426 - val_precision: 0.8598 - val_recall: 0.8350\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1493 - precision: 0.9171 - recall: 0.9015 - val_loss: 0.2483 - val_precision: 0.8627 - val_recall: 0.8350\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1384 - precision: 0.9193 - recall: 0.9110 - val_loss: 0.2453 - val_precision: 0.8758 - val_recall: 0.8375\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1353 - precision: 0.9190 - recall: 0.9095 - val_loss: 0.2924 - val_precision: 0.8669 - val_recall: 0.8061\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765543035.839989 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "{'batch_size': 16, 'layer_number': 5, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 123 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.5099 - precision: 0.7977 - recall: 0.4722 - val_loss: 0.4752 - val_precision: 0.8110 - val_recall: 0.4992\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4575 - precision: 0.8373 - recall: 0.4971 - val_loss: 0.4665 - val_precision: 0.8167 - val_recall: 0.5074\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4470 - precision: 0.8395 - recall: 0.5008 - val_loss: 0.4571 - val_precision: 0.8245 - val_recall: 0.5116\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4391 - precision: 0.8314 - recall: 0.5107 - val_loss: 0.4491 - val_precision: 0.8111 - val_recall: 0.5421\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4317 - precision: 0.8253 - recall: 0.5269 - val_loss: 0.4413 - val_precision: 0.8086 - val_recall: 0.5611\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4261 - precision: 0.8149 - recall: 0.5503 - val_loss: 0.4356 - val_precision: 0.8111 - val_recall: 0.5668\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4199 - precision: 0.8137 - recall: 0.5614 - val_loss: 0.4329 - val_precision: 0.8042 - val_recall: 0.5693\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4141 - precision: 0.8088 - recall: 0.5707 - val_loss: 0.4278 - val_precision: 0.7907 - val_recall: 0.5924\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4081 - precision: 0.8047 - recall: 0.5819 - val_loss: 0.4248 - val_precision: 0.7996 - val_recall: 0.6023\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4028 - precision: 0.8041 - recall: 0.5951 - val_loss: 0.4208 - val_precision: 0.8051 - val_recall: 0.6031\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3979 - precision: 0.8042 - recall: 0.6023 - val_loss: 0.4178 - val_precision: 0.8076 - val_recall: 0.5990\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3939 - precision: 0.8016 - recall: 0.6044 - val_loss: 0.4128 - val_precision: 0.8093 - val_recall: 0.6023\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3906 - precision: 0.8043 - recall: 0.6073 - val_loss: 0.4071 - val_precision: 0.8043 - val_recall: 0.6172\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3865 - precision: 0.8030 - recall: 0.6115 - val_loss: 0.4043 - val_precision: 0.8017 - val_recall: 0.6205\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3828 - precision: 0.8055 - recall: 0.6187 - val_loss: 0.4006 - val_precision: 0.8082 - val_recall: 0.6155\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3795 - precision: 0.8085 - recall: 0.6227 - val_loss: 0.3977 - val_precision: 0.8144 - val_recall: 0.6155\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3752 - precision: 0.8089 - recall: 0.6298 - val_loss: 0.3933 - val_precision: 0.8118 - val_recall: 0.6229\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3726 - precision: 0.8098 - recall: 0.6343 - val_loss: 0.3896 - val_precision: 0.8065 - val_recall: 0.6328\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3697 - precision: 0.8116 - recall: 0.6383 - val_loss: 0.3846 - val_precision: 0.8148 - val_recall: 0.6353\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3657 - precision: 0.8101 - recall: 0.6492 - val_loss: 0.3795 - val_precision: 0.8098 - val_recall: 0.6427\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3621 - precision: 0.8131 - recall: 0.6572 - val_loss: 0.3765 - val_precision: 0.8135 - val_recall: 0.6477\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3592 - precision: 0.8130 - recall: 0.6633 - val_loss: 0.3730 - val_precision: 0.8137 - val_recall: 0.6485\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3559 - precision: 0.8129 - recall: 0.6637 - val_loss: 0.3700 - val_precision: 0.7982 - val_recall: 0.6724\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3520 - precision: 0.8146 - recall: 0.6713 - val_loss: 0.3664 - val_precision: 0.7883 - val_recall: 0.6790\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3495 - precision: 0.8184 - recall: 0.6789 - val_loss: 0.3632 - val_precision: 0.7898 - val_recall: 0.6881\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3457 - precision: 0.8177 - recall: 0.6835 - val_loss: 0.3583 - val_precision: 0.7947 - val_recall: 0.6964\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3418 - precision: 0.8184 - recall: 0.6932 - val_loss: 0.3565 - val_precision: 0.7896 - val_recall: 0.7030\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3387 - precision: 0.8218 - recall: 0.6987 - val_loss: 0.3546 - val_precision: 0.8019 - val_recall: 0.7046\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3348 - precision: 0.8244 - recall: 0.7081 - val_loss: 0.3531 - val_precision: 0.8011 - val_recall: 0.7013\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3312 - precision: 0.8255 - recall: 0.7138 - val_loss: 0.3514 - val_precision: 0.8047 - val_recall: 0.7005\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3283 - precision: 0.8270 - recall: 0.7180 - val_loss: 0.3501 - val_precision: 0.8056 - val_recall: 0.7079\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3245 - precision: 0.8272 - recall: 0.7201 - val_loss: 0.3503 - val_precision: 0.7991 - val_recall: 0.7021\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3206 - precision: 0.8260 - recall: 0.7241 - val_loss: 0.3504 - val_precision: 0.8149 - val_recall: 0.6972\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3182 - precision: 0.8269 - recall: 0.7287 - val_loss: 0.3497 - val_precision: 0.8178 - val_recall: 0.6964\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3147 - precision: 0.8278 - recall: 0.7325 - val_loss: 0.3488 - val_precision: 0.8247 - val_recall: 0.6832\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3121 - precision: 0.8300 - recall: 0.7376 - val_loss: 0.3437 - val_precision: 0.8266 - val_recall: 0.6922\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3077 - precision: 0.8318 - recall: 0.7410 - val_loss: 0.3365 - val_precision: 0.8410 - val_recall: 0.6939\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3036 - precision: 0.8330 - recall: 0.7441 - val_loss: 0.3324 - val_precision: 0.8402 - val_recall: 0.6939\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3001 - precision: 0.8325 - recall: 0.7521 - val_loss: 0.3326 - val_precision: 0.8320 - val_recall: 0.6947\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2959 - precision: 0.8381 - recall: 0.7580 - val_loss: 0.3303 - val_precision: 0.8242 - val_recall: 0.7038\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2911 - precision: 0.8418 - recall: 0.7662 - val_loss: 0.3321 - val_precision: 0.8198 - val_recall: 0.7096\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2883 - precision: 0.8369 - recall: 0.7677 - val_loss: 0.3316 - val_precision: 0.8124 - val_recall: 0.7145\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2845 - precision: 0.8399 - recall: 0.7750 - val_loss: 0.3271 - val_precision: 0.8282 - val_recall: 0.7079\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2810 - precision: 0.8432 - recall: 0.7822 - val_loss: 0.3242 - val_precision: 0.8256 - val_recall: 0.7228\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2774 - precision: 0.8432 - recall: 0.7843 - val_loss: 0.3206 - val_precision: 0.8195 - val_recall: 0.7269\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2735 - precision: 0.8448 - recall: 0.7891 - val_loss: 0.3160 - val_precision: 0.8304 - val_recall: 0.7310\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2706 - precision: 0.8478 - recall: 0.7961 - val_loss: 0.3137 - val_precision: 0.8245 - val_recall: 0.7327\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2690 - precision: 0.8469 - recall: 0.7929 - val_loss: 0.3114 - val_precision: 0.8221 - val_recall: 0.7434\n",
      "Epoch 49/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2664 - precision: 0.8486 - recall: 0.7973 - val_loss: 0.3101 - val_precision: 0.8357 - val_recall: 0.7343\n",
      "Epoch 50/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2649 - precision: 0.8500 - recall: 0.7988 - val_loss: 0.3056 - val_precision: 0.8320 - val_recall: 0.7475\n",
      "Epoch 51/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2619 - precision: 0.8513 - recall: 0.8013 - val_loss: 0.3031 - val_precision: 0.8300 - val_recall: 0.7533\n",
      "Epoch 52/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2598 - precision: 0.8555 - recall: 0.8024 - val_loss: 0.3013 - val_precision: 0.8243 - val_recall: 0.7550\n",
      "Epoch 53/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2568 - precision: 0.8570 - recall: 0.8049 - val_loss: 0.3005 - val_precision: 0.8270 - val_recall: 0.7574\n",
      "Epoch 54/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2519 - precision: 0.8594 - recall: 0.8091 - val_loss: 0.2973 - val_precision: 0.8243 - val_recall: 0.7624\n",
      "Epoch 55/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2495 - precision: 0.8592 - recall: 0.8106 - val_loss: 0.2937 - val_precision: 0.8259 - val_recall: 0.7673\n",
      "Epoch 56/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2458 - precision: 0.8597 - recall: 0.8136 - val_loss: 0.2975 - val_precision: 0.8248 - val_recall: 0.7616\n",
      "Epoch 57/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2439 - precision: 0.8641 - recall: 0.8159 - val_loss: 0.2963 - val_precision: 0.8401 - val_recall: 0.7541\n",
      "Epoch 58/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2421 - precision: 0.8640 - recall: 0.8157 - val_loss: 0.2958 - val_precision: 0.8427 - val_recall: 0.7517\n",
      "Epoch 59/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2392 - precision: 0.8666 - recall: 0.8178 - val_loss: 0.2944 - val_precision: 0.8401 - val_recall: 0.7500\n",
      "Epoch 60/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2371 - precision: 0.8660 - recall: 0.8190 - val_loss: 0.2936 - val_precision: 0.8480 - val_recall: 0.7550\n",
      "Epoch 61/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2349 - precision: 0.8678 - recall: 0.8207 - val_loss: 0.2909 - val_precision: 0.8440 - val_recall: 0.7541\n",
      "Epoch 62/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2324 - precision: 0.8687 - recall: 0.8211 - val_loss: 0.2859 - val_precision: 0.8377 - val_recall: 0.7624\n",
      "Epoch 63/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2293 - precision: 0.8692 - recall: 0.8249 - val_loss: 0.2847 - val_precision: 0.8323 - val_recall: 0.7739\n",
      "Epoch 64/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2253 - precision: 0.8739 - recall: 0.8300 - val_loss: 0.2884 - val_precision: 0.8293 - val_recall: 0.7657\n",
      "Epoch 65/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2239 - precision: 0.8750 - recall: 0.8335 - val_loss: 0.2851 - val_precision: 0.8369 - val_recall: 0.7789\n",
      "Epoch 66/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2230 - precision: 0.8737 - recall: 0.8314 - val_loss: 0.2838 - val_precision: 0.8271 - val_recall: 0.7855\n",
      "Epoch 67/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2198 - precision: 0.8757 - recall: 0.8363 - val_loss: 0.2866 - val_precision: 0.8275 - val_recall: 0.7756\n",
      "Epoch 68/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2188 - precision: 0.8756 - recall: 0.8369 - val_loss: 0.2891 - val_precision: 0.8191 - val_recall: 0.7847\n",
      "Epoch 69/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2187 - precision: 0.8735 - recall: 0.8373 - val_loss: 0.2895 - val_precision: 0.8212 - val_recall: 0.7880\n",
      "Epoch 70/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2138 - precision: 0.8808 - recall: 0.8426 - val_loss: 0.2951 - val_precision: 0.8106 - val_recall: 0.7946\n",
      "Epoch 71/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2143 - precision: 0.8753 - recall: 0.8422 - val_loss: 0.2906 - val_precision: 0.8126 - val_recall: 0.7979\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765543550.022414 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4971 - precision: 0.8040 - recall: 0.4842 - val_loss: 0.5070 - val_precision: 0.7340 - val_recall: 0.5396\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4749 - precision: 0.8267 - recall: 0.4958 - val_loss: 0.4919 - val_precision: 0.7735 - val_recall: 0.5017\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4655 - precision: 0.8323 - recall: 0.4952 - val_loss: 0.4751 - val_precision: 0.7618 - val_recall: 0.5198\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4612 - precision: 0.8314 - recall: 0.4992 - val_loss: 0.4759 - val_precision: 0.7691 - val_recall: 0.5140\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4585 - precision: 0.8355 - recall: 0.5025 - val_loss: 0.4719 - val_precision: 0.7755 - val_recall: 0.5074\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4523 - precision: 0.8350 - recall: 0.5067 - val_loss: 0.4658 - val_precision: 0.8102 - val_recall: 0.5107\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4459 - precision: 0.8394 - recall: 0.5114 - val_loss: 0.4614 - val_precision: 0.8282 - val_recall: 0.5091\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4297 - precision: 0.8092 - recall: 0.5507 - val_loss: 0.4489 - val_precision: 0.7549 - val_recall: 0.6023\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4210 - precision: 0.7900 - recall: 0.5859 - val_loss: 0.4424 - val_precision: 0.7533 - val_recall: 0.6097\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4116 - precision: 0.7898 - recall: 0.5976 - val_loss: 0.4308 - val_precision: 0.7573 - val_recall: 0.6180\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4044 - precision: 0.7921 - recall: 0.6103 - val_loss: 0.4211 - val_precision: 0.7682 - val_recall: 0.6345\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3974 - precision: 0.7937 - recall: 0.6111 - val_loss: 0.4125 - val_precision: 0.7700 - val_recall: 0.6436\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3899 - precision: 0.7962 - recall: 0.6231 - val_loss: 0.4036 - val_precision: 0.7756 - val_recall: 0.6444\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3839 - precision: 0.7982 - recall: 0.6267 - val_loss: 0.3984 - val_precision: 0.7733 - val_recall: 0.6502\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3758 - precision: 0.8050 - recall: 0.6324 - val_loss: 0.3863 - val_precision: 0.8071 - val_recall: 0.6386\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3676 - precision: 0.8155 - recall: 0.6391 - val_loss: 0.3754 - val_precision: 0.8028 - val_recall: 0.6683\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3586 - precision: 0.8249 - recall: 0.6521 - val_loss: 0.3667 - val_precision: 0.7913 - val_recall: 0.6914\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3499 - precision: 0.8260 - recall: 0.6644 - val_loss: 0.3568 - val_precision: 0.8032 - val_recall: 0.7005\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3382 - precision: 0.8312 - recall: 0.6818 - val_loss: 0.3465 - val_precision: 0.8058 - val_recall: 0.7153\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3266 - precision: 0.8395 - recall: 0.7020 - val_loss: 0.3373 - val_precision: 0.8190 - val_recall: 0.7318\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3135 - precision: 0.8418 - recall: 0.7233 - val_loss: 0.3290 - val_precision: 0.8151 - val_recall: 0.7492\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3002 - precision: 0.8509 - recall: 0.7363 - val_loss: 0.3187 - val_precision: 0.8335 - val_recall: 0.7475\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2914 - precision: 0.8500 - recall: 0.7464 - val_loss: 0.3093 - val_precision: 0.8442 - val_recall: 0.7599\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2780 - precision: 0.8547 - recall: 0.7652 - val_loss: 0.2963 - val_precision: 0.8445 - val_recall: 0.7706\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2667 - precision: 0.8570 - recall: 0.7734 - val_loss: 0.2921 - val_precision: 0.8497 - val_recall: 0.7838\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2554 - precision: 0.8597 - recall: 0.7891 - val_loss: 0.2934 - val_precision: 0.8473 - val_recall: 0.8012\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2453 - precision: 0.8623 - recall: 0.8001 - val_loss: 0.2954 - val_precision: 0.8193 - val_recall: 0.8045\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2356 - precision: 0.8699 - recall: 0.8087 - val_loss: 0.2853 - val_precision: 0.8403 - val_recall: 0.7987\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2269 - precision: 0.8724 - recall: 0.8199 - val_loss: 0.2955 - val_precision: 0.8552 - val_recall: 0.7946\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2200 - precision: 0.8752 - recall: 0.8281 - val_loss: 0.2903 - val_precision: 0.8336 - val_recall: 0.8144\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2119 - precision: 0.8809 - recall: 0.8329 - val_loss: 0.2756 - val_precision: 0.8326 - val_recall: 0.8210\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2061 - precision: 0.8847 - recall: 0.8399 - val_loss: 0.2769 - val_precision: 0.8400 - val_recall: 0.8144\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1989 - precision: 0.8886 - recall: 0.8525 - val_loss: 0.2866 - val_precision: 0.8258 - val_recall: 0.8292\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1926 - precision: 0.8911 - recall: 0.8592 - val_loss: 0.2804 - val_precision: 0.8203 - val_recall: 0.8399\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1818 - precision: 0.8968 - recall: 0.8668 - val_loss: 0.2721 - val_precision: 0.8331 - val_recall: 0.8399\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1740 - precision: 0.9015 - recall: 0.8744 - val_loss: 0.2847 - val_precision: 0.8238 - val_recall: 0.8408\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1689 - precision: 0.9034 - recall: 0.8792 - val_loss: 0.2967 - val_precision: 0.8172 - val_recall: 0.8408\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1593 - precision: 0.9092 - recall: 0.8870 - val_loss: 0.2836 - val_precision: 0.8237 - val_recall: 0.8482\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1524 - precision: 0.9128 - recall: 0.8941 - val_loss: 0.2986 - val_precision: 0.8228 - val_recall: 0.8507\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1484 - precision: 0.9125 - recall: 0.8958 - val_loss: 0.3068 - val_precision: 0.8177 - val_recall: 0.8548\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765543840.188547 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n",
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5038 - precision: 0.7972 - recall: 0.4806 - val_loss: 0.4806 - val_precision: 0.7699 - val_recall: 0.5190\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4595 - precision: 0.8385 - recall: 0.4928 - val_loss: 0.4722 - val_precision: 0.7720 - val_recall: 0.5140\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4466 - precision: 0.8358 - recall: 0.5036 - val_loss: 0.4611 - val_precision: 0.8099 - val_recall: 0.5132\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4325 - precision: 0.8293 - recall: 0.5194 - val_loss: 0.4424 - val_precision: 0.8382 - val_recall: 0.5173\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4216 - precision: 0.8205 - recall: 0.5436 - val_loss: 0.4267 - val_precision: 0.8187 - val_recall: 0.5701\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4117 - precision: 0.8125 - recall: 0.5680 - val_loss: 0.4193 - val_precision: 0.8015 - val_recall: 0.6097\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4024 - precision: 0.8146 - recall: 0.5814 - val_loss: 0.4080 - val_precision: 0.8139 - val_recall: 0.5990\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3937 - precision: 0.8119 - recall: 0.5905 - val_loss: 0.4025 - val_precision: 0.8266 - val_recall: 0.6056\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3865 - precision: 0.8137 - recall: 0.6046 - val_loss: 0.3946 - val_precision: 0.8347 - val_recall: 0.6040\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3788 - precision: 0.8136 - recall: 0.6189 - val_loss: 0.3880 - val_precision: 0.8414 - val_recall: 0.6130\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3707 - precision: 0.8188 - recall: 0.6296 - val_loss: 0.3843 - val_precision: 0.8508 - val_recall: 0.6163\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3637 - precision: 0.8192 - recall: 0.6418 - val_loss: 0.3776 - val_precision: 0.8599 - val_recall: 0.6279\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3541 - precision: 0.8189 - recall: 0.6641 - val_loss: 0.3715 - val_precision: 0.8581 - val_recall: 0.6287\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3485 - precision: 0.8149 - recall: 0.6700 - val_loss: 0.3585 - val_precision: 0.8528 - val_recall: 0.6452\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3379 - precision: 0.8216 - recall: 0.6959 - val_loss: 0.3565 - val_precision: 0.8356 - val_recall: 0.6708\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3282 - precision: 0.8264 - recall: 0.7104 - val_loss: 0.3439 - val_precision: 0.8355 - val_recall: 0.6955\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3208 - precision: 0.8315 - recall: 0.7216 - val_loss: 0.3341 - val_precision: 0.8389 - val_recall: 0.7046\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3113 - precision: 0.8312 - recall: 0.7388 - val_loss: 0.3284 - val_precision: 0.8173 - val_recall: 0.7236\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3016 - precision: 0.8326 - recall: 0.7504 - val_loss: 0.3236 - val_precision: 0.8081 - val_recall: 0.7261\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2943 - precision: 0.8356 - recall: 0.7593 - val_loss: 0.3169 - val_precision: 0.8189 - val_recall: 0.7351\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2848 - precision: 0.8391 - recall: 0.7725 - val_loss: 0.3143 - val_precision: 0.8185 - val_recall: 0.7517\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2773 - precision: 0.8425 - recall: 0.7799 - val_loss: 0.3142 - val_precision: 0.8301 - val_recall: 0.7335\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2697 - precision: 0.8466 - recall: 0.7877 - val_loss: 0.3132 - val_precision: 0.8315 - val_recall: 0.7409\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2611 - precision: 0.8514 - recall: 0.7992 - val_loss: 0.3080 - val_precision: 0.8306 - val_recall: 0.7483\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2539 - precision: 0.8563 - recall: 0.8074 - val_loss: 0.3041 - val_precision: 0.8401 - val_recall: 0.7368\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2463 - precision: 0.8607 - recall: 0.8152 - val_loss: 0.3006 - val_precision: 0.8346 - val_recall: 0.7492\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2393 - precision: 0.8627 - recall: 0.8182 - val_loss: 0.2897 - val_precision: 0.8350 - val_recall: 0.7599\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2340 - precision: 0.8662 - recall: 0.8295 - val_loss: 0.2899 - val_precision: 0.8435 - val_recall: 0.7426\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2290 - precision: 0.8723 - recall: 0.8291 - val_loss: 0.2904 - val_precision: 0.8396 - val_recall: 0.7731\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2240 - precision: 0.8741 - recall: 0.8361 - val_loss: 0.2867 - val_precision: 0.8385 - val_recall: 0.7880\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2234 - precision: 0.8744 - recall: 0.8338 - val_loss: 0.3014 - val_precision: 0.8110 - val_recall: 0.8003\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2153 - precision: 0.8763 - recall: 0.8422 - val_loss: 0.2954 - val_precision: 0.8216 - val_recall: 0.7979\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2092 - precision: 0.8781 - recall: 0.8476 - val_loss: 0.3115 - val_precision: 0.7794 - val_recall: 0.8135\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2029 - precision: 0.8825 - recall: 0.8537 - val_loss: 0.3031 - val_precision: 0.8003 - val_recall: 0.8069\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2028 - precision: 0.8843 - recall: 0.8544 - val_loss: 0.2891 - val_precision: 0.7913 - val_recall: 0.8292\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765544112.867700 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5222 - precision: 0.7982 - recall: 0.4745 - val_loss: 0.5267 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.5094 - precision: 0.8022 - recall: 0.4754 - val_loss: 0.5186 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.5048 - precision: 0.8022 - recall: 0.4754 - val_loss: 0.5256 - val_precision: 0.7969 - val_recall: 0.4629\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4903 - precision: 0.8127 - recall: 0.4747 - val_loss: 0.4902 - val_precision: 0.8431 - val_recall: 0.4744\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4619 - precision: 0.8386 - recall: 0.4996 - val_loss: 0.4750 - val_precision: 0.8285 - val_recall: 0.4942\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4489 - precision: 0.8428 - recall: 0.5101 - val_loss: 0.4508 - val_precision: 0.7905 - val_recall: 0.5635\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4383 - precision: 0.7930 - recall: 0.5739 - val_loss: 0.4308 - val_precision: 0.7987 - val_recall: 0.5990\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4096 - precision: 0.7985 - recall: 0.6004 - val_loss: 0.4375 - val_precision: 0.7562 - val_recall: 0.6246\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3965 - precision: 0.8028 - recall: 0.6252 - val_loss: 0.4097 - val_precision: 0.8110 - val_recall: 0.6337\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3835 - precision: 0.8023 - recall: 0.6437 - val_loss: 0.3967 - val_precision: 0.8068 - val_recall: 0.6477\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3722 - precision: 0.8048 - recall: 0.6646 - val_loss: 0.3767 - val_precision: 0.8206 - val_recall: 0.6493\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3561 - precision: 0.8010 - recall: 0.7005 - val_loss: 0.3743 - val_precision: 0.8412 - val_recall: 0.6469\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3328 - precision: 0.8100 - recall: 0.7277 - val_loss: 0.3417 - val_precision: 0.8292 - val_recall: 0.7087\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3148 - precision: 0.8231 - recall: 0.7557 - val_loss: 0.3411 - val_precision: 0.8338 - val_recall: 0.6955\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2960 - precision: 0.8312 - recall: 0.7782 - val_loss: 0.3301 - val_precision: 0.8335 - val_recall: 0.7186\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2788 - precision: 0.8440 - recall: 0.7868 - val_loss: 0.3336 - val_precision: 0.8371 - val_recall: 0.7079\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2569 - precision: 0.8558 - recall: 0.8119 - val_loss: 0.3215 - val_precision: 0.8394 - val_recall: 0.7417\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2397 - precision: 0.8673 - recall: 0.8264 - val_loss: 0.3068 - val_precision: 0.8480 - val_recall: 0.7781\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2238 - precision: 0.8763 - recall: 0.8396 - val_loss: 0.3057 - val_precision: 0.8387 - val_recall: 0.7937\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2092 - precision: 0.8830 - recall: 0.8563 - val_loss: 0.3339 - val_precision: 0.8244 - val_recall: 0.7904\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1932 - precision: 0.8888 - recall: 0.8666 - val_loss: 0.3132 - val_precision: 0.8388 - val_recall: 0.7987\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1844 - precision: 0.8914 - recall: 0.8723 - val_loss: 0.3141 - val_precision: 0.8457 - val_recall: 0.7913\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1722 - precision: 0.8984 - recall: 0.8834 - val_loss: 0.2913 - val_precision: 0.8275 - val_recall: 0.8391\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1658 - precision: 0.9003 - recall: 0.8853 - val_loss: 0.2802 - val_precision: 0.8384 - val_recall: 0.8564\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1585 - precision: 0.9095 - recall: 0.8923 - val_loss: 0.3024 - val_precision: 0.8284 - val_recall: 0.8564\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1404 - precision: 0.9151 - recall: 0.9053 - val_loss: 0.3191 - val_precision: 0.8202 - val_recall: 0.8358\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1265 - precision: 0.9259 - recall: 0.9146 - val_loss: 0.3259 - val_precision: 0.8170 - val_recall: 0.8655\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1217 - precision: 0.9243 - recall: 0.9167 - val_loss: 0.3185 - val_precision: 0.8277 - val_recall: 0.8523\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1177 - precision: 0.9342 - recall: 0.9232 - val_loss: 0.2682 - val_precision: 0.8612 - val_recall: 0.8548\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1200 - precision: 0.9303 - recall: 0.9211 - val_loss: 0.2910 - val_precision: 0.8269 - val_recall: 0.8828\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1200 - precision: 0.9298 - recall: 0.9223 - val_loss: 0.2652 - val_precision: 0.8434 - val_recall: 0.8845\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1135 - precision: 0.9349 - recall: 0.9310 - val_loss: 0.2732 - val_precision: 0.8401 - val_recall: 0.8845\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0984 - precision: 0.9438 - recall: 0.9373 - val_loss: 0.2604 - val_precision: 0.8533 - val_recall: 0.8878\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0853 - precision: 0.9470 - recall: 0.9478 - val_loss: 0.3127 - val_precision: 0.8533 - val_recall: 0.8639\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0813 - precision: 0.9507 - recall: 0.9499 - val_loss: 0.3037 - val_precision: 0.8769 - val_recall: 0.8639\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0801 - precision: 0.9547 - recall: 0.9535 - val_loss: 0.2986 - val_precision: 0.8719 - val_recall: 0.8647\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0778 - precision: 0.9559 - recall: 0.9484 - val_loss: 0.3245 - val_precision: 0.8804 - val_recall: 0.8201\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0623 - precision: 0.9631 - recall: 0.9617 - val_loss: 0.3388 - val_precision: 0.8841 - val_recall: 0.8432\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765544408.331655 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "{'batch_size': 16, 'layer_number': 5, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================== INIZIO CICLO CON SEED: 555 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n",
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - loss: 0.5156 - precision: 0.7989 - recall: 0.4747 - val_loss: 0.4929 - val_precision: 0.8360 - val_recall: 0.4641\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4610 - precision: 0.8359 - recall: 0.5017 - val_loss: 0.4744 - val_precision: 0.8427 - val_recall: 0.4665\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4498 - precision: 0.8406 - recall: 0.5047 - val_loss: 0.4844 - val_precision: 0.8359 - val_recall: 0.4720\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4414 - precision: 0.8435 - recall: 0.5066 - val_loss: 0.4796 - val_precision: 0.8340 - val_recall: 0.4696\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4325 - precision: 0.8356 - recall: 0.5168 - val_loss: 0.4680 - val_precision: 0.8399 - val_recall: 0.4736\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4242 - precision: 0.8281 - recall: 0.5359 - val_loss: 0.4627 - val_precision: 0.8408 - val_recall: 0.4976\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4181 - precision: 0.8259 - recall: 0.5497 - val_loss: 0.4558 - val_precision: 0.8395 - val_recall: 0.5264\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4128 - precision: 0.8265 - recall: 0.5569 - val_loss: 0.4528 - val_precision: 0.8467 - val_recall: 0.5296\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4074 - precision: 0.8234 - recall: 0.5609 - val_loss: 0.4503 - val_precision: 0.8448 - val_recall: 0.5391\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4028 - precision: 0.8238 - recall: 0.5675 - val_loss: 0.4510 - val_precision: 0.8462 - val_recall: 0.5407\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3989 - precision: 0.8256 - recall: 0.5705 - val_loss: 0.4503 - val_precision: 0.8477 - val_recall: 0.5335\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3952 - precision: 0.8260 - recall: 0.5743 - val_loss: 0.4436 - val_precision: 0.8535 - val_recall: 0.5399\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3902 - precision: 0.8247 - recall: 0.5811 - val_loss: 0.4341 - val_precision: 0.8502 - val_recall: 0.5487\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3856 - precision: 0.8244 - recall: 0.5898 - val_loss: 0.4220 - val_precision: 0.8514 - val_recall: 0.5583\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3797 - precision: 0.8261 - recall: 0.5947 - val_loss: 0.4178 - val_precision: 0.8345 - val_recall: 0.5599\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3745 - precision: 0.8267 - recall: 0.6014 - val_loss: 0.4136 - val_precision: 0.8273 - val_recall: 0.5663\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3692 - precision: 0.8255 - recall: 0.6135 - val_loss: 0.4048 - val_precision: 0.8187 - val_recall: 0.5735\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3645 - precision: 0.8268 - recall: 0.6222 - val_loss: 0.3980 - val_precision: 0.8200 - val_recall: 0.5895\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3594 - precision: 0.8269 - recall: 0.6295 - val_loss: 0.3895 - val_precision: 0.8208 - val_recall: 0.6110\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3552 - precision: 0.8215 - recall: 0.6388 - val_loss: 0.3881 - val_precision: 0.8228 - val_recall: 0.6118\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3514 - precision: 0.8201 - recall: 0.6462 - val_loss: 0.3832 - val_precision: 0.8237 - val_recall: 0.6230\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3475 - precision: 0.8220 - recall: 0.6545 - val_loss: 0.3792 - val_precision: 0.8194 - val_recall: 0.6342\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3422 - precision: 0.8235 - recall: 0.6634 - val_loss: 0.3743 - val_precision: 0.8125 - val_recall: 0.6438\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3382 - precision: 0.8198 - recall: 0.6721 - val_loss: 0.3691 - val_precision: 0.8097 - val_recall: 0.6558\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3339 - precision: 0.8211 - recall: 0.6789 - val_loss: 0.3661 - val_precision: 0.8127 - val_recall: 0.6757\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3299 - precision: 0.8232 - recall: 0.6889 - val_loss: 0.3635 - val_precision: 0.8078 - val_recall: 0.6781\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3268 - precision: 0.8275 - recall: 0.6955 - val_loss: 0.3669 - val_precision: 0.8198 - val_recall: 0.6685\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3234 - precision: 0.8272 - recall: 0.7020 - val_loss: 0.3625 - val_precision: 0.8200 - val_recall: 0.6733\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3200 - precision: 0.8289 - recall: 0.7063 - val_loss: 0.3563 - val_precision: 0.8211 - val_recall: 0.6781\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3170 - precision: 0.8310 - recall: 0.7129 - val_loss: 0.3579 - val_precision: 0.8237 - val_recall: 0.6717\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3141 - precision: 0.8348 - recall: 0.7163 - val_loss: 0.3564 - val_precision: 0.8249 - val_recall: 0.6773\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3099 - precision: 0.8348 - recall: 0.7230 - val_loss: 0.3520 - val_precision: 0.8206 - val_recall: 0.6797\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3077 - precision: 0.8339 - recall: 0.7296 - val_loss: 0.3492 - val_precision: 0.8272 - val_recall: 0.6805\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3039 - precision: 0.8383 - recall: 0.7341 - val_loss: 0.3467 - val_precision: 0.8266 - val_recall: 0.6853\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3005 - precision: 0.8403 - recall: 0.7394 - val_loss: 0.3405 - val_precision: 0.8294 - val_recall: 0.7029\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2967 - precision: 0.8414 - recall: 0.7455 - val_loss: 0.3378 - val_precision: 0.8167 - val_recall: 0.7188\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2936 - precision: 0.8457 - recall: 0.7470 - val_loss: 0.3319 - val_precision: 0.8150 - val_recall: 0.7356\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2905 - precision: 0.8445 - recall: 0.7481 - val_loss: 0.3295 - val_precision: 0.8183 - val_recall: 0.7516\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.2878 - precision: 0.8458 - recall: 0.7542 - val_loss: 0.3288 - val_precision: 0.8112 - val_recall: 0.7548\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.2843 - precision: 0.8458 - recall: 0.7576 - val_loss: 0.3285 - val_precision: 0.8069 - val_recall: 0.7676\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2810 - precision: 0.8456 - recall: 0.7604 - val_loss: 0.3255 - val_precision: 0.8067 - val_recall: 0.7700\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2765 - precision: 0.8479 - recall: 0.7676 - val_loss: 0.3263 - val_precision: 0.8002 - val_recall: 0.7804\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2738 - precision: 0.8486 - recall: 0.7697 - val_loss: 0.3231 - val_precision: 0.7961 - val_recall: 0.7923\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.2717 - precision: 0.8488 - recall: 0.7731 - val_loss: 0.3210 - val_precision: 0.8057 - val_recall: 0.7915\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.2683 - precision: 0.8501 - recall: 0.7765 - val_loss: 0.3170 - val_precision: 0.8106 - val_recall: 0.7931\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2646 - precision: 0.8510 - recall: 0.7791 - val_loss: 0.3141 - val_precision: 0.8106 - val_recall: 0.7963\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2610 - precision: 0.8543 - recall: 0.7854 - val_loss: 0.3111 - val_precision: 0.8096 - val_recall: 0.8083\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2580 - precision: 0.8537 - recall: 0.7876 - val_loss: 0.3094 - val_precision: 0.8051 - val_recall: 0.8083\n",
      "Epoch 49/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2541 - precision: 0.8556 - recall: 0.7922 - val_loss: 0.3093 - val_precision: 0.8051 - val_recall: 0.8147\n",
      "Epoch 50/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2514 - precision: 0.8571 - recall: 0.7944 - val_loss: 0.3052 - val_precision: 0.8062 - val_recall: 0.8139\n",
      "Epoch 51/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2482 - precision: 0.8596 - recall: 0.7992 - val_loss: 0.3073 - val_precision: 0.8031 - val_recall: 0.8179\n",
      "Epoch 52/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2449 - precision: 0.8627 - recall: 0.8011 - val_loss: 0.3041 - val_precision: 0.8057 - val_recall: 0.8179\n",
      "Epoch 53/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2430 - precision: 0.8632 - recall: 0.8035 - val_loss: 0.3016 - val_precision: 0.8075 - val_recall: 0.8211\n",
      "Epoch 54/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2393 - precision: 0.8683 - recall: 0.8086 - val_loss: 0.2998 - val_precision: 0.8045 - val_recall: 0.8219\n",
      "Epoch 55/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2371 - precision: 0.8668 - recall: 0.8094 - val_loss: 0.3017 - val_precision: 0.8006 - val_recall: 0.8243\n",
      "Epoch 56/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2354 - precision: 0.8667 - recall: 0.8126 - val_loss: 0.3000 - val_precision: 0.8041 - val_recall: 0.8227\n",
      "Epoch 57/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2321 - precision: 0.8680 - recall: 0.8164 - val_loss: 0.2977 - val_precision: 0.8037 - val_recall: 0.8275\n",
      "Epoch 58/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2295 - precision: 0.8701 - recall: 0.8175 - val_loss: 0.2942 - val_precision: 0.8089 - val_recall: 0.8251\n",
      "Epoch 59/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2266 - precision: 0.8720 - recall: 0.8213 - val_loss: 0.2880 - val_precision: 0.8132 - val_recall: 0.8275\n",
      "Epoch 60/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2238 - precision: 0.8714 - recall: 0.8253 - val_loss: 0.2881 - val_precision: 0.8195 - val_recall: 0.8267\n",
      "Epoch 61/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2213 - precision: 0.8734 - recall: 0.8275 - val_loss: 0.2849 - val_precision: 0.8288 - val_recall: 0.8235\n",
      "Epoch 62/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2187 - precision: 0.8734 - recall: 0.8298 - val_loss: 0.2905 - val_precision: 0.8205 - val_recall: 0.8323\n",
      "Epoch 63/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2169 - precision: 0.8761 - recall: 0.8287 - val_loss: 0.2898 - val_precision: 0.8161 - val_recall: 0.8331\n",
      "Epoch 64/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2153 - precision: 0.8761 - recall: 0.8313 - val_loss: 0.2832 - val_precision: 0.8289 - val_recall: 0.8283\n",
      "Epoch 65/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2125 - precision: 0.8780 - recall: 0.8351 - val_loss: 0.2845 - val_precision: 0.8239 - val_recall: 0.8331\n",
      "Epoch 66/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2111 - precision: 0.8777 - recall: 0.8360 - val_loss: 0.2861 - val_precision: 0.8251 - val_recall: 0.8363\n",
      "Epoch 67/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2088 - precision: 0.8793 - recall: 0.8368 - val_loss: 0.2835 - val_precision: 0.8272 - val_recall: 0.8371\n",
      "Epoch 68/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2073 - precision: 0.8814 - recall: 0.8372 - val_loss: 0.2790 - val_precision: 0.8335 - val_recall: 0.8435\n",
      "Epoch 69/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2040 - precision: 0.8808 - recall: 0.8436 - val_loss: 0.2783 - val_precision: 0.8289 - val_recall: 0.8435\n",
      "Epoch 70/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2014 - precision: 0.8851 - recall: 0.8466 - val_loss: 0.2829 - val_precision: 0.8324 - val_recall: 0.8490\n",
      "Epoch 71/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1992 - precision: 0.8832 - recall: 0.8474 - val_loss: 0.2731 - val_precision: 0.8449 - val_recall: 0.8442\n",
      "Epoch 72/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1967 - precision: 0.8852 - recall: 0.8489 - val_loss: 0.2812 - val_precision: 0.8314 - val_recall: 0.8546\n",
      "Epoch 73/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1946 - precision: 0.8859 - recall: 0.8536 - val_loss: 0.2832 - val_precision: 0.8291 - val_recall: 0.8602\n",
      "Epoch 74/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1933 - precision: 0.8864 - recall: 0.8531 - val_loss: 0.2751 - val_precision: 0.8404 - val_recall: 0.8578\n",
      "Epoch 75/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.1913 - precision: 0.8864 - recall: 0.8563 - val_loss: 0.2793 - val_precision: 0.8321 - val_recall: 0.8706\n",
      "Epoch 76/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.1885 - precision: 0.8888 - recall: 0.8604 - val_loss: 0.2743 - val_precision: 0.8351 - val_recall: 0.8658\n",
      "\u001b[1m10/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765544959.173327 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.5191 - precision: 0.7930 - recall: 0.4739 - val_loss: 0.5220 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.4906 - precision: 0.8092 - recall: 0.4815 - val_loss: 0.5110 - val_precision: 0.8215 - val_recall: 0.4633\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.4697 - precision: 0.8305 - recall: 0.5000 - val_loss: 0.5173 - val_precision: 0.8205 - val_recall: 0.4601\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.4657 - precision: 0.8284 - recall: 0.4998 - val_loss: 0.5191 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4633 - precision: 0.8353 - recall: 0.5036 - val_loss: 0.5035 - val_precision: 0.8233 - val_recall: 0.4577\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4597 - precision: 0.8434 - recall: 0.5028 - val_loss: 0.5025 - val_precision: 0.8312 - val_recall: 0.4641\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4508 - precision: 0.8525 - recall: 0.5102 - val_loss: 0.4980 - val_precision: 0.8307 - val_recall: 0.4625\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4436 - precision: 0.8591 - recall: 0.5161 - val_loss: 0.4768 - val_precision: 0.8484 - val_recall: 0.4736\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4322 - precision: 0.8454 - recall: 0.5282 - val_loss: 0.4552 - val_precision: 0.8587 - val_recall: 0.5000\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4206 - precision: 0.8373 - recall: 0.5484 - val_loss: 0.4433 - val_precision: 0.8599 - val_recall: 0.5296\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4075 - precision: 0.8237 - recall: 0.5722 - val_loss: 0.4321 - val_precision: 0.8554 - val_recall: 0.5575\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3924 - precision: 0.8213 - recall: 0.6036 - val_loss: 0.4140 - val_precision: 0.8419 - val_recall: 0.6166\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3820 - precision: 0.8209 - recall: 0.6208 - val_loss: 0.4020 - val_precision: 0.8531 - val_recall: 0.6078\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3676 - precision: 0.8239 - recall: 0.6367 - val_loss: 0.3927 - val_precision: 0.8382 - val_recall: 0.6374\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3569 - precision: 0.8215 - recall: 0.6545 - val_loss: 0.3924 - val_precision: 0.8221 - val_recall: 0.6645\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3474 - precision: 0.8182 - recall: 0.6657 - val_loss: 0.3744 - val_precision: 0.8158 - val_recall: 0.6829\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3339 - precision: 0.8192 - recall: 0.6923 - val_loss: 0.3586 - val_precision: 0.8306 - val_recall: 0.6773\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3171 - precision: 0.8300 - recall: 0.7097 - val_loss: 0.3416 - val_precision: 0.8280 - val_recall: 0.7037\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3044 - precision: 0.8361 - recall: 0.7275 - val_loss: 0.3338 - val_precision: 0.8376 - val_recall: 0.7005\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2848 - precision: 0.8517 - recall: 0.7506 - val_loss: 0.3286 - val_precision: 0.8304 - val_recall: 0.7157\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2747 - precision: 0.8535 - recall: 0.7629 - val_loss: 0.3200 - val_precision: 0.8396 - val_recall: 0.7276\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2634 - precision: 0.8619 - recall: 0.7763 - val_loss: 0.3104 - val_precision: 0.8381 - val_recall: 0.7276\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2532 - precision: 0.8665 - recall: 0.7867 - val_loss: 0.3162 - val_precision: 0.8180 - val_recall: 0.7468\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2377 - precision: 0.8725 - recall: 0.8033 - val_loss: 0.2919 - val_precision: 0.8484 - val_recall: 0.7819\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 0.2266 - precision: 0.8796 - recall: 0.8152 - val_loss: 0.2884 - val_precision: 0.8384 - val_recall: 0.7955\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2197 - precision: 0.8788 - recall: 0.8219 - val_loss: 0.2862 - val_precision: 0.8188 - val_recall: 0.8155\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2140 - precision: 0.8811 - recall: 0.8304 - val_loss: 0.2913 - val_precision: 0.8433 - val_recall: 0.7907\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2024 - precision: 0.8848 - recall: 0.8442 - val_loss: 0.2669 - val_precision: 0.8373 - val_recall: 0.8139\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1886 - precision: 0.8938 - recall: 0.8559 - val_loss: 0.2619 - val_precision: 0.8507 - val_recall: 0.8235\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1786 - precision: 0.8966 - recall: 0.8669 - val_loss: 0.2546 - val_precision: 0.8500 - val_recall: 0.8283\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1734 - precision: 0.8973 - recall: 0.8756 - val_loss: 0.2701 - val_precision: 0.8568 - val_recall: 0.8027\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1623 - precision: 0.9045 - recall: 0.8829 - val_loss: 0.2410 - val_precision: 0.8704 - val_recall: 0.8259\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1581 - precision: 0.9049 - recall: 0.8888 - val_loss: 0.2395 - val_precision: 0.8870 - val_recall: 0.8147\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1499 - precision: 0.9129 - recall: 0.8939 - val_loss: 0.2437 - val_precision: 0.8932 - val_recall: 0.8219\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1410 - precision: 0.9175 - recall: 0.9034 - val_loss: 0.2325 - val_precision: 0.8954 - val_recall: 0.8275\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1402 - precision: 0.9165 - recall: 0.9066 - val_loss: 0.2514 - val_precision: 0.8962 - val_recall: 0.8203\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1284 - precision: 0.9256 - recall: 0.9140 - val_loss: 0.2362 - val_precision: 0.8938 - val_recall: 0.8339\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1173 - precision: 0.9358 - recall: 0.9223 - val_loss: 0.2275 - val_precision: 0.9033 - val_recall: 0.8427\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1289 - precision: 0.9247 - recall: 0.9198 - val_loss: 0.3016 - val_precision: 0.8878 - val_recall: 0.7835\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1238 - precision: 0.9316 - recall: 0.9185 - val_loss: 0.2472 - val_precision: 0.8966 - val_recall: 0.8315\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1101 - precision: 0.9362 - recall: 0.9287 - val_loss: 0.2365 - val_precision: 0.8941 - val_recall: 0.8427\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1216 - precision: 0.9294 - recall: 0.9251 - val_loss: 0.2227 - val_precision: 0.8893 - val_recall: 0.8594\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1003 - precision: 0.9413 - recall: 0.9351 - val_loss: 0.2051 - val_precision: 0.9021 - val_recall: 0.8538\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0955 - precision: 0.9428 - recall: 0.9380 - val_loss: 0.2058 - val_precision: 0.8946 - val_recall: 0.8746\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0943 - precision: 0.9452 - recall: 0.9376 - val_loss: 0.2153 - val_precision: 0.9208 - val_recall: 0.8546\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1031 - precision: 0.9404 - recall: 0.9342 - val_loss: 0.2512 - val_precision: 0.9139 - val_recall: 0.8139\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0921 - precision: 0.9462 - recall: 0.9404 - val_loss: 0.2063 - val_precision: 0.9374 - val_recall: 0.8610\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0906 - precision: 0.9434 - recall: 0.9476 - val_loss: 0.2220 - val_precision: 0.9281 - val_recall: 0.8658\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765545315.530730 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5169 - precision: 0.7923 - recall: 0.4743 - val_loss: 0.5386 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4709 - precision: 0.8130 - recall: 0.4992 - val_loss: 0.4762 - val_precision: 0.7896 - val_recall: 0.5455\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4390 - precision: 0.8195 - recall: 0.5291 - val_loss: 0.4499 - val_precision: 0.7923 - val_recall: 0.5791\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4275 - precision: 0.8140 - recall: 0.5435 - val_loss: 0.4390 - val_precision: 0.8130 - val_recall: 0.5695\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4191 - precision: 0.8137 - recall: 0.5626 - val_loss: 0.4430 - val_precision: 0.8296 - val_recall: 0.5599\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4121 - precision: 0.8167 - recall: 0.5662 - val_loss: 0.4375 - val_precision: 0.8381 - val_recall: 0.5623\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4033 - precision: 0.8199 - recall: 0.5749 - val_loss: 0.4297 - val_precision: 0.8287 - val_recall: 0.5759\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3962 - precision: 0.8164 - recall: 0.5832 - val_loss: 0.4192 - val_precision: 0.8271 - val_recall: 0.5847\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.3883 - precision: 0.8129 - recall: 0.5893 - val_loss: 0.4103 - val_precision: 0.8239 - val_recall: 0.5942\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3792 - precision: 0.8151 - recall: 0.6121 - val_loss: 0.3908 - val_precision: 0.8068 - val_recall: 0.6238\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3689 - precision: 0.8194 - recall: 0.6231 - val_loss: 0.3798 - val_precision: 0.8084 - val_recall: 0.6438\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3601 - precision: 0.8235 - recall: 0.6388 - val_loss: 0.3719 - val_precision: 0.8095 - val_recall: 0.6550\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3503 - precision: 0.8264 - recall: 0.6556 - val_loss: 0.3644 - val_precision: 0.8247 - val_recall: 0.6502\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3415 - precision: 0.8235 - recall: 0.6732 - val_loss: 0.3552 - val_precision: 0.8295 - val_recall: 0.6645\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3318 - precision: 0.8257 - recall: 0.6908 - val_loss: 0.3492 - val_precision: 0.8248 - val_recall: 0.6917\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.3224 - precision: 0.8282 - recall: 0.7071 - val_loss: 0.3449 - val_precision: 0.8218 - val_recall: 0.7109\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3130 - precision: 0.8310 - recall: 0.7220 - val_loss: 0.3388 - val_precision: 0.8210 - val_recall: 0.7181\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3040 - precision: 0.8368 - recall: 0.7358 - val_loss: 0.3300 - val_precision: 0.8179 - val_recall: 0.7212\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2943 - precision: 0.8403 - recall: 0.7492 - val_loss: 0.3329 - val_precision: 0.8219 - val_recall: 0.7188\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2872 - precision: 0.8451 - recall: 0.7574 - val_loss: 0.3207 - val_precision: 0.8194 - val_recall: 0.7428\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2781 - precision: 0.8469 - recall: 0.7704 - val_loss: 0.3213 - val_precision: 0.8116 - val_recall: 0.7572\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2696 - precision: 0.8482 - recall: 0.7827 - val_loss: 0.3124 - val_precision: 0.8054 - val_recall: 0.7804\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.2626 - precision: 0.8513 - recall: 0.7884 - val_loss: 0.3136 - val_precision: 0.8123 - val_recall: 0.7708\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2555 - precision: 0.8519 - recall: 0.7994 - val_loss: 0.3107 - val_precision: 0.8044 - val_recall: 0.7883\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2494 - precision: 0.8569 - recall: 0.8060 - val_loss: 0.2992 - val_precision: 0.8059 - val_recall: 0.8227\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.2413 - precision: 0.8634 - recall: 0.8156 - val_loss: 0.2988 - val_precision: 0.8201 - val_recall: 0.7899\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2331 - precision: 0.8701 - recall: 0.8247 - val_loss: 0.2922 - val_precision: 0.8326 - val_recall: 0.7947\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2270 - precision: 0.8736 - recall: 0.8317 - val_loss: 0.2983 - val_precision: 0.8388 - val_recall: 0.7564\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.2197 - precision: 0.8735 - recall: 0.8398 - val_loss: 0.2864 - val_precision: 0.8450 - val_recall: 0.7796\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.2133 - precision: 0.8787 - recall: 0.8442 - val_loss: 0.2829 - val_precision: 0.8472 - val_recall: 0.7883\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2061 - precision: 0.8820 - recall: 0.8519 - val_loss: 0.2726 - val_precision: 0.8426 - val_recall: 0.8211\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1998 - precision: 0.8860 - recall: 0.8580 - val_loss: 0.2761 - val_precision: 0.8432 - val_recall: 0.8163\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1904 - precision: 0.8911 - recall: 0.8720 - val_loss: 0.2671 - val_precision: 0.8441 - val_recall: 0.8171\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1831 - precision: 0.8927 - recall: 0.8756 - val_loss: 0.2588 - val_precision: 0.8560 - val_recall: 0.8307\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1754 - precision: 0.8990 - recall: 0.8818 - val_loss: 0.2496 - val_precision: 0.8661 - val_recall: 0.8419\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1697 - precision: 0.9025 - recall: 0.8879 - val_loss: 0.2407 - val_precision: 0.8699 - val_recall: 0.8435\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1626 - precision: 0.9061 - recall: 0.8933 - val_loss: 0.2498 - val_precision: 0.8710 - val_recall: 0.8251\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1589 - precision: 0.9098 - recall: 0.8988 - val_loss: 0.2664 - val_precision: 0.8682 - val_recall: 0.7947\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1529 - precision: 0.9094 - recall: 0.9011 - val_loss: 0.2816 - val_precision: 0.8800 - val_recall: 0.7612\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1495 - precision: 0.9140 - recall: 0.9020 - val_loss: 0.2677 - val_precision: 0.8989 - val_recall: 0.7740\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1422 - precision: 0.9193 - recall: 0.9113 - val_loss: 0.2496 - val_precision: 0.9066 - val_recall: 0.7987\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765545642.854990 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.5252 - precision: 0.7782 - recall: 0.4764 - val_loss: 0.5192 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4856 - precision: 0.8129 - recall: 0.4896 - val_loss: 0.5250 - val_precision: 0.8168 - val_recall: 0.4593\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4733 - precision: 0.8297 - recall: 0.4911 - val_loss: 0.5085 - val_precision: 0.8205 - val_recall: 0.4601\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4746 - precision: 0.8421 - recall: 0.5049 - val_loss: 0.4869 - val_precision: 0.8482 - val_recall: 0.4776\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4506 - precision: 0.8540 - recall: 0.5138 - val_loss: 0.4773 - val_precision: 0.8652 - val_recall: 0.4872\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4383 - precision: 0.8535 - recall: 0.5229 - val_loss: 0.4670 - val_precision: 0.8646 - val_recall: 0.5000\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4229 - precision: 0.8417 - recall: 0.5473 - val_loss: 0.4511 - val_precision: 0.8325 - val_recall: 0.5399\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.4093 - precision: 0.8307 - recall: 0.5664 - val_loss: 0.4347 - val_precision: 0.8734 - val_recall: 0.5016\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3926 - precision: 0.8266 - recall: 0.5860 - val_loss: 0.4199 - val_precision: 0.8688 - val_recall: 0.5343\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3782 - precision: 0.8227 - recall: 0.6106 - val_loss: 0.4048 - val_precision: 0.8696 - val_recall: 0.5591\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3670 - precision: 0.8228 - recall: 0.6307 - val_loss: 0.3997 - val_precision: 0.8512 - val_recall: 0.5895\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3529 - precision: 0.8274 - recall: 0.6500 - val_loss: 0.3900 - val_precision: 0.8639 - val_recall: 0.5982\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3333 - precision: 0.8263 - recall: 0.6812 - val_loss: 0.3824 - val_precision: 0.8544 - val_recall: 0.6326\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.3166 - precision: 0.8388 - recall: 0.7103 - val_loss: 0.3811 - val_precision: 0.8452 - val_recall: 0.6454\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2965 - precision: 0.8399 - recall: 0.7402 - val_loss: 0.3464 - val_precision: 0.8333 - val_recall: 0.7029\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2854 - precision: 0.8471 - recall: 0.7572 - val_loss: 0.3515 - val_precision: 0.8341 - val_recall: 0.6829\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2667 - precision: 0.8493 - recall: 0.7763 - val_loss: 0.3271 - val_precision: 0.8608 - val_recall: 0.7061\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2489 - precision: 0.8581 - recall: 0.7982 - val_loss: 0.3151 - val_precision: 0.8633 - val_recall: 0.7364\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2284 - precision: 0.8700 - recall: 0.8181 - val_loss: 0.3520 - val_precision: 0.8688 - val_recall: 0.7141\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2094 - precision: 0.8857 - recall: 0.8385 - val_loss: 0.3222 - val_precision: 0.8693 - val_recall: 0.7436\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1956 - precision: 0.8924 - recall: 0.8572 - val_loss: 0.3339 - val_precision: 0.8719 - val_recall: 0.7284\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1794 - precision: 0.9026 - recall: 0.8693 - val_loss: 0.3437 - val_precision: 0.8739 - val_recall: 0.7308\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1693 - precision: 0.9030 - recall: 0.8771 - val_loss: 0.3302 - val_precision: 0.8688 - val_recall: 0.7564\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765545829.017814 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "{'batch_size': 16, 'layer_number': 4, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 123 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.5128 - precision: 0.7881 - recall: 0.4792 - val_loss: 0.4846 - val_precision: 0.8411 - val_recall: 0.4736\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4587 - precision: 0.8342 - recall: 0.5008 - val_loss: 0.4700 - val_precision: 0.8364 - val_recall: 0.4776\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4467 - precision: 0.8414 - recall: 0.5066 - val_loss: 0.4591 - val_precision: 0.8466 - val_recall: 0.4760\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4376 - precision: 0.8427 - recall: 0.5104 - val_loss: 0.4511 - val_precision: 0.8582 - val_recall: 0.4784\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4299 - precision: 0.8383 - recall: 0.5238 - val_loss: 0.4444 - val_precision: 0.8507 - val_recall: 0.4960\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4234 - precision: 0.8306 - recall: 0.5390 - val_loss: 0.4375 - val_precision: 0.8327 - val_recall: 0.5447\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4184 - precision: 0.8270 - recall: 0.5488 - val_loss: 0.4331 - val_precision: 0.8416 - val_recall: 0.5559\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4134 - precision: 0.8222 - recall: 0.5554 - val_loss: 0.4289 - val_precision: 0.8322 - val_recall: 0.5703\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4087 - precision: 0.8221 - recall: 0.5649 - val_loss: 0.4260 - val_precision: 0.8277 - val_recall: 0.5831\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.4042 - precision: 0.8193 - recall: 0.5715 - val_loss: 0.4214 - val_precision: 0.8189 - val_recall: 0.5958\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3987 - precision: 0.8200 - recall: 0.5819 - val_loss: 0.4173 - val_precision: 0.8203 - val_recall: 0.6054\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3947 - precision: 0.8212 - recall: 0.5887 - val_loss: 0.4143 - val_precision: 0.8226 - val_recall: 0.6038\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3889 - precision: 0.8229 - recall: 0.5938 - val_loss: 0.4110 - val_precision: 0.8237 - val_recall: 0.6006\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3837 - precision: 0.8261 - recall: 0.6019 - val_loss: 0.4076 - val_precision: 0.8379 - val_recall: 0.5863\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3786 - precision: 0.8281 - recall: 0.6084 - val_loss: 0.4043 - val_precision: 0.8244 - val_recall: 0.6038\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3743 - precision: 0.8247 - recall: 0.6121 - val_loss: 0.3989 - val_precision: 0.8168 - val_recall: 0.6230\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3684 - precision: 0.8261 - recall: 0.6220 - val_loss: 0.3941 - val_precision: 0.8267 - val_recall: 0.6174\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3635 - precision: 0.8288 - recall: 0.6278 - val_loss: 0.3893 - val_precision: 0.8319 - val_recall: 0.6206\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3593 - precision: 0.8289 - recall: 0.6322 - val_loss: 0.3844 - val_precision: 0.8226 - val_recall: 0.6334\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3545 - precision: 0.8311 - recall: 0.6360 - val_loss: 0.3802 - val_precision: 0.8191 - val_recall: 0.6438\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3512 - precision: 0.8260 - recall: 0.6447 - val_loss: 0.3750 - val_precision: 0.8226 - val_recall: 0.6518\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3470 - precision: 0.8292 - recall: 0.6490 - val_loss: 0.3717 - val_precision: 0.8181 - val_recall: 0.6717\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.3427 - precision: 0.8304 - recall: 0.6547 - val_loss: 0.3690 - val_precision: 0.8199 - val_recall: 0.6765\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3383 - precision: 0.8336 - recall: 0.6632 - val_loss: 0.3660 - val_precision: 0.8210 - val_recall: 0.6813\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.3344 - precision: 0.8363 - recall: 0.6700 - val_loss: 0.3630 - val_precision: 0.8201 - val_recall: 0.6917\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3311 - precision: 0.8357 - recall: 0.6770 - val_loss: 0.3612 - val_precision: 0.8187 - val_recall: 0.6997\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3279 - precision: 0.8345 - recall: 0.6836 - val_loss: 0.3617 - val_precision: 0.8168 - val_recall: 0.7053\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3245 - precision: 0.8387 - recall: 0.6921 - val_loss: 0.3599 - val_precision: 0.8179 - val_recall: 0.7069\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3213 - precision: 0.8404 - recall: 0.6976 - val_loss: 0.3599 - val_precision: 0.8134 - val_recall: 0.7173\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3175 - precision: 0.8400 - recall: 0.7063 - val_loss: 0.3588 - val_precision: 0.8113 - val_recall: 0.7212\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3136 - precision: 0.8414 - recall: 0.7124 - val_loss: 0.3565 - val_precision: 0.8072 - val_recall: 0.7188\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3098 - precision: 0.8409 - recall: 0.7245 - val_loss: 0.3537 - val_precision: 0.8147 - val_recall: 0.7165\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3063 - precision: 0.8408 - recall: 0.7286 - val_loss: 0.3514 - val_precision: 0.8094 - val_recall: 0.7188\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3027 - precision: 0.8406 - recall: 0.7328 - val_loss: 0.3461 - val_precision: 0.8146 - val_recall: 0.7228\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2988 - precision: 0.8436 - recall: 0.7394 - val_loss: 0.3416 - val_precision: 0.8203 - val_recall: 0.7292\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2949 - precision: 0.8427 - recall: 0.7447 - val_loss: 0.3395 - val_precision: 0.8195 - val_recall: 0.7324\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2915 - precision: 0.8435 - recall: 0.7494 - val_loss: 0.3346 - val_precision: 0.8191 - val_recall: 0.7412\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2877 - precision: 0.8443 - recall: 0.7572 - val_loss: 0.3302 - val_precision: 0.8232 - val_recall: 0.7476\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2838 - precision: 0.8454 - recall: 0.7604 - val_loss: 0.3282 - val_precision: 0.8182 - val_recall: 0.7548\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2806 - precision: 0.8466 - recall: 0.7651 - val_loss: 0.3269 - val_precision: 0.8192 - val_recall: 0.7564\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2778 - precision: 0.8473 - recall: 0.7689 - val_loss: 0.3232 - val_precision: 0.8228 - val_recall: 0.7604\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2742 - precision: 0.8465 - recall: 0.7723 - val_loss: 0.3210 - val_precision: 0.8210 - val_recall: 0.7620\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2716 - precision: 0.8479 - recall: 0.7787 - val_loss: 0.3203 - val_precision: 0.8227 - val_recall: 0.7596\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2684 - precision: 0.8490 - recall: 0.7837 - val_loss: 0.3188 - val_precision: 0.8271 - val_recall: 0.7604\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2647 - precision: 0.8499 - recall: 0.7880 - val_loss: 0.3157 - val_precision: 0.8323 - val_recall: 0.7652\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2616 - precision: 0.8516 - recall: 0.7914 - val_loss: 0.3140 - val_precision: 0.8317 - val_recall: 0.7620\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2581 - precision: 0.8538 - recall: 0.7944 - val_loss: 0.3110 - val_precision: 0.8408 - val_recall: 0.7596\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2546 - precision: 0.8563 - recall: 0.7978 - val_loss: 0.3076 - val_precision: 0.8413 - val_recall: 0.7620\n",
      "Epoch 49/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2509 - precision: 0.8568 - recall: 0.8022 - val_loss: 0.3060 - val_precision: 0.8414 - val_recall: 0.7540\n",
      "Epoch 50/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2476 - precision: 0.8589 - recall: 0.8062 - val_loss: 0.3037 - val_precision: 0.8418 - val_recall: 0.7524\n",
      "Epoch 51/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2443 - precision: 0.8609 - recall: 0.8092 - val_loss: 0.3012 - val_precision: 0.8447 - val_recall: 0.7644\n",
      "Epoch 52/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2415 - precision: 0.8618 - recall: 0.8128 - val_loss: 0.3006 - val_precision: 0.8370 - val_recall: 0.7668\n",
      "Epoch 53/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2378 - precision: 0.8640 - recall: 0.8171 - val_loss: 0.2984 - val_precision: 0.8420 - val_recall: 0.7620\n",
      "Epoch 54/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2349 - precision: 0.8619 - recall: 0.8183 - val_loss: 0.2954 - val_precision: 0.8422 - val_recall: 0.7628\n",
      "Epoch 55/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2314 - precision: 0.8662 - recall: 0.8228 - val_loss: 0.2933 - val_precision: 0.8355 - val_recall: 0.7708\n",
      "Epoch 56/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2285 - precision: 0.8644 - recall: 0.8253 - val_loss: 0.2903 - val_precision: 0.8351 - val_recall: 0.7684\n",
      "Epoch 57/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2258 - precision: 0.8670 - recall: 0.8275 - val_loss: 0.2889 - val_precision: 0.8354 - val_recall: 0.7700\n",
      "Epoch 58/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2227 - precision: 0.8677 - recall: 0.8313 - val_loss: 0.2875 - val_precision: 0.8357 - val_recall: 0.7676\n",
      "Epoch 59/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2184 - precision: 0.8704 - recall: 0.8340 - val_loss: 0.2862 - val_precision: 0.8427 - val_recall: 0.7700\n",
      "Epoch 60/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2163 - precision: 0.8721 - recall: 0.8366 - val_loss: 0.2838 - val_precision: 0.8414 - val_recall: 0.7796\n",
      "Epoch 61/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2139 - precision: 0.8741 - recall: 0.8398 - val_loss: 0.2836 - val_precision: 0.8401 - val_recall: 0.7804\n",
      "Epoch 62/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2111 - precision: 0.8772 - recall: 0.8417 - val_loss: 0.2836 - val_precision: 0.8440 - val_recall: 0.7819\n",
      "Epoch 63/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2082 - precision: 0.8793 - recall: 0.8455 - val_loss: 0.2827 - val_precision: 0.8422 - val_recall: 0.7843\n",
      "Epoch 64/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2055 - precision: 0.8813 - recall: 0.8480 - val_loss: 0.2794 - val_precision: 0.8429 - val_recall: 0.7883\n",
      "Epoch 65/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2030 - precision: 0.8821 - recall: 0.8493 - val_loss: 0.2767 - val_precision: 0.8490 - val_recall: 0.7859\n",
      "Epoch 66/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.2009 - precision: 0.8843 - recall: 0.8531 - val_loss: 0.2781 - val_precision: 0.8440 - val_recall: 0.7907\n",
      "Epoch 67/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1982 - precision: 0.8876 - recall: 0.8551 - val_loss: 0.2783 - val_precision: 0.8434 - val_recall: 0.7915\n",
      "Epoch 68/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1954 - precision: 0.8905 - recall: 0.8563 - val_loss: 0.2751 - val_precision: 0.8445 - val_recall: 0.7851\n",
      "Epoch 69/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1937 - precision: 0.8916 - recall: 0.8604 - val_loss: 0.2773 - val_precision: 0.8476 - val_recall: 0.7907\n",
      "Epoch 70/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1928 - precision: 0.8901 - recall: 0.8591 - val_loss: 0.2779 - val_precision: 0.8476 - val_recall: 0.7907\n",
      "Epoch 71/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1903 - precision: 0.8911 - recall: 0.8612 - val_loss: 0.2744 - val_precision: 0.8469 - val_recall: 0.7907\n",
      "Epoch 72/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1880 - precision: 0.8949 - recall: 0.8638 - val_loss: 0.2731 - val_precision: 0.8464 - val_recall: 0.7923\n",
      "Epoch 73/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1865 - precision: 0.8953 - recall: 0.8642 - val_loss: 0.2765 - val_precision: 0.8435 - val_recall: 0.7963\n",
      "Epoch 74/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1854 - precision: 0.8974 - recall: 0.8671 - val_loss: 0.2778 - val_precision: 0.8537 - val_recall: 0.7875\n",
      "Epoch 75/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1838 - precision: 0.8985 - recall: 0.8680 - val_loss: 0.2807 - val_precision: 0.8509 - val_recall: 0.7931\n",
      "Epoch 76/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1826 - precision: 0.8993 - recall: 0.8684 - val_loss: 0.2741 - val_precision: 0.8541 - val_recall: 0.7947\n",
      "Epoch 77/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1812 - precision: 0.8995 - recall: 0.8720 - val_loss: 0.2689 - val_precision: 0.8522 - val_recall: 0.7923\n",
      "Epoch 78/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1801 - precision: 0.9034 - recall: 0.8729 - val_loss: 0.2619 - val_precision: 0.8570 - val_recall: 0.7995\n",
      "Epoch 79/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1786 - precision: 0.9021 - recall: 0.8756 - val_loss: 0.2592 - val_precision: 0.8546 - val_recall: 0.8027\n",
      "Epoch 80/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1776 - precision: 0.9009 - recall: 0.8737 - val_loss: 0.2577 - val_precision: 0.8580 - val_recall: 0.8011\n",
      "Epoch 81/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1740 - precision: 0.9058 - recall: 0.8752 - val_loss: 0.2570 - val_precision: 0.8502 - val_recall: 0.8067\n",
      "Epoch 82/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1729 - precision: 0.9065 - recall: 0.8786 - val_loss: 0.2556 - val_precision: 0.8509 - val_recall: 0.8115\n",
      "Epoch 83/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1707 - precision: 0.9077 - recall: 0.8790 - val_loss: 0.2568 - val_precision: 0.8441 - val_recall: 0.8131\n",
      "Epoch 84/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1702 - precision: 0.9094 - recall: 0.8799 - val_loss: 0.2542 - val_precision: 0.8444 - val_recall: 0.8195\n",
      "Epoch 85/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1710 - precision: 0.9075 - recall: 0.8790 - val_loss: 0.2588 - val_precision: 0.8430 - val_recall: 0.8235\n",
      "Epoch 86/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1693 - precision: 0.9088 - recall: 0.8835 - val_loss: 0.2488 - val_precision: 0.8544 - val_recall: 0.8251\n",
      "Epoch 87/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1656 - precision: 0.9099 - recall: 0.8854 - val_loss: 0.2468 - val_precision: 0.8551 - val_recall: 0.8251\n",
      "Epoch 88/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1632 - precision: 0.9111 - recall: 0.8879 - val_loss: 0.2496 - val_precision: 0.8541 - val_recall: 0.8275\n",
      "Epoch 89/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1622 - precision: 0.9110 - recall: 0.8882 - val_loss: 0.2441 - val_precision: 0.8704 - val_recall: 0.8099\n",
      "Epoch 90/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1601 - precision: 0.9118 - recall: 0.8911 - val_loss: 0.2439 - val_precision: 0.8699 - val_recall: 0.8171\n",
      "Epoch 91/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1578 - precision: 0.9129 - recall: 0.8947 - val_loss: 0.2433 - val_precision: 0.8724 - val_recall: 0.8139\n",
      "Epoch 92/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1551 - precision: 0.9174 - recall: 0.8933 - val_loss: 0.2445 - val_precision: 0.8752 - val_recall: 0.8123\n",
      "Epoch 93/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1536 - precision: 0.9177 - recall: 0.8969 - val_loss: 0.2423 - val_precision: 0.8778 - val_recall: 0.8147\n",
      "Epoch 94/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1526 - precision: 0.9189 - recall: 0.8971 - val_loss: 0.2399 - val_precision: 0.8772 - val_recall: 0.8219\n",
      "Epoch 95/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1524 - precision: 0.9186 - recall: 0.8977 - val_loss: 0.2414 - val_precision: 0.8812 - val_recall: 0.8179\n",
      "Epoch 96/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1495 - precision: 0.9193 - recall: 0.9015 - val_loss: 0.2417 - val_precision: 0.8830 - val_recall: 0.8139\n",
      "Epoch 97/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1481 - precision: 0.9185 - recall: 0.9037 - val_loss: 0.2386 - val_precision: 0.8768 - val_recall: 0.8187\n",
      "Epoch 98/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1461 - precision: 0.9235 - recall: 0.9049 - val_loss: 0.2376 - val_precision: 0.8796 - val_recall: 0.8227\n",
      "Epoch 99/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1452 - precision: 0.9205 - recall: 0.9062 - val_loss: 0.2334 - val_precision: 0.8826 - val_recall: 0.8283\n",
      "Epoch 100/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1418 - precision: 0.9199 - recall: 0.9064 - val_loss: 0.2323 - val_precision: 0.8788 - val_recall: 0.8339\n",
      "Epoch 101/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1392 - precision: 0.9223 - recall: 0.9096 - val_loss: 0.2330 - val_precision: 0.8809 - val_recall: 0.8331\n",
      "Epoch 102/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1385 - precision: 0.9233 - recall: 0.9124 - val_loss: 0.2341 - val_precision: 0.8816 - val_recall: 0.8387\n",
      "Epoch 103/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1406 - precision: 0.9210 - recall: 0.9083 - val_loss: 0.2429 - val_precision: 0.8785 - val_recall: 0.8203\n",
      "Epoch 104/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1399 - precision: 0.9207 - recall: 0.9092 - val_loss: 0.2464 - val_precision: 0.8927 - val_recall: 0.8043\n",
      "Epoch 105/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.1378 - precision: 0.9217 - recall: 0.9115 - val_loss: 0.2527 - val_precision: 0.8868 - val_recall: 0.8195\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765546602.059069 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 0.5182 - precision: 0.7820 - recall: 0.4726 - val_loss: 0.5331 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4802 - precision: 0.8192 - recall: 0.4913 - val_loss: 0.4982 - val_precision: 0.8348 - val_recall: 0.4561\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4641 - precision: 0.8353 - recall: 0.4983 - val_loss: 0.4824 - val_precision: 0.8413 - val_recall: 0.4617\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4597 - precision: 0.8391 - recall: 0.5025 - val_loss: 0.4724 - val_precision: 0.8437 - val_recall: 0.4872\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4532 - precision: 0.8470 - recall: 0.5076 - val_loss: 0.4669 - val_precision: 0.8456 - val_recall: 0.4856\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4469 - precision: 0.8472 - recall: 0.5155 - val_loss: 0.4600 - val_precision: 0.8506 - val_recall: 0.4912\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.4407 - precision: 0.8510 - recall: 0.5166 - val_loss: 0.4523 - val_precision: 0.8565 - val_recall: 0.4912\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4288 - precision: 0.8417 - recall: 0.5369 - val_loss: 0.4384 - val_precision: 0.8474 - val_recall: 0.5144\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4319 - precision: 0.8428 - recall: 0.5348 - val_loss: 0.4381 - val_precision: 0.8292 - val_recall: 0.5351\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.4101 - precision: 0.8179 - recall: 0.5766 - val_loss: 0.4098 - val_precision: 0.8315 - val_recall: 0.6070\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3940 - precision: 0.8079 - recall: 0.5997 - val_loss: 0.4060 - val_precision: 0.8615 - val_recall: 0.5663\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3792 - precision: 0.8091 - recall: 0.6133 - val_loss: 0.3876 - val_precision: 0.8193 - val_recall: 0.6661\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3619 - precision: 0.8108 - recall: 0.6439 - val_loss: 0.3698 - val_precision: 0.8395 - val_recall: 0.6478\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.3451 - precision: 0.8142 - recall: 0.6825 - val_loss: 0.3605 - val_precision: 0.8411 - val_recall: 0.6637\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.3281 - precision: 0.8244 - recall: 0.7103 - val_loss: 0.3489 - val_precision: 0.8428 - val_recall: 0.6893\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.3102 - precision: 0.8263 - recall: 0.7309 - val_loss: 0.3331 - val_precision: 0.8446 - val_recall: 0.7077\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2922 - precision: 0.8410 - recall: 0.7523 - val_loss: 0.3307 - val_precision: 0.8505 - val_recall: 0.6861\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2807 - precision: 0.8473 - recall: 0.7653 - val_loss: 0.3112 - val_precision: 0.8478 - val_recall: 0.7388\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2632 - precision: 0.8538 - recall: 0.7859 - val_loss: 0.2945 - val_precision: 0.8449 - val_recall: 0.7748\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2523 - precision: 0.8561 - recall: 0.7967 - val_loss: 0.2834 - val_precision: 0.8561 - val_recall: 0.7700\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2388 - precision: 0.8630 - recall: 0.8090 - val_loss: 0.2733 - val_precision: 0.8747 - val_recall: 0.7804\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.2215 - precision: 0.8751 - recall: 0.8264 - val_loss: 0.2655 - val_precision: 0.8676 - val_recall: 0.7955\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.2144 - precision: 0.8780 - recall: 0.8372 - val_loss: 0.2538 - val_precision: 0.8703 - val_recall: 0.8091\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1993 - precision: 0.8877 - recall: 0.8504 - val_loss: 0.2472 - val_precision: 0.8758 - val_recall: 0.7995\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1899 - precision: 0.8894 - recall: 0.8614 - val_loss: 0.2407 - val_precision: 0.8869 - val_recall: 0.8267\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1775 - precision: 0.8982 - recall: 0.8748 - val_loss: 0.2389 - val_precision: 0.8895 - val_recall: 0.8163\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1730 - precision: 0.8948 - recall: 0.8773 - val_loss: 0.2344 - val_precision: 0.8801 - val_recall: 0.8498\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1669 - precision: 0.8986 - recall: 0.8801 - val_loss: 0.2286 - val_precision: 0.8926 - val_recall: 0.8427\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1595 - precision: 0.9043 - recall: 0.8922 - val_loss: 0.2136 - val_precision: 0.9015 - val_recall: 0.8482\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1598 - precision: 0.9014 - recall: 0.8922 - val_loss: 0.2030 - val_precision: 0.9206 - val_recall: 0.8427\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1339 - precision: 0.9194 - recall: 0.9151 - val_loss: 0.1929 - val_precision: 0.9320 - val_recall: 0.8538\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1322 - precision: 0.9179 - recall: 0.9092 - val_loss: 0.1968 - val_precision: 0.9197 - val_recall: 0.8594\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1261 - precision: 0.9222 - recall: 0.9155 - val_loss: 0.1950 - val_precision: 0.9140 - val_recall: 0.8570\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1163 - precision: 0.9292 - recall: 0.9251 - val_loss: 0.1998 - val_precision: 0.8856 - val_recall: 0.8714\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1156 - precision: 0.9284 - recall: 0.9300 - val_loss: 0.1820 - val_precision: 0.9234 - val_recall: 0.8762\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1077 - precision: 0.9376 - recall: 0.9312 - val_loss: 0.1834 - val_precision: 0.9469 - val_recall: 0.8403\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0992 - precision: 0.9408 - recall: 0.9368 - val_loss: 0.1872 - val_precision: 0.9385 - val_recall: 0.8538\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0981 - precision: 0.9398 - recall: 0.9372 - val_loss: 0.1872 - val_precision: 0.9349 - val_recall: 0.8722\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.1021 - precision: 0.9405 - recall: 0.9385 - val_loss: 0.2041 - val_precision: 0.9224 - val_recall: 0.8546\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0987 - precision: 0.9409 - recall: 0.9387 - val_loss: 0.1730 - val_precision: 0.9364 - val_recall: 0.9058\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0911 - precision: 0.9460 - recall: 0.9442 - val_loss: 0.1783 - val_precision: 0.9308 - val_recall: 0.8914\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0872 - precision: 0.9456 - recall: 0.9440 - val_loss: 0.1955 - val_precision: 0.9155 - val_recall: 0.8914\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0907 - precision: 0.9434 - recall: 0.9446 - val_loss: 0.2295 - val_precision: 0.9269 - val_recall: 0.8714\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.0823 - precision: 0.9528 - recall: 0.9503 - val_loss: 0.2052 - val_precision: 0.9405 - val_recall: 0.8714\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.0804 - precision: 0.9534 - recall: 0.9518 - val_loss: 0.1973 - val_precision: 0.9350 - val_recall: 0.8730\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765546935.227894 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.4935 - precision: 0.8059 - recall: 0.4847 - val_loss: 0.4787 - val_precision: 0.8683 - val_recall: 0.4425\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.4505 - precision: 0.8317 - recall: 0.5015 - val_loss: 0.4573 - val_precision: 0.8622 - val_recall: 0.4696\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.4322 - precision: 0.8309 - recall: 0.5204 - val_loss: 0.4431 - val_precision: 0.8434 - val_recall: 0.5120\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4241 - precision: 0.8257 - recall: 0.5380 - val_loss: 0.4390 - val_precision: 0.8508 - val_recall: 0.5192\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4153 - precision: 0.8280 - recall: 0.5497 - val_loss: 0.4286 - val_precision: 0.8390 - val_recall: 0.5495\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4067 - precision: 0.8247 - recall: 0.5673 - val_loss: 0.4200 - val_precision: 0.8520 - val_recall: 0.5519\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3977 - precision: 0.8223 - recall: 0.5745 - val_loss: 0.4133 - val_precision: 0.8543 - val_recall: 0.5575\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3875 - precision: 0.8265 - recall: 0.5802 - val_loss: 0.4028 - val_precision: 0.8490 - val_recall: 0.5703\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3810 - precision: 0.8291 - recall: 0.5932 - val_loss: 0.3952 - val_precision: 0.8417 - val_recall: 0.6030\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3696 - precision: 0.8316 - recall: 0.6080 - val_loss: 0.3861 - val_precision: 0.8314 - val_recall: 0.6302\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3576 - precision: 0.8254 - recall: 0.6282 - val_loss: 0.3766 - val_precision: 0.8351 - val_recall: 0.6310\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3446 - precision: 0.8271 - recall: 0.6517 - val_loss: 0.3697 - val_precision: 0.8504 - val_recall: 0.6358\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3322 - precision: 0.8273 - recall: 0.6749 - val_loss: 0.3629 - val_precision: 0.8680 - val_recall: 0.6198\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3217 - precision: 0.8305 - recall: 0.7020 - val_loss: 0.3535 - val_precision: 0.8580 - val_recall: 0.6565\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3110 - precision: 0.8376 - recall: 0.7247 - val_loss: 0.3496 - val_precision: 0.8667 - val_recall: 0.6597\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3020 - precision: 0.8383 - recall: 0.7362 - val_loss: 0.3434 - val_precision: 0.8582 - val_recall: 0.6765\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2921 - precision: 0.8432 - recall: 0.7511 - val_loss: 0.3368 - val_precision: 0.8598 - val_recall: 0.7053\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2822 - precision: 0.8474 - recall: 0.7600 - val_loss: 0.3223 - val_precision: 0.8517 - val_recall: 0.7204\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2705 - precision: 0.8523 - recall: 0.7789 - val_loss: 0.3085 - val_precision: 0.8599 - val_recall: 0.7356\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2615 - precision: 0.8557 - recall: 0.7876 - val_loss: 0.3000 - val_precision: 0.8449 - val_recall: 0.7612\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2517 - precision: 0.8622 - recall: 0.7992 - val_loss: 0.2934 - val_precision: 0.8449 - val_recall: 0.7660\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2423 - precision: 0.8666 - recall: 0.8109 - val_loss: 0.2898 - val_precision: 0.8570 - val_recall: 0.7660\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2343 - precision: 0.8706 - recall: 0.8183 - val_loss: 0.2787 - val_precision: 0.8587 - val_recall: 0.7764\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2267 - precision: 0.8744 - recall: 0.8256 - val_loss: 0.2712 - val_precision: 0.8629 - val_recall: 0.7995\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2170 - precision: 0.8779 - recall: 0.8360 - val_loss: 0.2647 - val_precision: 0.8718 - val_recall: 0.8035\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2095 - precision: 0.8816 - recall: 0.8425 - val_loss: 0.2713 - val_precision: 0.8667 - val_recall: 0.7891\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.2029 - precision: 0.8819 - recall: 0.8478 - val_loss: 0.2721 - val_precision: 0.8736 - val_recall: 0.7620\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1971 - precision: 0.8849 - recall: 0.8546 - val_loss: 0.2655 - val_precision: 0.8716 - val_recall: 0.7859\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1896 - precision: 0.8885 - recall: 0.8674 - val_loss: 0.2633 - val_precision: 0.9046 - val_recall: 0.7572\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1811 - precision: 0.8949 - recall: 0.8708 - val_loss: 0.2525 - val_precision: 0.9075 - val_recall: 0.7684\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1774 - precision: 0.8990 - recall: 0.8769 - val_loss: 0.2528 - val_precision: 0.8925 - val_recall: 0.7827\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1699 - precision: 0.9019 - recall: 0.8837 - val_loss: 0.2456 - val_precision: 0.8967 - val_recall: 0.7907\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1625 - precision: 0.9068 - recall: 0.8903 - val_loss: 0.2389 - val_precision: 0.9075 - val_recall: 0.7995\n",
      "Epoch 34/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1552 - precision: 0.9090 - recall: 0.8941 - val_loss: 0.2384 - val_precision: 0.9036 - val_recall: 0.8163\n",
      "Epoch 35/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1534 - precision: 0.9097 - recall: 0.8983 - val_loss: 0.2538 - val_precision: 0.9185 - val_recall: 0.7652\n",
      "Epoch 36/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1476 - precision: 0.9178 - recall: 0.9056 - val_loss: 0.2451 - val_precision: 0.9140 - val_recall: 0.7891\n",
      "Epoch 37/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1467 - precision: 0.9155 - recall: 0.9034 - val_loss: 0.2424 - val_precision: 0.9138 - val_recall: 0.7875\n",
      "Epoch 38/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1418 - precision: 0.9176 - recall: 0.9077 - val_loss: 0.2282 - val_precision: 0.9012 - val_recall: 0.8163\n",
      "Epoch 39/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1357 - precision: 0.9224 - recall: 0.9128 - val_loss: 0.2246 - val_precision: 0.9129 - val_recall: 0.8123\n",
      "Epoch 40/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1269 - precision: 0.9245 - recall: 0.9221 - val_loss: 0.2242 - val_precision: 0.9088 - val_recall: 0.8195\n",
      "Epoch 41/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1221 - precision: 0.9270 - recall: 0.9249 - val_loss: 0.2182 - val_precision: 0.9096 - val_recall: 0.8355\n",
      "Epoch 42/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1180 - precision: 0.9303 - recall: 0.9240 - val_loss: 0.2171 - val_precision: 0.9201 - val_recall: 0.8283\n",
      "Epoch 43/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1131 - precision: 0.9330 - recall: 0.9308 - val_loss: 0.2179 - val_precision: 0.9242 - val_recall: 0.8379\n",
      "Epoch 44/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1105 - precision: 0.9344 - recall: 0.9304 - val_loss: 0.2103 - val_precision: 0.9218 - val_recall: 0.8379\n",
      "Epoch 45/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1109 - precision: 0.9322 - recall: 0.9274 - val_loss: 0.2126 - val_precision: 0.9210 - val_recall: 0.8283\n",
      "Epoch 46/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1120 - precision: 0.9320 - recall: 0.9274 - val_loss: 0.2366 - val_precision: 0.9294 - val_recall: 0.8099\n",
      "Epoch 47/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1126 - precision: 0.9357 - recall: 0.9302 - val_loss: 0.2208 - val_precision: 0.9272 - val_recall: 0.8235\n",
      "Epoch 48/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1065 - precision: 0.9369 - recall: 0.9353 - val_loss: 0.2034 - val_precision: 0.9170 - val_recall: 0.8466\n",
      "Epoch 49/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0989 - precision: 0.9415 - recall: 0.9393 - val_loss: 0.1922 - val_precision: 0.9270 - val_recall: 0.8514\n",
      "Epoch 50/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1034 - precision: 0.9397 - recall: 0.9399 - val_loss: 0.2321 - val_precision: 0.9479 - val_recall: 0.7995\n",
      "Epoch 51/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1001 - precision: 0.9400 - recall: 0.9348 - val_loss: 0.2146 - val_precision: 0.9386 - val_recall: 0.8299\n",
      "Epoch 52/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0915 - precision: 0.9451 - recall: 0.9433 - val_loss: 0.2311 - val_precision: 0.9318 - val_recall: 0.8187\n",
      "Epoch 53/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0842 - precision: 0.9491 - recall: 0.9501 - val_loss: 0.2122 - val_precision: 0.9346 - val_recall: 0.8562\n",
      "Epoch 54/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0822 - precision: 0.9519 - recall: 0.9497 - val_loss: 0.2295 - val_precision: 0.9371 - val_recall: 0.8331\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765547359.173736 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - loss: 0.5217 - precision: 0.7942 - recall: 0.4767 - val_loss: 0.5266 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 2/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.5095 - precision: 0.7976 - recall: 0.4767 - val_loss: 0.5201 - val_precision: 0.8153 - val_recall: 0.4585\n",
      "Epoch 3/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4818 - precision: 0.8123 - recall: 0.4877 - val_loss: 0.4802 - val_precision: 0.8503 - val_recall: 0.4808\n",
      "Epoch 4/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.4724 - precision: 0.8438 - recall: 0.4873 - val_loss: 0.4748 - val_precision: 0.8555 - val_recall: 0.4776\n",
      "Epoch 5/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4527 - precision: 0.8556 - recall: 0.5053 - val_loss: 0.4665 - val_precision: 0.8549 - val_recall: 0.4848\n",
      "Epoch 6/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4426 - precision: 0.8491 - recall: 0.5159 - val_loss: 0.4477 - val_precision: 0.8545 - val_recall: 0.4832\n",
      "Epoch 7/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4241 - precision: 0.8422 - recall: 0.5414 - val_loss: 0.4339 - val_precision: 0.8394 - val_recall: 0.5383\n",
      "Epoch 8/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.4084 - precision: 0.8257 - recall: 0.5772 - val_loss: 0.4217 - val_precision: 0.8328 - val_recall: 0.5727\n",
      "Epoch 9/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3886 - precision: 0.8046 - recall: 0.6231 - val_loss: 0.4225 - val_precision: 0.8260 - val_recall: 0.5990\n",
      "Epoch 10/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3707 - precision: 0.8087 - recall: 0.6488 - val_loss: 0.3949 - val_precision: 0.8291 - val_recall: 0.6318\n",
      "Epoch 11/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3706 - precision: 0.8024 - recall: 0.6505 - val_loss: 0.3945 - val_precision: 0.8483 - val_recall: 0.5895\n",
      "Epoch 12/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3325 - precision: 0.8220 - recall: 0.7025 - val_loss: 0.3641 - val_precision: 0.8589 - val_recall: 0.6270\n",
      "Epoch 13/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.3072 - precision: 0.8407 - recall: 0.7368 - val_loss: 0.3469 - val_precision: 0.8485 - val_recall: 0.6709\n",
      "Epoch 14/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.2839 - precision: 0.8488 - recall: 0.7670 - val_loss: 0.3364 - val_precision: 0.8594 - val_recall: 0.6981\n",
      "Epoch 15/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.2645 - precision: 0.8554 - recall: 0.7937 - val_loss: 0.3501 - val_precision: 0.8718 - val_recall: 0.6733\n",
      "Epoch 16/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.2425 - precision: 0.8632 - recall: 0.8143 - val_loss: 0.3345 - val_precision: 0.8796 - val_recall: 0.7117\n",
      "Epoch 17/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2261 - precision: 0.8705 - recall: 0.8315 - val_loss: 0.3136 - val_precision: 0.8925 - val_recall: 0.7165\n",
      "Epoch 18/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.2049 - precision: 0.8820 - recall: 0.8487 - val_loss: 0.3273 - val_precision: 0.8841 - val_recall: 0.7005\n",
      "Epoch 19/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1935 - precision: 0.8877 - recall: 0.8625 - val_loss: 0.3000 - val_precision: 0.8786 - val_recall: 0.7396\n",
      "Epoch 20/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1826 - precision: 0.8910 - recall: 0.8722 - val_loss: 0.2961 - val_precision: 0.8738 - val_recall: 0.7356\n",
      "Epoch 21/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1667 - precision: 0.9043 - recall: 0.8882 - val_loss: 0.2985 - val_precision: 0.8816 - val_recall: 0.7436\n",
      "Epoch 22/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.1608 - precision: 0.9078 - recall: 0.8922 - val_loss: 0.2716 - val_precision: 0.8788 - val_recall: 0.7931\n",
      "Epoch 23/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1462 - precision: 0.9163 - recall: 0.8992 - val_loss: 0.2629 - val_precision: 0.9049 - val_recall: 0.7748\n",
      "Epoch 24/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1324 - precision: 0.9223 - recall: 0.9149 - val_loss: 0.2182 - val_precision: 0.8927 - val_recall: 0.8442\n",
      "Epoch 25/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1230 - precision: 0.9294 - recall: 0.9132 - val_loss: 0.2016 - val_precision: 0.8923 - val_recall: 0.8866\n",
      "Epoch 26/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.1080 - precision: 0.9385 - recall: 0.9291 - val_loss: 0.2034 - val_precision: 0.8755 - val_recall: 0.9042\n",
      "Epoch 27/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0969 - precision: 0.9429 - recall: 0.9385 - val_loss: 0.2340 - val_precision: 0.8617 - val_recall: 0.9209\n",
      "Epoch 28/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0934 - precision: 0.9461 - recall: 0.9425 - val_loss: 0.2014 - val_precision: 0.8758 - val_recall: 0.9121\n",
      "Epoch 29/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0875 - precision: 0.9475 - recall: 0.9457 - val_loss: 0.2110 - val_precision: 0.8974 - val_recall: 0.9225\n",
      "Epoch 30/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0789 - precision: 0.9528 - recall: 0.9508 - val_loss: 0.2307 - val_precision: 0.8866 - val_recall: 0.9177\n",
      "Epoch 31/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0854 - precision: 0.9506 - recall: 0.9514 - val_loss: 0.2234 - val_precision: 0.8872 - val_recall: 0.9050\n",
      "Epoch 32/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.0688 - precision: 0.9561 - recall: 0.9559 - val_loss: 0.2299 - val_precision: 0.9279 - val_recall: 0.8842\n",
      "Epoch 33/120\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 0.0573 - precision: 0.9655 - recall: 0.9633 - val_loss: 0.2516 - val_precision: 0.9334 - val_recall: 0.8842\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765547616.087496 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "{'batch_size': 16, 'layer_number': 4, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ================== INIZIO CICLO CON SEED: 555 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n",
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - loss: 0.4963 - precision: 0.8164 - recall: 0.4743 - val_loss: 0.4682 - val_precision: 0.8379 - val_recall: 0.4873\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.4484 - precision: 0.8316 - recall: 0.5032 - val_loss: 0.4419 - val_precision: 0.8447 - val_recall: 0.5397\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.4328 - precision: 0.8249 - recall: 0.5384 - val_loss: 0.4321 - val_precision: 0.8131 - val_recall: 0.5755\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.4229 - precision: 0.8122 - recall: 0.5603 - val_loss: 0.4268 - val_precision: 0.8046 - val_recall: 0.6014\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.4160 - precision: 0.8110 - recall: 0.5705 - val_loss: 0.4201 - val_precision: 0.8069 - val_recall: 0.6103\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.4095 - precision: 0.8108 - recall: 0.5791 - val_loss: 0.4143 - val_precision: 0.8020 - val_recall: 0.6207\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.4047 - precision: 0.8119 - recall: 0.5878 - val_loss: 0.4093 - val_precision: 0.8040 - val_recall: 0.6196\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3996 - precision: 0.8117 - recall: 0.5910 - val_loss: 0.4069 - val_precision: 0.7888 - val_recall: 0.6362\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3948 - precision: 0.8123 - recall: 0.5930 - val_loss: 0.3971 - val_precision: 0.8085 - val_recall: 0.6213\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3891 - precision: 0.8159 - recall: 0.5965 - val_loss: 0.3891 - val_precision: 0.8114 - val_recall: 0.6262\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.3833 - precision: 0.8194 - recall: 0.6014 - val_loss: 0.3810 - val_precision: 0.8089 - val_recall: 0.6345\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3773 - precision: 0.8210 - recall: 0.6116 - val_loss: 0.3755 - val_precision: 0.8071 - val_recall: 0.6433\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3719 - precision: 0.8202 - recall: 0.6211 - val_loss: 0.3656 - val_precision: 0.8174 - val_recall: 0.6488\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3660 - precision: 0.8207 - recall: 0.6283 - val_loss: 0.3647 - val_precision: 0.8075 - val_recall: 0.6544\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3610 - precision: 0.8203 - recall: 0.6377 - val_loss: 0.3601 - val_precision: 0.8122 - val_recall: 0.6582\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.3559 - precision: 0.8188 - recall: 0.6475 - val_loss: 0.3579 - val_precision: 0.8123 - val_recall: 0.6560\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3504 - precision: 0.8191 - recall: 0.6558 - val_loss: 0.3547 - val_precision: 0.8168 - val_recall: 0.6637\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3461 - precision: 0.8187 - recall: 0.6659 - val_loss: 0.3516 - val_precision: 0.8267 - val_recall: 0.6654\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3416 - precision: 0.8212 - recall: 0.6729 - val_loss: 0.3464 - val_precision: 0.8192 - val_recall: 0.6819\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3365 - precision: 0.8228 - recall: 0.6830 - val_loss: 0.3394 - val_precision: 0.8248 - val_recall: 0.6957\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3319 - precision: 0.8275 - recall: 0.6917 - val_loss: 0.3409 - val_precision: 0.8232 - val_recall: 0.6957\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3274 - precision: 0.8267 - recall: 0.6997 - val_loss: 0.3384 - val_precision: 0.8180 - val_recall: 0.7111\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3220 - precision: 0.8302 - recall: 0.7093 - val_loss: 0.3324 - val_precision: 0.8127 - val_recall: 0.7249\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3173 - precision: 0.8342 - recall: 0.7204 - val_loss: 0.3304 - val_precision: 0.8033 - val_recall: 0.7315\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3129 - precision: 0.8339 - recall: 0.7243 - val_loss: 0.3295 - val_precision: 0.7977 - val_recall: 0.7393\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3080 - precision: 0.8387 - recall: 0.7314 - val_loss: 0.3295 - val_precision: 0.7956 - val_recall: 0.7530\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3035 - precision: 0.8394 - recall: 0.7386 - val_loss: 0.3240 - val_precision: 0.7890 - val_recall: 0.7668\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2984 - precision: 0.8393 - recall: 0.7434 - val_loss: 0.3207 - val_precision: 0.7909 - val_recall: 0.7734\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2940 - precision: 0.8408 - recall: 0.7478 - val_loss: 0.3227 - val_precision: 0.7873 - val_recall: 0.7817\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2892 - precision: 0.8443 - recall: 0.7567 - val_loss: 0.3165 - val_precision: 0.7969 - val_recall: 0.7872\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2857 - precision: 0.8457 - recall: 0.7593 - val_loss: 0.3127 - val_precision: 0.7934 - val_recall: 0.7916\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2814 - precision: 0.8467 - recall: 0.7643 - val_loss: 0.3118 - val_precision: 0.7825 - val_recall: 0.8054\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2769 - precision: 0.8507 - recall: 0.7691 - val_loss: 0.3068 - val_precision: 0.7890 - val_recall: 0.8120\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2718 - precision: 0.8545 - recall: 0.7755 - val_loss: 0.3038 - val_precision: 0.7886 - val_recall: 0.8164\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2682 - precision: 0.8547 - recall: 0.7796 - val_loss: 0.3013 - val_precision: 0.7925 - val_recall: 0.8104\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2649 - precision: 0.8558 - recall: 0.7828 - val_loss: 0.2977 - val_precision: 0.7895 - val_recall: 0.8208\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2613 - precision: 0.8560 - recall: 0.7879 - val_loss: 0.2979 - val_precision: 0.7879 - val_recall: 0.8275\n",
      "Epoch 38/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2573 - precision: 0.8568 - recall: 0.7922 - val_loss: 0.2996 - val_precision: 0.7878 - val_recall: 0.8225\n",
      "Epoch 39/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2549 - precision: 0.8572 - recall: 0.7960 - val_loss: 0.2999 - val_precision: 0.7966 - val_recall: 0.8203\n",
      "Epoch 40/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2510 - precision: 0.8604 - recall: 0.8003 - val_loss: 0.2955 - val_precision: 0.7960 - val_recall: 0.8258\n",
      "Epoch 41/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2483 - precision: 0.8612 - recall: 0.8023 - val_loss: 0.2912 - val_precision: 0.8051 - val_recall: 0.8241\n",
      "Epoch 42/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2443 - precision: 0.8650 - recall: 0.8076 - val_loss: 0.2853 - val_precision: 0.8121 - val_recall: 0.8241\n",
      "Epoch 43/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2403 - precision: 0.8656 - recall: 0.8130 - val_loss: 0.2858 - val_precision: 0.8041 - val_recall: 0.8302\n",
      "Epoch 44/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2370 - precision: 0.8661 - recall: 0.8163 - val_loss: 0.2783 - val_precision: 0.8094 - val_recall: 0.8335\n",
      "Epoch 45/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2330 - precision: 0.8704 - recall: 0.8228 - val_loss: 0.2784 - val_precision: 0.8108 - val_recall: 0.8385\n",
      "Epoch 46/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2312 - precision: 0.8692 - recall: 0.8233 - val_loss: 0.2752 - val_precision: 0.8209 - val_recall: 0.8341\n",
      "Epoch 47/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2276 - precision: 0.8715 - recall: 0.8285 - val_loss: 0.2794 - val_precision: 0.8195 - val_recall: 0.8407\n",
      "Epoch 48/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2248 - precision: 0.8739 - recall: 0.8301 - val_loss: 0.2751 - val_precision: 0.8150 - val_recall: 0.8379\n",
      "Epoch 49/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2216 - precision: 0.8785 - recall: 0.8341 - val_loss: 0.2705 - val_precision: 0.8233 - val_recall: 0.8451\n",
      "Epoch 50/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2178 - precision: 0.8800 - recall: 0.8400 - val_loss: 0.2670 - val_precision: 0.8195 - val_recall: 0.8512\n",
      "Epoch 51/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2146 - precision: 0.8803 - recall: 0.8417 - val_loss: 0.2668 - val_precision: 0.8206 - val_recall: 0.8473\n",
      "Epoch 52/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2128 - precision: 0.8802 - recall: 0.8451 - val_loss: 0.2610 - val_precision: 0.8246 - val_recall: 0.8423\n",
      "Epoch 53/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2090 - precision: 0.8827 - recall: 0.8480 - val_loss: 0.2578 - val_precision: 0.8232 - val_recall: 0.8396\n",
      "Epoch 54/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2058 - precision: 0.8861 - recall: 0.8505 - val_loss: 0.2582 - val_precision: 0.8209 - val_recall: 0.8462\n",
      "Epoch 55/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2032 - precision: 0.8859 - recall: 0.8532 - val_loss: 0.2601 - val_precision: 0.8229 - val_recall: 0.8479\n",
      "Epoch 56/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1993 - precision: 0.8883 - recall: 0.8577 - val_loss: 0.2593 - val_precision: 0.8227 - val_recall: 0.8440\n",
      "Epoch 57/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1976 - precision: 0.8890 - recall: 0.8578 - val_loss: 0.2580 - val_precision: 0.8205 - val_recall: 0.8517\n",
      "Epoch 58/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1950 - precision: 0.8898 - recall: 0.8602 - val_loss: 0.2477 - val_precision: 0.8339 - val_recall: 0.8440\n",
      "Epoch 59/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1931 - precision: 0.8891 - recall: 0.8622 - val_loss: 0.2504 - val_precision: 0.8337 - val_recall: 0.8512\n",
      "Epoch 60/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1911 - precision: 0.8917 - recall: 0.8648 - val_loss: 0.2460 - val_precision: 0.8362 - val_recall: 0.8528\n",
      "Epoch 61/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1888 - precision: 0.8921 - recall: 0.8671 - val_loss: 0.2466 - val_precision: 0.8410 - val_recall: 0.8456\n",
      "Epoch 62/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1865 - precision: 0.8940 - recall: 0.8696 - val_loss: 0.2488 - val_precision: 0.8397 - val_recall: 0.8550\n",
      "Epoch 63/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1846 - precision: 0.8947 - recall: 0.8688 - val_loss: 0.2496 - val_precision: 0.8459 - val_recall: 0.8506\n",
      "Epoch 64/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1813 - precision: 0.8962 - recall: 0.8727 - val_loss: 0.2445 - val_precision: 0.8479 - val_recall: 0.8479\n",
      "Epoch 65/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1794 - precision: 0.8963 - recall: 0.8761 - val_loss: 0.2455 - val_precision: 0.8450 - val_recall: 0.8567\n",
      "Epoch 66/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1774 - precision: 0.8990 - recall: 0.8773 - val_loss: 0.2479 - val_precision: 0.8475 - val_recall: 0.8484\n",
      "Epoch 67/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1749 - precision: 0.9005 - recall: 0.8797 - val_loss: 0.2474 - val_precision: 0.8376 - val_recall: 0.8616\n",
      "Epoch 68/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1724 - precision: 0.9018 - recall: 0.8821 - val_loss: 0.2508 - val_precision: 0.8339 - val_recall: 0.8633\n",
      "Epoch 69/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1693 - precision: 0.9053 - recall: 0.8843 - val_loss: 0.2499 - val_precision: 0.8361 - val_recall: 0.8605\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765548368.276181 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - loss: 0.5133 - precision: 0.7992 - recall: 0.4734 - val_loss: 0.5290 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4748 - precision: 0.8251 - recall: 0.4914 - val_loss: 0.5040 - val_precision: 0.8021 - val_recall: 0.4647\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4616 - precision: 0.8454 - recall: 0.4968 - val_loss: 0.5289 - val_precision: 0.8019 - val_recall: 0.4664\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4568 - precision: 0.8463 - recall: 0.5017 - val_loss: 0.4956 - val_precision: 0.8222 - val_recall: 0.4691\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4456 - precision: 0.8492 - recall: 0.5125 - val_loss: 0.4511 - val_precision: 0.8506 - val_recall: 0.5022\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4241 - precision: 0.8279 - recall: 0.5450 - val_loss: 0.4341 - val_precision: 0.7800 - val_recall: 0.5981\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4033 - precision: 0.7998 - recall: 0.5966 - val_loss: 0.4031 - val_precision: 0.7795 - val_recall: 0.6626\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3866 - precision: 0.8047 - recall: 0.6153 - val_loss: 0.4152 - val_precision: 0.8019 - val_recall: 0.6136\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3741 - precision: 0.7995 - recall: 0.6391 - val_loss: 0.3561 - val_precision: 0.8424 - val_recall: 0.6483\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3519 - precision: 0.8151 - recall: 0.6761 - val_loss: 0.3441 - val_precision: 0.8566 - val_recall: 0.6588\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3366 - precision: 0.8204 - recall: 0.6917 - val_loss: 0.3422 - val_precision: 0.8091 - val_recall: 0.7266\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3199 - precision: 0.8268 - recall: 0.7081 - val_loss: 0.3174 - val_precision: 0.8302 - val_recall: 0.7359\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3039 - precision: 0.8391 - recall: 0.7305 - val_loss: 0.3031 - val_precision: 0.8331 - val_recall: 0.7459\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2882 - precision: 0.8430 - recall: 0.7549 - val_loss: 0.2953 - val_precision: 0.8085 - val_recall: 0.7911\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2737 - precision: 0.8483 - recall: 0.7729 - val_loss: 0.2923 - val_precision: 0.8055 - val_recall: 0.8126\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2614 - precision: 0.8524 - recall: 0.7855 - val_loss: 0.3169 - val_precision: 0.7843 - val_recall: 0.7817\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2493 - precision: 0.8556 - recall: 0.8023 - val_loss: 0.2722 - val_precision: 0.8205 - val_recall: 0.8192\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2367 - precision: 0.8674 - recall: 0.8151 - val_loss: 0.2606 - val_precision: 0.8260 - val_recall: 0.8401\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2278 - precision: 0.8684 - recall: 0.8225 - val_loss: 0.2728 - val_precision: 0.7975 - val_recall: 0.8705\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2159 - precision: 0.8762 - recall: 0.8360 - val_loss: 0.2691 - val_precision: 0.7982 - val_recall: 0.8743\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2041 - precision: 0.8850 - recall: 0.8467 - val_loss: 0.2548 - val_precision: 0.8045 - val_recall: 0.8936\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1938 - precision: 0.8896 - recall: 0.8585 - val_loss: 0.2625 - val_precision: 0.8090 - val_recall: 0.8660\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1813 - precision: 0.8945 - recall: 0.8655 - val_loss: 0.2355 - val_precision: 0.8291 - val_recall: 0.8931\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1713 - precision: 0.8994 - recall: 0.8775 - val_loss: 0.2447 - val_precision: 0.8088 - val_recall: 0.8931\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1635 - precision: 0.9055 - recall: 0.8868 - val_loss: 0.2266 - val_precision: 0.8441 - val_recall: 0.9013\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1619 - precision: 0.9037 - recall: 0.8899 - val_loss: 0.2079 - val_precision: 0.8534 - val_recall: 0.8986\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1514 - precision: 0.9112 - recall: 0.8979 - val_loss: 0.2129 - val_precision: 0.8473 - val_recall: 0.9112\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1390 - precision: 0.9170 - recall: 0.9033 - val_loss: 0.1829 - val_precision: 0.8775 - val_recall: 0.9123\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1333 - precision: 0.9194 - recall: 0.9073 - val_loss: 0.2220 - val_precision: 0.8502 - val_recall: 0.8914\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1274 - precision: 0.9217 - recall: 0.9156 - val_loss: 0.1821 - val_precision: 0.8873 - val_recall: 0.9024\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1203 - precision: 0.9247 - recall: 0.9188 - val_loss: 0.1821 - val_precision: 0.8864 - val_recall: 0.9079\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1202 - precision: 0.9240 - recall: 0.9174 - val_loss: 0.1670 - val_precision: 0.8948 - val_recall: 0.9234\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1115 - precision: 0.9334 - recall: 0.9250 - val_loss: 0.1612 - val_precision: 0.8904 - val_recall: 0.9316\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1218 - precision: 0.9288 - recall: 0.9195 - val_loss: 0.1505 - val_precision: 0.9089 - val_recall: 0.9245\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1132 - precision: 0.9326 - recall: 0.9275 - val_loss: 0.1423 - val_precision: 0.9117 - val_recall: 0.9223\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0990 - precision: 0.9381 - recall: 0.9351 - val_loss: 0.1446 - val_precision: 0.9202 - val_recall: 0.9151\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0989 - precision: 0.9394 - recall: 0.9365 - val_loss: 0.1693 - val_precision: 0.9140 - val_recall: 0.9079\n",
      "Epoch 38/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0910 - precision: 0.9444 - recall: 0.9431 - val_loss: 0.1669 - val_precision: 0.9021 - val_recall: 0.9146\n",
      "Epoch 39/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0856 - precision: 0.9484 - recall: 0.9485 - val_loss: 0.1650 - val_precision: 0.9143 - val_recall: 0.9112\n",
      "Epoch 40/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0850 - precision: 0.9471 - recall: 0.9462 - val_loss: 0.1476 - val_precision: 0.9283 - val_recall: 0.9129\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765548796.849534 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - loss: 0.4957 - precision: 0.8151 - recall: 0.4771 - val_loss: 0.4679 - val_precision: 0.8456 - val_recall: 0.4768\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4458 - precision: 0.8373 - recall: 0.5072 - val_loss: 0.4469 - val_precision: 0.8519 - val_recall: 0.5138\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4277 - precision: 0.8239 - recall: 0.5439 - val_loss: 0.4158 - val_precision: 0.8576 - val_recall: 0.5447\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4109 - precision: 0.8229 - recall: 0.5681 - val_loss: 0.4044 - val_precision: 0.8401 - val_recall: 0.5937\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3990 - precision: 0.8242 - recall: 0.5858 - val_loss: 0.4089 - val_precision: 0.7931 - val_recall: 0.6295\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3906 - precision: 0.8222 - recall: 0.5990 - val_loss: 0.4019 - val_precision: 0.7870 - val_recall: 0.6499\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3783 - precision: 0.8251 - recall: 0.6119 - val_loss: 0.3933 - val_precision: 0.7866 - val_recall: 0.6422\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3678 - precision: 0.8226 - recall: 0.6230 - val_loss: 0.3798 - val_precision: 0.7919 - val_recall: 0.6483\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3568 - precision: 0.8274 - recall: 0.6425 - val_loss: 0.3649 - val_precision: 0.8086 - val_recall: 0.6566\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3479 - precision: 0.8277 - recall: 0.6601 - val_loss: 0.3556 - val_precision: 0.8161 - val_recall: 0.6703\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3374 - precision: 0.8290 - recall: 0.6779 - val_loss: 0.3440 - val_precision: 0.8164 - val_recall: 0.6841\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3242 - precision: 0.8344 - recall: 0.7058 - val_loss: 0.3376 - val_precision: 0.7986 - val_recall: 0.7128\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3128 - precision: 0.8390 - recall: 0.7248 - val_loss: 0.3320 - val_precision: 0.7825 - val_recall: 0.7558\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3009 - precision: 0.8426 - recall: 0.7416 - val_loss: 0.3269 - val_precision: 0.7807 - val_recall: 0.7850\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2905 - precision: 0.8457 - recall: 0.7553 - val_loss: 0.3231 - val_precision: 0.7813 - val_recall: 0.7740\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2810 - precision: 0.8481 - recall: 0.7647 - val_loss: 0.3140 - val_precision: 0.7869 - val_recall: 0.7756\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2703 - precision: 0.8529 - recall: 0.7780 - val_loss: 0.3074 - val_precision: 0.8024 - val_recall: 0.7745\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2622 - precision: 0.8544 - recall: 0.7873 - val_loss: 0.2930 - val_precision: 0.8175 - val_recall: 0.7778\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2533 - precision: 0.8595 - recall: 0.7982 - val_loss: 0.2908 - val_precision: 0.8190 - val_recall: 0.7784\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2457 - precision: 0.8642 - recall: 0.8031 - val_loss: 0.2767 - val_precision: 0.8376 - val_recall: 0.7762\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2380 - precision: 0.8710 - recall: 0.8103 - val_loss: 0.2760 - val_precision: 0.8247 - val_recall: 0.8037\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2309 - precision: 0.8740 - recall: 0.8187 - val_loss: 0.2760 - val_precision: 0.8302 - val_recall: 0.8004\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2222 - precision: 0.8771 - recall: 0.8275 - val_loss: 0.2710 - val_precision: 0.8292 - val_recall: 0.8004\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2134 - precision: 0.8821 - recall: 0.8372 - val_loss: 0.2585 - val_precision: 0.8371 - val_recall: 0.8076\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2046 - precision: 0.8833 - recall: 0.8446 - val_loss: 0.2699 - val_precision: 0.8357 - val_recall: 0.7993\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1994 - precision: 0.8875 - recall: 0.8529 - val_loss: 0.2462 - val_precision: 0.8455 - val_recall: 0.8264\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1894 - precision: 0.8907 - recall: 0.8626 - val_loss: 0.2494 - val_precision: 0.8478 - val_recall: 0.8230\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1846 - precision: 0.8963 - recall: 0.8693 - val_loss: 0.2410 - val_precision: 0.8503 - val_recall: 0.8264\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1786 - precision: 0.9001 - recall: 0.8755 - val_loss: 0.2405 - val_precision: 0.8511 - val_recall: 0.8319\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1753 - precision: 0.9029 - recall: 0.8791 - val_loss: 0.2456 - val_precision: 0.8477 - val_recall: 0.8286\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1716 - precision: 0.9005 - recall: 0.8811 - val_loss: 0.2237 - val_precision: 0.8681 - val_recall: 0.8379\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1651 - precision: 0.9047 - recall: 0.8849 - val_loss: 0.2212 - val_precision: 0.8689 - val_recall: 0.8407\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1578 - precision: 0.9110 - recall: 0.8901 - val_loss: 0.2124 - val_precision: 0.8700 - val_recall: 0.8556\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1502 - precision: 0.9150 - recall: 0.8990 - val_loss: 0.2262 - val_precision: 0.8742 - val_recall: 0.8429\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1439 - precision: 0.9204 - recall: 0.9034 - val_loss: 0.2202 - val_precision: 0.8643 - val_recall: 0.8501\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1391 - precision: 0.9212 - recall: 0.9084 - val_loss: 0.2282 - val_precision: 0.8616 - val_recall: 0.8407\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1343 - precision: 0.9229 - recall: 0.9086 - val_loss: 0.2039 - val_precision: 0.8610 - val_recall: 0.8842\n",
      "Epoch 38/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1283 - precision: 0.9280 - recall: 0.9164 - val_loss: 0.1881 - val_precision: 0.8814 - val_recall: 0.8809\n",
      "Epoch 39/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1236 - precision: 0.9311 - recall: 0.9226 - val_loss: 0.1902 - val_precision: 0.8795 - val_recall: 0.8848\n",
      "Epoch 40/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1190 - precision: 0.9327 - recall: 0.9226 - val_loss: 0.1736 - val_precision: 0.8894 - val_recall: 0.8953\n",
      "Epoch 41/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1181 - precision: 0.9312 - recall: 0.9226 - val_loss: 0.1775 - val_precision: 0.9009 - val_recall: 0.8716\n",
      "Epoch 42/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1162 - precision: 0.9324 - recall: 0.9250 - val_loss: 0.1596 - val_precision: 0.9224 - val_recall: 0.8842\n",
      "Epoch 43/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1067 - precision: 0.9365 - recall: 0.9372 - val_loss: 0.1555 - val_precision: 0.9060 - val_recall: 0.9090\n",
      "Epoch 44/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1006 - precision: 0.9421 - recall: 0.9384 - val_loss: 0.1515 - val_precision: 0.9157 - val_recall: 0.9101\n",
      "Epoch 45/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0978 - precision: 0.9448 - recall: 0.9404 - val_loss: 0.1475 - val_precision: 0.9092 - val_recall: 0.9168\n",
      "Epoch 46/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0935 - precision: 0.9458 - recall: 0.9445 - val_loss: 0.1757 - val_precision: 0.8781 - val_recall: 0.9096\n",
      "Epoch 47/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0914 - precision: 0.9482 - recall: 0.9439 - val_loss: 0.1670 - val_precision: 0.9095 - val_recall: 0.8975\n",
      "Epoch 48/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0898 - precision: 0.9497 - recall: 0.9443 - val_loss: 0.1707 - val_precision: 0.9053 - val_recall: 0.8964\n",
      "Epoch 49/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0850 - precision: 0.9522 - recall: 0.9470 - val_loss: 0.1498 - val_precision: 0.9092 - val_recall: 0.9223\n",
      "Epoch 50/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0863 - precision: 0.9515 - recall: 0.9469 - val_loss: 0.1498 - val_precision: 0.9085 - val_recall: 0.9195\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765549369.094387 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - loss: 0.5112 - precision: 0.8006 - recall: 0.4752 - val_loss: 0.4689 - val_precision: 0.8525 - val_recall: 0.4813\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4673 - precision: 0.8449 - recall: 0.4910 - val_loss: 0.5145 - val_precision: 0.8293 - val_recall: 0.4768\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4592 - precision: 0.8535 - recall: 0.4982 - val_loss: 0.5203 - val_precision: 0.8227 - val_recall: 0.4708\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4547 - precision: 0.8611 - recall: 0.5049 - val_loss: 0.4810 - val_precision: 0.8619 - val_recall: 0.4680\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4463 - precision: 0.8621 - recall: 0.5064 - val_loss: 0.4823 - val_precision: 0.8637 - val_recall: 0.4752\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4283 - precision: 0.8527 - recall: 0.5276 - val_loss: 0.4505 - val_precision: 0.8119 - val_recall: 0.5474\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4063 - precision: 0.8314 - recall: 0.5774 - val_loss: 0.4020 - val_precision: 0.8679 - val_recall: 0.5469\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3857 - precision: 0.8245 - recall: 0.6227 - val_loss: 0.3814 - val_precision: 0.8241 - val_recall: 0.6301\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3665 - precision: 0.8209 - recall: 0.6608 - val_loss: 0.3699 - val_precision: 0.8275 - val_recall: 0.6428\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3508 - precision: 0.8199 - recall: 0.6842 - val_loss: 0.3590 - val_precision: 0.7973 - val_recall: 0.7244\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.3307 - precision: 0.8246 - recall: 0.7040 - val_loss: 0.3573 - val_precision: 0.7913 - val_recall: 0.7233\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.3131 - precision: 0.8350 - recall: 0.7218 - val_loss: 0.3248 - val_precision: 0.8110 - val_recall: 0.7641\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.3002 - precision: 0.8429 - recall: 0.7403 - val_loss: 0.3211 - val_precision: 0.7927 - val_recall: 0.7756\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 0.2838 - precision: 0.8480 - recall: 0.7651 - val_loss: 0.3090 - val_precision: 0.7931 - val_recall: 0.8010\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.2659 - precision: 0.8489 - recall: 0.7846 - val_loss: 0.3050 - val_precision: 0.7890 - val_recall: 0.8120\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.2510 - precision: 0.8597 - recall: 0.8068 - val_loss: 0.2800 - val_precision: 0.8017 - val_recall: 0.8423\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.2338 - precision: 0.8664 - recall: 0.8247 - val_loss: 0.2625 - val_precision: 0.8135 - val_recall: 0.8534\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.2195 - precision: 0.8757 - recall: 0.8410 - val_loss: 0.2488 - val_precision: 0.8363 - val_recall: 0.8534\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.2054 - precision: 0.8814 - recall: 0.8545 - val_loss: 0.2774 - val_precision: 0.7878 - val_recall: 0.8864\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1920 - precision: 0.8906 - recall: 0.8674 - val_loss: 0.2466 - val_precision: 0.8228 - val_recall: 0.8859\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1776 - precision: 0.9012 - recall: 0.8776 - val_loss: 0.2374 - val_precision: 0.8342 - val_recall: 0.8820\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1803 - precision: 0.8964 - recall: 0.8773 - val_loss: 0.2232 - val_precision: 0.8610 - val_recall: 0.8638\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.1650 - precision: 0.9067 - recall: 0.8867 - val_loss: 0.2231 - val_precision: 0.8436 - val_recall: 0.8743\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1490 - precision: 0.9168 - recall: 0.8993 - val_loss: 0.2118 - val_precision: 0.8564 - val_recall: 0.9008\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1424 - precision: 0.9188 - recall: 0.9077 - val_loss: 0.1994 - val_precision: 0.8713 - val_recall: 0.9030\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1363 - precision: 0.9195 - recall: 0.9100 - val_loss: 0.2040 - val_precision: 0.8670 - val_recall: 0.9057\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1299 - precision: 0.9247 - recall: 0.9155 - val_loss: 0.2166 - val_precision: 0.8668 - val_recall: 0.9008\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1141 - precision: 0.9326 - recall: 0.9275 - val_loss: 0.2140 - val_precision: 0.8785 - val_recall: 0.9008\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.1051 - precision: 0.9374 - recall: 0.9330 - val_loss: 0.1967 - val_precision: 0.8865 - val_recall: 0.9002\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.1056 - precision: 0.9381 - recall: 0.9352 - val_loss: 0.2669 - val_precision: 0.8748 - val_recall: 0.8280\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0944 - precision: 0.9445 - recall: 0.9403 - val_loss: 0.1932 - val_precision: 0.9082 - val_recall: 0.9002\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0897 - precision: 0.9473 - recall: 0.9449 - val_loss: 0.1955 - val_precision: 0.9040 - val_recall: 0.9030\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0887 - precision: 0.9462 - recall: 0.9494 - val_loss: 0.2012 - val_precision: 0.9299 - val_recall: 0.8848\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0789 - precision: 0.9530 - recall: 0.9546 - val_loss: 0.2016 - val_precision: 0.9179 - val_recall: 0.8881\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0816 - precision: 0.9523 - recall: 0.9547 - val_loss: 0.1953 - val_precision: 0.9265 - val_recall: 0.8826\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0671 - precision: 0.9602 - recall: 0.9642 - val_loss: 0.2153 - val_precision: 0.9295 - val_recall: 0.8716\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765549773.513784 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "{'batch_size': 16, 'layer_number': 4, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n",
      "\n",
      " ================== INIZIO CICLO CON SEED: 123 ================== \n",
      "\n",
      "TRAINING RUN 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4941 - precision: 0.8134 - recall: 0.4829 - val_loss: 0.4658 - val_precision: 0.8416 - val_recall: 0.4950\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4525 - precision: 0.8397 - recall: 0.4994 - val_loss: 0.4551 - val_precision: 0.8391 - val_recall: 0.4945\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4416 - precision: 0.8379 - recall: 0.5123 - val_loss: 0.4389 - val_precision: 0.8430 - val_recall: 0.4972\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4322 - precision: 0.8317 - recall: 0.5275 - val_loss: 0.4327 - val_precision: 0.8389 - val_recall: 0.5022\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4242 - precision: 0.8239 - recall: 0.5433 - val_loss: 0.4240 - val_precision: 0.8430 - val_recall: 0.5121\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4168 - precision: 0.8191 - recall: 0.5541 - val_loss: 0.4125 - val_precision: 0.8440 - val_recall: 0.5309\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4111 - precision: 0.8213 - recall: 0.5600 - val_loss: 0.4081 - val_precision: 0.8482 - val_recall: 0.5358\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4059 - precision: 0.8200 - recall: 0.5639 - val_loss: 0.3977 - val_precision: 0.8479 - val_recall: 0.5562\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4000 - precision: 0.8234 - recall: 0.5714 - val_loss: 0.3946 - val_precision: 0.8513 - val_recall: 0.5617\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3947 - precision: 0.8238 - recall: 0.5768 - val_loss: 0.3918 - val_precision: 0.8512 - val_recall: 0.5645\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3897 - precision: 0.8239 - recall: 0.5837 - val_loss: 0.3833 - val_precision: 0.8376 - val_recall: 0.5915\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3847 - precision: 0.8241 - recall: 0.5911 - val_loss: 0.3746 - val_precision: 0.8320 - val_recall: 0.6169\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3795 - precision: 0.8244 - recall: 0.5996 - val_loss: 0.3691 - val_precision: 0.8190 - val_recall: 0.6334\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3742 - precision: 0.8240 - recall: 0.6098 - val_loss: 0.3635 - val_precision: 0.8165 - val_recall: 0.6400\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3692 - precision: 0.8253 - recall: 0.6200 - val_loss: 0.3600 - val_precision: 0.8181 - val_recall: 0.6521\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3635 - precision: 0.8224 - recall: 0.6293 - val_loss: 0.3568 - val_precision: 0.7980 - val_recall: 0.6968\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3576 - precision: 0.8221 - recall: 0.6439 - val_loss: 0.3516 - val_precision: 0.8146 - val_recall: 0.7001\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3514 - precision: 0.8220 - recall: 0.6568 - val_loss: 0.3488 - val_precision: 0.8087 - val_recall: 0.7133\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3455 - precision: 0.8222 - recall: 0.6673 - val_loss: 0.3438 - val_precision: 0.8074 - val_recall: 0.7211\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.3408 - precision: 0.8194 - recall: 0.6802 - val_loss: 0.3389 - val_precision: 0.8150 - val_recall: 0.7211\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3356 - precision: 0.8222 - recall: 0.6924 - val_loss: 0.3356 - val_precision: 0.8180 - val_recall: 0.7233\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3295 - precision: 0.8230 - recall: 0.7047 - val_loss: 0.3325 - val_precision: 0.8222 - val_recall: 0.7315\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3242 - precision: 0.8255 - recall: 0.7158 - val_loss: 0.3270 - val_precision: 0.8204 - val_recall: 0.7404\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.3189 - precision: 0.8293 - recall: 0.7225 - val_loss: 0.3250 - val_precision: 0.8211 - val_recall: 0.7387\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.3146 - precision: 0.8293 - recall: 0.7263 - val_loss: 0.3216 - val_precision: 0.8237 - val_recall: 0.7365\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3092 - precision: 0.8339 - recall: 0.7344 - val_loss: 0.3201 - val_precision: 0.8180 - val_recall: 0.7459\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3046 - precision: 0.8329 - recall: 0.7382 - val_loss: 0.3132 - val_precision: 0.8317 - val_recall: 0.7409\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.2982 - precision: 0.8343 - recall: 0.7461 - val_loss: 0.3063 - val_precision: 0.8341 - val_recall: 0.7596\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2940 - precision: 0.8378 - recall: 0.7532 - val_loss: 0.3028 - val_precision: 0.8326 - val_recall: 0.7679\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2878 - precision: 0.8425 - recall: 0.7591 - val_loss: 0.2981 - val_precision: 0.8292 - val_recall: 0.7652\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2841 - precision: 0.8429 - recall: 0.7630 - val_loss: 0.2947 - val_precision: 0.8324 - val_recall: 0.7778\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2785 - precision: 0.8460 - recall: 0.7712 - val_loss: 0.2897 - val_precision: 0.8315 - val_recall: 0.7751\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2733 - precision: 0.8511 - recall: 0.7797 - val_loss: 0.2892 - val_precision: 0.8354 - val_recall: 0.7806\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2689 - precision: 0.8518 - recall: 0.7841 - val_loss: 0.2832 - val_precision: 0.8369 - val_recall: 0.7861\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2649 - precision: 0.8525 - recall: 0.7891 - val_loss: 0.2802 - val_precision: 0.8409 - val_recall: 0.7867\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2602 - precision: 0.8556 - recall: 0.7944 - val_loss: 0.2763 - val_precision: 0.8396 - val_recall: 0.7933\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2563 - precision: 0.8565 - recall: 0.7975 - val_loss: 0.2732 - val_precision: 0.8402 - val_recall: 0.7999\n",
      "Epoch 38/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2517 - precision: 0.8595 - recall: 0.8052 - val_loss: 0.2675 - val_precision: 0.8500 - val_recall: 0.7999\n",
      "Epoch 39/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2473 - precision: 0.8595 - recall: 0.8082 - val_loss: 0.2660 - val_precision: 0.8515 - val_recall: 0.7966\n",
      "Epoch 40/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2438 - precision: 0.8624 - recall: 0.8120 - val_loss: 0.2659 - val_precision: 0.8544 - val_recall: 0.8021\n",
      "Epoch 41/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2403 - precision: 0.8641 - recall: 0.8151 - val_loss: 0.2599 - val_precision: 0.8643 - val_recall: 0.8004\n",
      "Epoch 42/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2362 - precision: 0.8650 - recall: 0.8186 - val_loss: 0.2601 - val_precision: 0.8658 - val_recall: 0.7999\n",
      "Epoch 43/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2332 - precision: 0.8651 - recall: 0.8215 - val_loss: 0.2567 - val_precision: 0.8633 - val_recall: 0.8010\n",
      "Epoch 44/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2289 - precision: 0.8684 - recall: 0.8264 - val_loss: 0.2565 - val_precision: 0.8736 - val_recall: 0.7999\n",
      "Epoch 45/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2249 - precision: 0.8706 - recall: 0.8274 - val_loss: 0.2589 - val_precision: 0.8674 - val_recall: 0.8004\n",
      "Epoch 46/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2219 - precision: 0.8722 - recall: 0.8287 - val_loss: 0.2535 - val_precision: 0.8714 - val_recall: 0.8109\n",
      "Epoch 47/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2193 - precision: 0.8734 - recall: 0.8345 - val_loss: 0.2610 - val_precision: 0.8705 - val_recall: 0.7966\n",
      "Epoch 48/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2171 - precision: 0.8739 - recall: 0.8345 - val_loss: 0.2610 - val_precision: 0.8685 - val_recall: 0.7900\n",
      "Epoch 49/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2141 - precision: 0.8773 - recall: 0.8399 - val_loss: 0.2486 - val_precision: 0.8670 - val_recall: 0.8192\n",
      "Epoch 50/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2104 - precision: 0.8788 - recall: 0.8435 - val_loss: 0.2524 - val_precision: 0.8760 - val_recall: 0.8060\n",
      "Epoch 51/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2068 - precision: 0.8830 - recall: 0.8466 - val_loss: 0.2439 - val_precision: 0.8738 - val_recall: 0.8208\n",
      "Epoch 52/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2044 - precision: 0.8845 - recall: 0.8496 - val_loss: 0.2364 - val_precision: 0.8701 - val_recall: 0.8308\n",
      "Epoch 53/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.2014 - precision: 0.8869 - recall: 0.8521 - val_loss: 0.2350 - val_precision: 0.8721 - val_recall: 0.8308\n",
      "Epoch 54/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1982 - precision: 0.8883 - recall: 0.8566 - val_loss: 0.2294 - val_precision: 0.8713 - val_recall: 0.8434\n",
      "Epoch 55/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1964 - precision: 0.8873 - recall: 0.8567 - val_loss: 0.2341 - val_precision: 0.8709 - val_recall: 0.8368\n",
      "Epoch 56/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1923 - precision: 0.8923 - recall: 0.8609 - val_loss: 0.2232 - val_precision: 0.8713 - val_recall: 0.8506\n",
      "Epoch 57/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1893 - precision: 0.8931 - recall: 0.8641 - val_loss: 0.2186 - val_precision: 0.8751 - val_recall: 0.8539\n",
      "Epoch 58/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1862 - precision: 0.8953 - recall: 0.8665 - val_loss: 0.2172 - val_precision: 0.8840 - val_recall: 0.8490\n",
      "Epoch 59/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1836 - precision: 0.8969 - recall: 0.8688 - val_loss: 0.2157 - val_precision: 0.8783 - val_recall: 0.8517\n",
      "Epoch 60/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1810 - precision: 0.8976 - recall: 0.8730 - val_loss: 0.2104 - val_precision: 0.8773 - val_recall: 0.8594\n",
      "Epoch 61/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1769 - precision: 0.9001 - recall: 0.8754 - val_loss: 0.2149 - val_precision: 0.8829 - val_recall: 0.8561\n",
      "Epoch 62/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1744 - precision: 0.9022 - recall: 0.8765 - val_loss: 0.2148 - val_precision: 0.8855 - val_recall: 0.8440\n",
      "Epoch 63/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1723 - precision: 0.9035 - recall: 0.8800 - val_loss: 0.2102 - val_precision: 0.8864 - val_recall: 0.8517\n",
      "Epoch 64/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1695 - precision: 0.9042 - recall: 0.8814 - val_loss: 0.2114 - val_precision: 0.8891 - val_recall: 0.8484\n",
      "Epoch 65/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1680 - precision: 0.9057 - recall: 0.8819 - val_loss: 0.2145 - val_precision: 0.8863 - val_recall: 0.8512\n",
      "Epoch 66/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1651 - precision: 0.9057 - recall: 0.8839 - val_loss: 0.2162 - val_precision: 0.8827 - val_recall: 0.8506\n",
      "Epoch 67/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1634 - precision: 0.9056 - recall: 0.8868 - val_loss: 0.2071 - val_precision: 0.8906 - val_recall: 0.8523\n",
      "Epoch 68/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1608 - precision: 0.9081 - recall: 0.8877 - val_loss: 0.2095 - val_precision: 0.8932 - val_recall: 0.8534\n",
      "Epoch 69/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.1589 - precision: 0.9086 - recall: 0.8932 - val_loss: 0.2097 - val_precision: 0.8933 - val_recall: 0.8490\n",
      "Epoch 70/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1583 - precision: 0.9060 - recall: 0.8925 - val_loss: 0.2130 - val_precision: 0.8889 - val_recall: 0.8467\n",
      "Epoch 71/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1568 - precision: 0.9108 - recall: 0.8933 - val_loss: 0.2146 - val_precision: 0.8857 - val_recall: 0.8462\n",
      "Epoch 72/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1554 - precision: 0.9099 - recall: 0.8923 - val_loss: 0.2221 - val_precision: 0.8849 - val_recall: 0.8352\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765550511.847065 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - loss: 0.5167 - precision: 0.7967 - recall: 0.4736 - val_loss: 0.5165 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.4925 - precision: 0.8145 - recall: 0.4790 - val_loss: 0.4812 - val_precision: 0.8322 - val_recall: 0.4868\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.4651 - precision: 0.8326 - recall: 0.4910 - val_loss: 0.4678 - val_precision: 0.8316 - val_recall: 0.4983\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4587 - precision: 0.8421 - recall: 0.5017 - val_loss: 0.4623 - val_precision: 0.8341 - val_recall: 0.5044\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4523 - precision: 0.8399 - recall: 0.5097 - val_loss: 0.4566 - val_precision: 0.8433 - val_recall: 0.5044\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4928 - precision: 0.8193 - recall: 0.4895 - val_loss: 0.4890 - val_precision: 0.8112 - val_recall: 0.4807\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4582 - precision: 0.8346 - recall: 0.5024 - val_loss: 0.4598 - val_precision: 0.8506 - val_recall: 0.4989\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4427 - precision: 0.8533 - recall: 0.5139 - val_loss: 0.4480 - val_precision: 0.8578 - val_recall: 0.5088\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4306 - precision: 0.8505 - recall: 0.5280 - val_loss: 0.4222 - val_precision: 0.8405 - val_recall: 0.5402\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.4081 - precision: 0.8229 - recall: 0.5851 - val_loss: 0.3985 - val_precision: 0.8199 - val_recall: 0.6097\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3884 - precision: 0.8163 - recall: 0.6262 - val_loss: 0.3864 - val_precision: 0.7908 - val_recall: 0.6544\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3724 - precision: 0.8189 - recall: 0.6531 - val_loss: 0.3709 - val_precision: 0.8117 - val_recall: 0.6725\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3573 - precision: 0.8219 - recall: 0.6736 - val_loss: 0.3581 - val_precision: 0.8156 - val_recall: 0.6874\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3435 - precision: 0.8260 - recall: 0.6941 - val_loss: 0.3515 - val_precision: 0.8151 - val_recall: 0.7045\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3313 - precision: 0.8325 - recall: 0.7046 - val_loss: 0.3432 - val_precision: 0.8106 - val_recall: 0.7194\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3183 - precision: 0.8377 - recall: 0.7179 - val_loss: 0.3301 - val_precision: 0.8213 - val_recall: 0.7370\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3038 - precision: 0.8440 - recall: 0.7337 - val_loss: 0.3225 - val_precision: 0.8259 - val_recall: 0.7530\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2876 - precision: 0.8512 - recall: 0.7549 - val_loss: 0.3092 - val_precision: 0.8304 - val_recall: 0.7828\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2743 - precision: 0.8571 - recall: 0.7726 - val_loss: 0.3050 - val_precision: 0.8335 - val_recall: 0.7784\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2626 - precision: 0.8624 - recall: 0.7862 - val_loss: 0.2827 - val_precision: 0.8489 - val_recall: 0.7988\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2518 - precision: 0.8664 - recall: 0.7985 - val_loss: 0.2759 - val_precision: 0.8526 - val_recall: 0.7971\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2446 - precision: 0.8662 - recall: 0.8059 - val_loss: 0.2623 - val_precision: 0.8501 - val_recall: 0.8131\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2342 - precision: 0.8731 - recall: 0.8145 - val_loss: 0.2509 - val_precision: 0.8582 - val_recall: 0.8241\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2252 - precision: 0.8761 - recall: 0.8281 - val_loss: 0.2421 - val_precision: 0.8646 - val_recall: 0.8236\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2139 - precision: 0.8804 - recall: 0.8385 - val_loss: 0.2318 - val_precision: 0.8716 - val_recall: 0.8308\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.2027 - precision: 0.8887 - recall: 0.8456 - val_loss: 0.2267 - val_precision: 0.8741 - val_recall: 0.8462\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1926 - precision: 0.8930 - recall: 0.8561 - val_loss: 0.2299 - val_precision: 0.8768 - val_recall: 0.8396\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1893 - precision: 0.8950 - recall: 0.8601 - val_loss: 0.2352 - val_precision: 0.8775 - val_recall: 0.8252\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1782 - precision: 0.9025 - recall: 0.8707 - val_loss: 0.2254 - val_precision: 0.8807 - val_recall: 0.8302\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1693 - precision: 0.9052 - recall: 0.8773 - val_loss: 0.2250 - val_precision: 0.8851 - val_recall: 0.8363\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1622 - precision: 0.9086 - recall: 0.8832 - val_loss: 0.2053 - val_precision: 0.8847 - val_recall: 0.8627\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1578 - precision: 0.9106 - recall: 0.8860 - val_loss: 0.2051 - val_precision: 0.8724 - val_recall: 0.8705\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1508 - precision: 0.9153 - recall: 0.8972 - val_loss: 0.2201 - val_precision: 0.8639 - val_recall: 0.8749\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1409 - precision: 0.9158 - recall: 0.9069 - val_loss: 0.2171 - val_precision: 0.8848 - val_recall: 0.8682\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1340 - precision: 0.9228 - recall: 0.9112 - val_loss: 0.2305 - val_precision: 0.8829 - val_recall: 0.8561\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1216 - precision: 0.9275 - recall: 0.9199 - val_loss: 0.2192 - val_precision: 0.8951 - val_recall: 0.8705\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.1179 - precision: 0.9283 - recall: 0.9218 - val_loss: 0.2615 - val_precision: 0.8668 - val_recall: 0.8539\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765550906.153928 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\n",
      "TRAINING RUN 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.4874 - precision: 0.8131 - recall: 0.4872 - val_loss: 0.4610 - val_precision: 0.8403 - val_recall: 0.4846\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4453 - precision: 0.8368 - recall: 0.5076 - val_loss: 0.4330 - val_precision: 0.8408 - val_recall: 0.4950\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4262 - precision: 0.8275 - recall: 0.5387 - val_loss: 0.4117 - val_precision: 0.8447 - val_recall: 0.5485\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4124 - precision: 0.8239 - recall: 0.5589 - val_loss: 0.3952 - val_precision: 0.8413 - val_recall: 0.5788\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.4013 - precision: 0.8263 - recall: 0.5756 - val_loss: 0.3854 - val_precision: 0.8383 - val_recall: 0.5888\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3906 - precision: 0.8253 - recall: 0.5910 - val_loss: 0.3761 - val_precision: 0.8477 - val_recall: 0.5954\n",
      "Epoch 7/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3791 - precision: 0.8207 - recall: 0.6085 - val_loss: 0.3646 - val_precision: 0.8165 - val_recall: 0.6207\n",
      "Epoch 8/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3631 - precision: 0.8228 - recall: 0.6366 - val_loss: 0.3483 - val_precision: 0.8098 - val_recall: 0.6830\n",
      "Epoch 9/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3482 - precision: 0.8293 - recall: 0.6667 - val_loss: 0.3353 - val_precision: 0.8193 - val_recall: 0.7073\n",
      "Epoch 10/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3338 - precision: 0.8272 - recall: 0.6925 - val_loss: 0.3235 - val_precision: 0.8163 - val_recall: 0.7326\n",
      "Epoch 11/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3196 - precision: 0.8269 - recall: 0.7152 - val_loss: 0.3173 - val_precision: 0.8103 - val_recall: 0.7514\n",
      "Epoch 12/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.3090 - precision: 0.8284 - recall: 0.7349 - val_loss: 0.3096 - val_precision: 0.8129 - val_recall: 0.7663\n",
      "Epoch 13/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2974 - precision: 0.8328 - recall: 0.7506 - val_loss: 0.3003 - val_precision: 0.8253 - val_recall: 0.7657\n",
      "Epoch 14/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2871 - precision: 0.8381 - recall: 0.7586 - val_loss: 0.2929 - val_precision: 0.8253 - val_recall: 0.7734\n",
      "Epoch 15/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2764 - precision: 0.8410 - recall: 0.7705 - val_loss: 0.2893 - val_precision: 0.8259 - val_recall: 0.7795\n",
      "Epoch 16/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2658 - precision: 0.8484 - recall: 0.7828 - val_loss: 0.2878 - val_precision: 0.8241 - val_recall: 0.7878\n",
      "Epoch 17/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2564 - precision: 0.8512 - recall: 0.7943 - val_loss: 0.2749 - val_precision: 0.8313 - val_recall: 0.7960\n",
      "Epoch 18/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2472 - precision: 0.8590 - recall: 0.8052 - val_loss: 0.2689 - val_precision: 0.8381 - val_recall: 0.8021\n",
      "Epoch 19/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2385 - precision: 0.8619 - recall: 0.8131 - val_loss: 0.2633 - val_precision: 0.8381 - val_recall: 0.8076\n",
      "Epoch 20/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2300 - precision: 0.8663 - recall: 0.8239 - val_loss: 0.2557 - val_precision: 0.8425 - val_recall: 0.8170\n",
      "Epoch 21/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2224 - precision: 0.8717 - recall: 0.8336 - val_loss: 0.2525 - val_precision: 0.8474 - val_recall: 0.8236\n",
      "Epoch 22/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2119 - precision: 0.8768 - recall: 0.8403 - val_loss: 0.2434 - val_precision: 0.8449 - val_recall: 0.8319\n",
      "Epoch 23/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.2016 - precision: 0.8856 - recall: 0.8487 - val_loss: 0.2426 - val_precision: 0.8447 - val_recall: 0.8396\n",
      "Epoch 24/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1940 - precision: 0.8902 - recall: 0.8567 - val_loss: 0.2363 - val_precision: 0.8468 - val_recall: 0.8473\n",
      "Epoch 25/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1850 - precision: 0.8956 - recall: 0.8672 - val_loss: 0.2275 - val_precision: 0.8599 - val_recall: 0.8390\n",
      "Epoch 26/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1777 - precision: 0.8982 - recall: 0.8725 - val_loss: 0.2228 - val_precision: 0.8659 - val_recall: 0.8401\n",
      "Epoch 27/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1748 - precision: 0.8990 - recall: 0.8759 - val_loss: 0.2156 - val_precision: 0.8669 - val_recall: 0.8506\n",
      "Epoch 28/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1694 - precision: 0.9038 - recall: 0.8797 - val_loss: 0.2148 - val_precision: 0.8564 - val_recall: 0.8583\n",
      "Epoch 29/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1628 - precision: 0.9084 - recall: 0.8857 - val_loss: 0.2117 - val_precision: 0.8588 - val_recall: 0.8649\n",
      "Epoch 30/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1543 - precision: 0.9131 - recall: 0.8926 - val_loss: 0.2112 - val_precision: 0.8578 - val_recall: 0.8716\n",
      "Epoch 31/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1489 - precision: 0.9140 - recall: 0.8967 - val_loss: 0.2066 - val_precision: 0.8554 - val_recall: 0.8837\n",
      "Epoch 32/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1416 - precision: 0.9166 - recall: 0.9059 - val_loss: 0.2034 - val_precision: 0.8627 - val_recall: 0.8870\n",
      "Epoch 33/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1320 - precision: 0.9249 - recall: 0.9122 - val_loss: 0.2037 - val_precision: 0.8666 - val_recall: 0.8809\n",
      "Epoch 34/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1246 - precision: 0.9265 - recall: 0.9178 - val_loss: 0.1994 - val_precision: 0.8836 - val_recall: 0.8743\n",
      "Epoch 35/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1242 - precision: 0.9288 - recall: 0.9185 - val_loss: 0.1993 - val_precision: 0.8920 - val_recall: 0.8738\n",
      "Epoch 36/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1189 - precision: 0.9334 - recall: 0.9215 - val_loss: 0.1935 - val_precision: 0.8936 - val_recall: 0.8705\n",
      "Epoch 37/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.1113 - precision: 0.9378 - recall: 0.9277 - val_loss: 0.1922 - val_precision: 0.9096 - val_recall: 0.8539\n",
      "Epoch 38/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.1102 - precision: 0.9379 - recall: 0.9293 - val_loss: 0.1952 - val_precision: 0.9178 - val_recall: 0.8616\n",
      "Epoch 39/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 0.1104 - precision: 0.9374 - recall: 0.9278 - val_loss: 0.2151 - val_precision: 0.9185 - val_recall: 0.8445\n",
      "Epoch 40/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1076 - precision: 0.9362 - recall: 0.9324 - val_loss: 0.2139 - val_precision: 0.9322 - val_recall: 0.8264\n",
      "Epoch 41/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1020 - precision: 0.9446 - recall: 0.9333 - val_loss: 0.2140 - val_precision: 0.9189 - val_recall: 0.8490\n",
      "Epoch 42/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.1032 - precision: 0.9408 - recall: 0.9351 - val_loss: 0.2035 - val_precision: 0.9263 - val_recall: 0.8319\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765551387.552665 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "TRAINING RUN 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - loss: 0.5163 - precision: 0.7895 - recall: 0.4774 - val_loss: 0.5125 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 2/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.5080 - precision: 0.8020 - recall: 0.4755 - val_loss: 0.5165 - val_precision: 0.7976 - val_recall: 0.4691\n",
      "Epoch 3/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.5093 - precision: 0.8013 - recall: 0.4749 - val_loss: 0.5187 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 4/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.5091 - precision: 0.8016 - recall: 0.4748 - val_loss: 0.5187 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 5/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.5089 - precision: 0.8016 - recall: 0.4748 - val_loss: 0.5189 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "Epoch 6/120\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.5087 - precision: 0.8016 - recall: 0.4748 - val_loss: 0.5191 - val_precision: 0.7992 - val_recall: 0.4653\n",
      "\u001b[1m 9/14\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765551459.885576 3263105 node_def_util.cc:682] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "{'batch_size': 16, 'layer_number': 4, 'kernel_dim': 7, 'pool_dim': 3, 'lr': 0.001, 'fc1': 128, 'fc2': 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/Desktop/ml_homework2/ml_hw2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "dataset, annotation=load_dataset()\n",
    "x_train,y_train, x_test, y_test=dataset_modelling(dataset, annotation)\n",
    "list_augtype=['flip','noise','both']\n",
    "for aug_type in list_augtype:\n",
    "    x_train_aug, y_train_aug = augment_train_set(x_train, y_train,aug_type)\n",
    "\n",
    "    combination=create_hyperparam_combination()\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        bestf1=0\n",
    "        all_results = []\n",
    "\n",
    "        print(f\"\\n ================== INIZIO CICLO CON SEED: {seed} ================== \")\n",
    "        for i,param in enumerate(combination):\n",
    "\n",
    "            \n",
    "            print(f\"\\nTRAINING RUN {i+1}/{len(combination)}\")\n",
    "            tf.keras.backend.clear_session()\n",
    "            reset_seeds(seed)\n",
    "            model=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'])\n",
    "            opt=tf.keras.optimizers.Adam(learning_rate=param['lr'])\n",
    "            model.compile(optimizer=opt,\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                                tf.keras.metrics.Recall(name='recall'),\n",
    "                                ])\n",
    "            early_stop=EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "            )\n",
    "            reset_seeds(seed)\n",
    "            #class_weights_dict=compute_class_weight(y_train)\n",
    "            history=model.fit(\n",
    "                x_train_aug,y_train_aug,\n",
    "                epochs=120,\n",
    "                batch_size=param['batch_size'], \n",
    "                validation_split=0.2, \n",
    "                callbacks=[early_stop]\n",
    "                )\n",
    "\n",
    "            y_pred=model.predict(x_test)\n",
    "            predictions_binary = (y_pred > 0.5).astype(int)\n",
    "            target_names = ['goalpost','ball','robot','goalspot','centerspot']\n",
    "            report_dict = classification_report(y_test, predictions_binary, target_names=target_names, output_dict=True)\n",
    "            f1_macro = report_dict['macro avg']['f1-score']\n",
    "            if f1_macro>bestf1:\n",
    "                best_report_dict=report_dict\n",
    "                best_param=param\n",
    "                bestf1=f1_macro\n",
    "            saving_csv(report_dict,param,target_names,all_results,seed,aug_type)\n",
    "\n",
    "\n",
    "        df_report = pd.DataFrame(best_report_dict).transpose()\n",
    "        df_report = df_report.round(2)\n",
    "        df_report['support'] = df_report['support'].astype(int)\n",
    "        csv_path = f'csv/report/report_bestcomb6{aug_type}_{seed}.csv'\n",
    "        df_report.to_csv(csv_path)\n",
    "        print(best_param)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
