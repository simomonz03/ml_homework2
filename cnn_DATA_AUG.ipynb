{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782da64b",
   "metadata": {},
   "source": [
    "IMPORT AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3282f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21.0-dev20251210\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✅ Op Determinism Abilitato!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"✅ Op Determinism Abilitato!\")\n",
    "except AttributeError:\n",
    "    print(\"⚠️ Attenzione: La tua versione di TF è troppo vecchia per enable_op_determinism.\")\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "SEEDS = [555]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65e287",
   "metadata": {},
   "source": [
    "DATASET LOADING AND MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d7a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    folder='dataset/images'\n",
    "    data=[]\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        img_path=os.path.join(folder,filename)\n",
    "        img=cv2.imread(img_path) #opencv save in bgr\n",
    "        data.append({\n",
    "            'image':img,\n",
    "            'filename':filename\n",
    "        })\n",
    "\n",
    "    print(len(data),'images loaded')\n",
    "    print('file name is: ',data[0]['filename'], 'shape of the image is:  ', data[0]['image'].shape )\n",
    "\n",
    "    label=pd.read_csv('dataset/raw/bbx_annotations.csv')\n",
    "    print(label.shape, label.iloc[0]['filename'])\n",
    "    #images order is random, and for 1 image you can have more class\n",
    "\n",
    "    print('we have', len(label['class'].unique()), 'different classes')\n",
    "\n",
    "    #replace biggger img with half sized ones\n",
    "    #cv2.imwrite('resize_image/last_img_pre_downsampling.jpg',data[-100]['image'])\n",
    "    for i,item in enumerate(data):\n",
    "        if \"upper\" in item[\"filename\"].lower():\n",
    "            data[i]['image']=cv2.resize(\n",
    "                data[i]['image'],\n",
    "                (data[i]['image'].shape[1]//2,data[i]['image'].shape[0]//2)\n",
    "                ,interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    #cv2.imwrite('resize_image/last_img_post_downsampling.jpg',data[-100]['image'])\n",
    "       \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea259a97",
   "metadata": {},
   "source": [
    "FROM THE PURE DATASET TO THE TRAIN AND TEST DATA AND LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e35d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_modelling(dataset,annotation):   \n",
    "    dataset_df = pd.DataFrame(dataset) \n",
    "    label_map={'goalpost':0,\n",
    "               'ball':1,\n",
    "               'robot':2,\n",
    "               'goalspot':3,\n",
    "               'centerspot':4}\n",
    "    def get_vector(classes_found):\n",
    "        vec=np.zeros(5,dtype=int)\n",
    "\n",
    "        for c in classes_found:\n",
    "            if c in label_map:\n",
    "                vec[label_map[c]]=1\n",
    "        return list(vec)\n",
    "    \n",
    "    grouped = annotation.groupby('filename')['class'].apply(list).reset_index()\n",
    "    grouped['label']=grouped['class'].apply(get_vector)\n",
    "    final_annotation=grouped[['filename','label']]\n",
    "\n",
    "    final_dataset= pd.merge(dataset_df, final_annotation[['filename', 'label']], on='filename', how='inner')\n",
    "    final_dataset.to_csv('csv/temp/final_dataset.csv')\n",
    "    final_dataset=final_dataset.drop(columns=['filename'])\n",
    "    df_train, df_test = train_test_split(final_dataset, test_size=0.2, random_state=42)\n",
    "    x_train = np.array(df_train['image'].tolist()).astype('float32') /255.0\n",
    "    y_train = np.array(df_train['label'].tolist()).astype('float32')\n",
    "    \n",
    "    x_test = np.array(df_test['image'].tolist()).astype('float32') / 255.0\n",
    "    y_test = np.array(df_test['label'].tolist()).astype('float32')\n",
    "    return x_train, y_train,x_test,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f862c6d",
   "metadata": {},
   "source": [
    "DOUBLING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fa642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_train_set(x_train,y_train):\n",
    "\n",
    "    rng = np.random.RandomState(42)    \n",
    "    \n",
    "    x_flipped = np.flip(x_train, axis=2)\n",
    "    y_flipped = y_train\n",
    "    #---------------------------------#\n",
    "    noise = rng.normal(loc=0.0, scale=0.05, size=x_train.shape)\n",
    "    x_noisy = x_train + noise\n",
    "    x_noisy = np.clip(x_noisy, 0., 1.)\n",
    "    y_noise = y_train\n",
    "    #--------------------------------#\n",
    "    factors = rng.uniform(0.1, 0.3, size=(x_train.shape[0], 1, 1, 1))\n",
    "    x_train_bright = np.clip(x_train + factors, 0.0, 1.0)\n",
    "    #---------------------------------#\n",
    "    contrast_fact = rng.uniform(0.8, 1.5, size=(x_train.shape[0], 1, 1, 1))\n",
    "    mean = np.mean(x_train, axis=(1, 2), keepdims=True)\n",
    "    x_contrast = (x_train - mean) * contrast_fact + mean\n",
    "    x_contrast = np.clip(x_contrast, 0.0, 1.0)\n",
    "    #--------------------------------#\n",
    "    x_train_aug = np.concatenate([x_train,x_flipped, x_noisy,x_train_bright,x_contrast], axis=0)\n",
    "    y_train_aug = np.concatenate([y_train,y_train, y_train,y_train,y_train], axis=0)\n",
    "\n",
    "    #avoid to have all noisy data in validation--> shuffle\n",
    "    indices = np.arange(x_train_aug.shape[0])\n",
    "    rng.shuffle(indices)\n",
    "    x_train_aug = x_train_aug[indices]\n",
    "    y_train_aug = y_train_aug[indices]\n",
    "\n",
    "    return x_train_aug, y_train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b40f52",
   "metadata": {},
   "source": [
    "MODEL BUILIDNG, \n",
    "kernel dimesnsion, pooling dimension, fc layers dimension, number of conv layer and learning rate have different combination.\n",
    "instead, i fixed:\n",
    "pooling stride=2 \n",
    "pooling type: avg pooling\n",
    "number of kernel per layer: 16, 32, 64...\n",
    "last pooling: glob avg pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673a61ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(240,320,3)))\n",
    "\n",
    "    for i in range(4):\n",
    "        kernel_number=16*(2**i)\n",
    "        model.add(layers.Conv2D(kernel_number,(7,7),activation='relu',padding='same'))\n",
    "        model.add(layers.AveragePooling2D((3,3),strides=2,padding='same'))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(128,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a2e85",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee23710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452 images loaded\n",
      "file name is:  lower_100056_jpg.rf.ec9852c66b4eee4a185317210a378f16.jpg shape of the image is:   (240, 320, 3)\n",
      "(8125, 8) upper_604302_jpg.rf.6215ee30a829ec658154eb4d067dfdf5.jpg\n",
      "we have 5 different classes\n"
     ]
    }
   ],
   "source": [
    "dataset, annotation=load_dataset()\n",
    "x_train,y_train, x_test, y_test=dataset_modelling(dataset, annotation)\n",
    "x_train,y_train=augment_train_set(x_train,y_train)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    bestf1=0\n",
    "    all_results = []\n",
    "\n",
    "    print(f\"\\n ================== INIZIO CICLO CON SEED: {seed} ================== \")\n",
    "\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    reset_seeds(seed)\n",
    "    model=build_model()\n",
    "\n",
    "    opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[tf.keras.metrics.Precision(name='precision'),\n",
    "                        tf.keras.metrics.Recall(name='recall'),\n",
    "                        ])\n",
    "    early_stop=EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "    reset_seeds(seed)\n",
    "    #class_weights_dict=compute_class_weight(y_train)\n",
    "    history=model.fit(\n",
    "        x_train,y_train,\n",
    "        epochs=120,\n",
    "        batch_size=16, \n",
    "        validation_split=0.2, \n",
    "        callbacks=[early_stop]\n",
    "        )\n",
    "\n",
    "    y_pred=model.predict(x_test)\n",
    "    predictions_binary = (y_pred > 0.5).astype(int)\n",
    "    target_names = ['goalpost','ball','robot','goalspot','centerspot']\n",
    "    report_dict = classification_report(y_test, predictions_binary, target_names=target_names, output_dict=True)\n",
    "    f1_macro = report_dict['macro avg']['f1-score']\n",
    "    \n",
    "\n",
    "    df_report = pd.DataFrame(report_dict).transpose()\n",
    "    df_report = df_report.round(2)\n",
    "    df_report['support'] = df_report['support'].astype(int)\n",
    "    csv_path = f'csv/report/report_data_aug_fnbctry_{seed}.csv'\n",
    "    df_report.to_csv(csv_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c01a22",
   "metadata": {},
   "source": [
    "FEATURES MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d77841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, input_image):\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n",
    "    layer_names = [layer.name for layer in model.layers if 'conv' in layer.name]\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    img_batch = np.expand_dims(input_image, axis=0)\n",
    "    activations = activation_model.predict(img_batch)\n",
    "    images_per_row = 16\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        n_features = layer_activation.shape[-1] \n",
    "        size_h = layer_activation.shape[1]     \n",
    "        size_w = layer_activation.shape[2]\n",
    "        n_features = min(n_features, 32) \n",
    "        n_cols = n_features // images_per_row\n",
    "        \n",
    "        if n_cols == 0: n_cols = 1 \n",
    "        \n",
    "        display_grid = np.zeros((size_h * n_cols, images_per_row * size_w))\n",
    "        \n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "                \n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= (channel_image.std() + 1e-5) \n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                \n",
    "                display_grid[col * size_h : (col + 1) * size_h,\n",
    "                             row * size_w : (row + 1) * size_w] = channel_image\n",
    "\n",
    "        # Plotting\n",
    "        scale = 1. / size_h\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(f\"Layer: {layer_name} ({n_features} feature maps)\")\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        plt.savefig('images/feature_map/data_aug_fnbC.jpg', bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "index_ball = np.where(y_test[:, 1] == 1)[0][0] \n",
    "img_to_test = x_test[index_ball]\n",
    "\n",
    "visualize_feature_maps(model, img_to_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
