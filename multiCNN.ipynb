{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e06851",
   "metadata": {},
   "source": [
    "5 DIFFERENT CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# Configurazione manuale (più sicura)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"MEmory Growth attivata su GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"Op Determinism Abilitato!\")\n",
    "except AttributeError:\n",
    "    print(\"Attenzione: La tua versione di TF è troppo vecchia per enable_op_determinism.\")\n",
    "\n",
    "def reset_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "SEEDS = [42,555]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff75dc6",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c35211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    folder='dataset/images'\n",
    "    data=[]\n",
    "    for filename in sorted(os.listdir(folder)):   \n",
    "        img_path=os.path.join(folder,filename)\n",
    "        img=cv2.imread(img_path) #opencv save in bgr\n",
    "        data.append({\n",
    "            'image':img,\n",
    "            'filename':filename\n",
    "        })\n",
    "\n",
    "    data_map = {item['filename']: item['image'] for item in data}\n",
    "    label=pd.read_csv('dataset/raw/bbx_annotations.csv')\n",
    "    \n",
    "    coords = ['xmin', 'xmax', 'ymin', 'ymax']\n",
    "    label[coords] = label[coords].astype(float)\n",
    "    \n",
    "    upper_mask = label['filename'].str.lower().str.contains('upper')\n",
    "    label.loc[upper_mask, ['xmin', 'xmax', 'ymin', 'ymax']] /= 2\n",
    "    \n",
    "    for i,item in enumerate(data):\n",
    "        if \"upper\" in item[\"filename\"].lower():\n",
    "            data[i]['image']=cv2.resize(\n",
    "                data[i]['image'],\n",
    "                (data[i]['image'].shape[1]//2,data[i]['image'].shape[0]//2)\n",
    "                ,interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756cd9e3",
   "metadata": {},
   "source": [
    "data modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dda34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_modelling(data,annotation):\n",
    "    dataset_df = pd.DataFrame(data) \n",
    "\n",
    "    \n",
    "    merged = pd.merge(dataset_df, annotation, on='filename')\n",
    "    \n",
    "    merged['area'] = (merged['xmax'] - merged['xmin']) * (merged['ymax'] - merged['ymin'])\n",
    "    merged = merged.sort_values(by=['filename', 'class', 'area'], ascending=[True, True, False])\n",
    "    merged = merged.drop_duplicates(subset=['filename', 'class'], keep='first')\n",
    "    label_map={'goalpost':1,\n",
    "               'ball':2,\n",
    "               'robot':3,\n",
    "               'goalspot':4,\n",
    "               'centerspot':5}\n",
    "    temp_class_id=[]\n",
    "    center_list=[]\n",
    "    for i,row in merged.iterrows():\n",
    "        cls_id = label_map.get(row['class'], 0)\n",
    "        temp_class_id.append(cls_id)\n",
    "\n",
    "        xmin, xmax = row['xmin'], row['xmax']\n",
    "        ymin, ymax = row['ymin'], row['ymax']\n",
    "        cx = (xmin + xmax) / 2.0 / 320.0 \n",
    "        cy = (ymin + ymax) / 2.0 / 240.0\n",
    "        center=(cx,cy)\n",
    "        center_list.append(center)\n",
    "\n",
    "    merged['class']=temp_class_id\n",
    "    merged = merged.drop(columns=['xmin', 'ymin', 'xmax', 'ymax','area'])   \n",
    "    merged['target']=center_list\n",
    "\n",
    "    df_goalpost   = merged[merged['class'] == 1].copy()\n",
    "    df_ball       = merged[merged['class'] == 2].copy()\n",
    "    df_robot      = merged[merged['class'] == 3].copy()\n",
    "    df_goalspot   = merged[merged['class'] == 4].copy()\n",
    "    df_centerspot = merged[merged['class'] == 5].copy()\n",
    "\n",
    "    train_df_gp, test_df_gp = train_test_split(df_goalpost, test_size=0.2, random_state=42)\n",
    "    train_df_b, test_df_b = train_test_split(df_ball, test_size=0.2, random_state=42)\n",
    "    train_df_r, test_df_r = train_test_split(df_robot, test_size=0.2, random_state=42)\n",
    "    train_df_gs, test_df_gs = train_test_split(df_goalspot, test_size=0.2, random_state=42)\n",
    "    train_df_cs, test_df_cs = train_test_split(df_centerspot, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_frames = [test_df_gp, test_df_b, test_df_r, test_df_gs, test_df_cs]\n",
    "    combined_test_df = pd.concat(test_frames, ignore_index=True)\n",
    "    combined_test_df = combined_test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    x_train_gp = np.array(train_df_gp['image'].tolist()).astype('float32') / 255.0\n",
    "    y_train_gp = np.array(train_df_gp['target'].tolist()).astype('float32')\n",
    "    \n",
    "    x_train_b = np.array(train_df_b['image'].tolist()).astype('float32') / 255.0    \n",
    "    y_train_b = np.array(train_df_b['target'].tolist()).astype('float32')\n",
    "\n",
    "    x_train_r = np.array(train_df_r['image'].tolist()).astype('float32') / 255.0\n",
    "    y_train_r = np.array(train_df_r['target'].tolist()).astype('float32')\n",
    "\n",
    "    x_train_gs = np.array(train_df_gs['image'].tolist()).astype('float32') / 255.0\n",
    "    y_train_gs = np.array(train_df_gs['target'].tolist()).astype('float32')\n",
    "\n",
    "    x_train_cs = np.array(train_df_cs['image'].tolist()).astype('float32') / 255.0\n",
    "    y_train_cs = np.array(train_df_cs['target'].tolist()).astype('float32')\n",
    "   \n",
    "    x_test_class = np.array(combined_test_df['class'].tolist()).astype('float32')\n",
    "    x_test_img = np.array(combined_test_df['image'].tolist()).astype('float32') / 255.0\n",
    "    y_test_target = np.array(combined_test_df['target'].tolist()).astype('float32')\n",
    "\n",
    "    return x_train_gp,y_train_gp,x_train_b,y_train_b,x_train_r,y_train_r,x_train_gs,y_train_gs,x_train_cs,y_train_cs,x_test_class,x_test_img, y_test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f142689",
   "metadata": {},
   "source": [
    "hyper search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4605cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparam_combination():\n",
    "    param_grid = {\n",
    "    'batch_size': [16],\n",
    "    'layer_number':[3,5],\n",
    "    'kernel_dim': [7],\n",
    "    'pool_dim': [3,2], \n",
    "    'lr': [0.0001],\n",
    "    'fc1' : [256],\n",
    "    'fc2': [0,256],\n",
    "    'activation':['relu'],\n",
    "    'dropout':[0.2],\n",
    "    'loss':['mae','mse']\n",
    "      \n",
    "}\n",
    "\n",
    "    #every possible combination\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = list(itertools.product(*values))\n",
    "    combinations_dicts = [dict(zip(keys, v)) for v in combinations]\n",
    "    return combinations_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9ba89",
   "metadata": {},
   "source": [
    "building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ec49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layer_num,kernel_dim,pool_dim,fc1,fc2,activation,dropout):\n",
    "    model=models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(240,320,3)))\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        kernel_number=16*(2**i)\n",
    "        model.add(layers.Conv2D(kernel_number,(kernel_dim,kernel_dim),activation=activation,padding='same'))\n",
    "        model.add(layers.AveragePooling2D((pool_dim,pool_dim),strides=2,padding='same'))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    if fc1>0:\n",
    "        model.add(layers.Dense(fc1,activation='relu'))\n",
    "    if fc2>0:\n",
    "        model.add(layers.Dense(fc2,activation='relu'))\n",
    "    model.add(layers.Dense(2,activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55dd02",
   "metadata": {},
   "source": [
    "saving csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89161846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(mae,param,seed,all_results,r2,r2_model,mae_model):\n",
    "    current_result = param.copy()  \n",
    "    current_result['mae_Score']=mae\n",
    "    current_result['R2_Score']=r2\n",
    "    current_result['R2_gp']=r2_model[0]\n",
    "    current_result['R2_b']=r2_model[1]\n",
    "    current_result['R2_r']=r2_model[2]\n",
    "    current_result['R2_gs']=r2_model[3]\n",
    "    current_result['R2_cs']=r2_model[4]\n",
    "    current_result['mae_gp']=mae_model[0]\n",
    "    current_result['mae_b']=mae_model[1]\n",
    "    current_result['mae_r']=mae_model[2]\n",
    "    current_result['mae_gs']=mae_model[3]\n",
    "    current_result['mae_cs']=mae_model[4]\n",
    "\n",
    "\n",
    "\n",
    "    all_results.append(current_result)\n",
    "\n",
    "    pd.DataFrame(all_results).to_csv(f'regression/csv/search/multi_cnn2_data_aug_{seed}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f8320a",
   "metadata": {},
   "source": [
    "visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_only_centers(model_gp,model_b,model_r,model_gs,model_cs, x_test_img,x_test_class, y_test,seed):\n",
    "    index_list=[10,34,80,120,25,48,72,60,50]\n",
    "    for index in index_list:\n",
    "        img_norm = x_test_img[index].copy()  \n",
    "        \n",
    "        real_targets = y_test[index]\n",
    "        \n",
    "        sample_img_batch = x_test_img[index:index+1]\n",
    "        if x_test_class[index]==1:\n",
    "            model=model_gp\n",
    "        elif x_test_class[index]==2:\n",
    "            model=model_b\n",
    "        elif x_test_class[index]==3:\n",
    "            model=model_r\n",
    "        elif x_test_class[index]==4:\n",
    "            model=model_gs\n",
    "        else:\n",
    "            model=model_cs\n",
    "\n",
    "        pred_targets = model.predict(sample_img_batch, verbose=0)[0]\n",
    "        \n",
    "        if img_norm.max() <= 1.0:\n",
    "            img_display = (img_norm * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_display = img_norm.astype(np.uint8)\n",
    "            \n",
    "        img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        IMG_H, IMG_W = img_display.shape[:2]\n",
    "        \n",
    "        print(f\"\\n--- Analisi Centri Immagine {index} ---\")\n",
    "\n",
    "        def draw_points(targets, color, label):\n",
    "            for i in range(0, len(targets), 2):\n",
    "                if i+1 >= len(targets): break\n",
    "                \n",
    "                xc = targets[i]\n",
    "                yc = targets[i+1]\n",
    "                \n",
    "                if xc < 0.01 and yc < 0.01: continue\n",
    "                \n",
    "                xc_px = int(xc * IMG_W)\n",
    "                yc_px = int(yc * IMG_H)\n",
    "                \n",
    "                cv2.circle(img_display, (xc_px, yc_px), 3, color, -1)\n",
    "                \n",
    "                cv2.circle(img_display, (xc_px, yc_px), 5, (255, 255, 255), 1)\n",
    "                \n",
    "                print(f\"{label} {i//2+1}: ({xc_px}, {yc_px}) px\")\n",
    "\n",
    "        draw_points(real_targets, (0, 255, 0), \"Reale\")    # Verde\n",
    "        draw_points(pred_targets, (255, 0, 0), \"Predetto\") # Rosso\n",
    "\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(img_display)\n",
    "        plt.title(f\"Img {index}: green=REAL  red=PREDICTION\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        save_path=f'regression/images/predvstrue/data_aug/multi_cnn2_img_{index}_seed{seed}.png'\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight') \n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def data_aug(x_train_gp, y_train_gp, x_train_b, y_train_b, x_train_r, y_train_r, x_train_gs, y_train_gs, x_train_cs, y_train_cs):\n",
    "    x_list = [x_train_gp, x_train_b, x_train_r, x_train_gs, x_train_cs]\n",
    "    y_list = [y_train_gp, y_train_b, y_train_r, y_train_gs, y_train_cs]\n",
    "    class_names = [\"GoalPost\", \"Ball\", \"Robot\", \"GoalSpot\", \"CenterSpot\"]\n",
    "    x_aug_list = []\n",
    "    y_aug_list = []\n",
    "\n",
    "    def augment_single(x, y):\n",
    "        rng = np.random.RandomState(42)    \n",
    "        \n",
    "        x_flipped = np.flip(x, axis=2)\n",
    "        y_flipped = y.copy()\n",
    "        y_flipped[:, 0] = 1.0 - y_flipped[:, 0] \n",
    "        \n",
    "        noise = rng.normal(loc=0.0, scale=0.02, size=x.shape)\n",
    "        x_noisy = np.clip(x + noise, 0., 1.)\n",
    "        \n",
    "        factors = rng.uniform(0.1, 0.3, size=(x.shape[0], 1, 1, 1))\n",
    "        x_bright = np.clip(x + factors, 0.0, 1.0)\n",
    "        \n",
    "        contrast_fact = rng.uniform(0.8, 1.5, size=(x.shape[0], 1, 1, 1))\n",
    "        mean = np.mean(x, axis=(1, 2), keepdims=True)\n",
    "        x_contrast = (x - mean) * contrast_fact + mean\n",
    "        x_contrast = np.clip(x_contrast, 0.0, 1.0)\n",
    "        \n",
    "        \n",
    "        x_final = np.concatenate([x, x_flipped, x_noisy, x_bright, x_contrast], axis=0)\n",
    "        y_final = np.concatenate([y, y_flipped, y, y, y], axis=0) \n",
    "        \n",
    "        indices = np.arange(x_final.shape[0])\n",
    "        rng.shuffle(indices)\n",
    "        \n",
    "        return x_final[indices], y_final[indices]\n",
    "\n",
    "    for i in range(len(x_list)):\n",
    "        original_count = x_list[i].shape[0]\n",
    "        name = class_names[i]\n",
    "        \n",
    "        x_a, y_a = augment_single(x_list[i], y_list[i])\n",
    "        \n",
    "        aug_count = x_a.shape[0]\n",
    "        print(f\"[{name}] Originali: {original_count} -> Aumentati: {aug_count} (x{aug_count/original_count:.0f})\")\n",
    "        \n",
    "        x_aug_list.append(x_a)\n",
    "        y_aug_list.append(y_a)\n",
    "\n",
    "    return (x_aug_list[0], y_aug_list[0], \n",
    "            x_aug_list[1], y_aug_list[1], \n",
    "            x_aug_list[2], y_aug_list[2],\n",
    "            x_aug_list[3], y_aug_list[3], \n",
    "            x_aug_list[4], y_aug_list[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4104215",
   "metadata": {},
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,annotation=load_dataset()\n",
    "x_gp, y_gp, x_b, y_b, x_r, y_r, x_gs, y_gs, x_cs, y_cs, x_test_class, x_test_img, y_test = dataset_modelling(data, annotation)\n",
    "x_t_gp, x_v_gp, y_t_gp, y_v_gp = train_test_split(x_gp, y_gp, test_size=0.2, random_state=42)\n",
    "x_t_b,  x_v_b,  y_t_b,  y_v_b  = train_test_split(x_b,  y_b,  test_size=0.2, random_state=42)\n",
    "x_t_r,  x_v_r,  y_t_r,  y_v_r  = train_test_split(x_r,  y_r,  test_size=0.2, random_state=42)\n",
    "x_t_gs, x_v_gs, y_t_gs, y_v_gs = train_test_split(x_gs, y_gs, test_size=0.2, random_state=42)\n",
    "x_t_cs, x_v_cs, y_t_cs, y_v_cs = train_test_split(x_cs, y_cs, test_size=0.2, random_state=42)\n",
    "x_t_gp_aug, y_t_gp_aug, x_t_b_aug,  y_t_b_aug, x_t_r_aug,  y_t_r_aug, x_t_gs_aug, y_t_gs_aug, x_t_cs_aug, y_t_cs_aug = data_aug(x_t_gp, y_t_gp, x_t_b, y_t_b, x_t_r, y_t_r, x_t_gs, y_t_gs, x_t_cs, y_t_cs)\n",
    "combination=create_hyperparam_combination()\n",
    "total_combinations = len(combination)\n",
    "final_results = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n ================== INIZIO CICLO CON SEED: {seed} ================== \")\n",
    "    all_results = []\n",
    "    bestmae=100000\n",
    "    best_r2=-1000000\n",
    "    current_seed_best_params = {}\n",
    "    for i,param in enumerate(combination):\n",
    "\n",
    "        print(f\"ITERAZIONE {i+1} of {total_combinations}\")\n",
    "        print(f\"PARAMETRI ATTUALI: {param}\")  \n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        reset_seeds(seed)\n",
    "\n",
    "        model_gp=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'],param['activation'],param['dropout'])\n",
    "        model_b=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'],param['activation'],param['dropout'])\n",
    "        model_r=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'],param['activation'],param['dropout'])\n",
    "        model_gs=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'],param['activation'],param['dropout'])\n",
    "        model_cs=build_model( param['layer_number'],param['kernel_dim'],param['pool_dim'],param['fc1'],param['fc2'],param['activation'],param['dropout'])\n",
    "\n",
    "        list_model=[model_gp, model_b, model_r, model_gs, model_cs]\n",
    "        \n",
    "        for model in list_model:\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=param['lr']),\n",
    "                        loss=param['loss'],\n",
    "                        )\n",
    "        early_stop_gp = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)            \n",
    "        history_gp=model_gp.fit(\n",
    "            x_t_gp_aug, y_t_gp_aug,      \n",
    "            validation_data=(x_v_gp, y_v_gp),\n",
    "            epochs=120,\n",
    "            batch_size=param['batch_size'], \n",
    "            validation_split=0.2, \n",
    "            callbacks=[early_stop_gp]\n",
    "                )\n",
    "        early_stop_b = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        history_b=model_b.fit(\n",
    "            x_t_b_aug, y_t_b_aug,\n",
    "            validation_data=(x_v_b, y_v_b),\n",
    "            epochs=120,\n",
    "            batch_size=param['batch_size'], \n",
    "            validation_split=0.2, \n",
    "            callbacks=[early_stop_b]\n",
    "                )\n",
    "        early_stop_r = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        history_r=model_r.fit(\n",
    "            x_t_r_aug, y_t_r_aug,\n",
    "            validation_data=(x_v_r, y_v_r),\n",
    "            epochs=120,\n",
    "            batch_size=param['batch_size'], \n",
    "            validation_split=0.2, \n",
    "            callbacks=[early_stop_r]\n",
    "                )\n",
    "        early_stop_gs = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        history_gs=model_gs.fit(\n",
    "            x_t_gs_aug, y_t_gs_aug,\n",
    "            validation_data=(x_v_gs, y_v_gs),\n",
    "            epochs=120,\n",
    "            batch_size=param['batch_size'], \n",
    "            validation_split=0.2, \n",
    "            callbacks=[early_stop_gs]\n",
    "                )\n",
    "        early_stop_cs = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "        history_cs=model_cs.fit(\n",
    "            x_t_cs_aug, y_t_cs_aug,\n",
    "            validation_data=(x_v_cs, y_v_cs),\n",
    "            epochs=120,\n",
    "            batch_size=param['batch_size'], \n",
    "            validation_split=0.2, \n",
    "            callbacks=[early_stop_cs]\n",
    "                )\n",
    "        \n",
    "        prediction=[]\n",
    "        for i,x_sample in enumerate(x_test_img):\n",
    "            x_sample = np.expand_dims(x_sample, axis=0)\n",
    "            label=x_test_class[i]\n",
    "            if label==1:\n",
    "                pred=model_gp.predict(x_sample,verbose=0)\n",
    "            elif label==2:\n",
    "                pred=model_b.predict(x_sample,verbose=0)\n",
    "            elif label==3:\n",
    "                pred=model_r.predict(x_sample,verbose=0)\n",
    "            elif label==4:\n",
    "                pred=model_gs.predict(x_sample,verbose=0)\n",
    "            else:\n",
    "                pred=model_cs.predict(x_sample,verbose=0)\n",
    "            prediction.append(pred[0])\n",
    "\n",
    "        prediction=np.array(prediction)\n",
    "        mae = mean_absolute_error(y_test, prediction)\n",
    "        r2=r2_score(y_test,prediction)\n",
    "\n",
    "        classes_map = {1: 'GoalPost', 2: 'Ball', 3: 'Robot', 4: 'GoalSpot', 5: 'CenterSpot'}\n",
    "        models_list = {1: model_gp, 2: model_b, 3: model_r, 4: model_gs, 5: model_cs}\n",
    "\n",
    "        print(\"\\n--- Performance per Class ---\")\n",
    "        mae_model=[]\n",
    "        r2_model=[]\n",
    "        for class_id, class_name in classes_map.items():\n",
    "            mask = (x_test_class == class_id)\n",
    "            \n",
    "            x_test_specific = x_test_img[mask]\n",
    "            y_test_specific = y_test[mask]\n",
    "            \n",
    "            model_specific = models_list[class_id]\n",
    "            pred_specific = model_specific.predict(x_test_specific, verbose=0)\n",
    "            \n",
    "            r2_specific = r2_score(y_test_specific, pred_specific)\n",
    "            r2_model.append(r2_specific)\n",
    "            mae_specific = mean_absolute_error(y_test_specific, pred_specific)\n",
    "            mae_model.append(mae_specific)\n",
    "        if mae<bestmae:\n",
    "            bestmae=mae\n",
    "            current_seed_best_params = param.copy()\n",
    "            best_r2=r2\n",
    "            model_gp.save_weights(f'regression/weights/best_gp_seed{seed}.weights.h5')\n",
    "            model_b.save_weights(f'regression/weights/best_b_seed{seed}.weights.h5')\n",
    "            model_r.save_weights(f'regression/weights/best_r_seed{seed}.weights.h5')\n",
    "            model_gs.save_weights(f'regression/weights/best_gs_seed{seed}.weights.h5')\n",
    "            model_cs.save_weights(f'regression/weights/best_cs_seed{seed}.weights.h5')\n",
    "        save_csv(mae,param,seed,all_results,r2,r2_model,mae_model)\n",
    "\n",
    "    p = current_seed_best_params\n",
    "\n",
    "    model_gp=build_model( p['layer_number'],p['kernel_dim'],p['pool_dim'],p['fc1'],p['fc2'],p['activation'],p['dropout'])\n",
    "    model_b=build_model( p['layer_number'],p['kernel_dim'],p['pool_dim'],p['fc1'],p['fc2'],p['activation'],p['dropout'])\n",
    "    model_r=build_model( p['layer_number'],p['kernel_dim'],p['pool_dim'],p['fc1'],p['fc2'],p['activation'],p['dropout'])\n",
    "    model_gs=build_model( p['layer_number'],p['kernel_dim'],p['pool_dim'],p['fc1'],p['fc2'],p['activation'],p['dropout'])\n",
    "    model_cs=build_model( p['layer_number'],p['kernel_dim'],p['pool_dim'],p['fc1'],p['fc2'],p['activation'],p['dropout'])\n",
    "\n",
    "    current_seed_best_params['seed'] = seed\n",
    "    current_seed_best_params['best_mae_score'] = bestmae\n",
    "    current_seed_best_params['best_r2_score'] = best_r2\n",
    "\n",
    "    model_gp.load_weights(f'regression/weights/best_gp_seed{seed}.weights.h5')\n",
    "    model_b.load_weights(f'regression/weights/best_b_seed{seed}.weights.h5')\n",
    "    model_r.load_weights(f'regression/weights/best_r_seed{seed}.weights.h5')\n",
    "    model_gs.load_weights(f'regression/weights/best_gs_seed{seed}.weights.h5')\n",
    "    model_cs.load_weights(f'regression/weights/best_cs_seed{seed}.weights.h5')\n",
    "\n",
    "    print(current_seed_best_params)\n",
    "    visualize_only_centers(model_gp,model_b,model_r,model_gs,model_cs, x_test_img,x_test_class ,y_test,seed)\n",
    "   \n",
    "    final_results.append(current_seed_best_params)\n",
    "\n",
    "\n",
    "df_best_results = pd.DataFrame(final_results)\n",
    "df_best_results.to_csv('regression/csv/best_model/multicnn2_dataaug.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
